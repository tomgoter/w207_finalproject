{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Flow Notebook\n",
    "## W207 Final Project\n",
    "### T. P. Goter\n",
    "### July 15, 2019\n",
    "\n",
    "This workbook is used to create convolutional neural nets for facial keypoint detection on CPUs (not TPUs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed packages\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tensorflow.keras import models, layers, callbacks\n",
    "from tensorflow.keras import optimizers, metrics\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "- Load in the pickle file that was created as part of the EDA in DataExploration.ipynb. \n",
    "- This dataset has the NaNs removed and a few mislabeled images removed as well. \n",
    "- As such there is only limited training and development data to use. \n",
    "- The image data has already been normalized to [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Random Seed for reproducibility\n",
    "np.random.seed(13)\n",
    "\n",
    "# Load the dataframe from the pickle file\n",
    "df_nostache_nonan = pd.read_pickle(\"df_nostache_nonan.pkl\")\n",
    "\n",
    "# Grab the last column - that is our image data for X matrix\n",
    "X = df_nostache_nonan.iloc[:, -1]\n",
    "\n",
    "# Convert from a series of arrays to an NDarray\n",
    "X = np.array([x.reshape(96,96,1) for x in X])\n",
    "\n",
    "# Grab the keypoints and stick into our y-variable\n",
    "y = np.array(df_nostache_nonan.iloc[:,:-1])\n",
    "# y = (y - 48) / 48  # scale target coordinates to [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_eye_center_x</th>\n",
       "      <th>left_eye_center_y</th>\n",
       "      <th>right_eye_center_x</th>\n",
       "      <th>right_eye_center_y</th>\n",
       "      <th>left_eye_inner_corner_x</th>\n",
       "      <th>left_eye_inner_corner_y</th>\n",
       "      <th>left_eye_outer_corner_x</th>\n",
       "      <th>left_eye_outer_corner_y</th>\n",
       "      <th>right_eye_inner_corner_x</th>\n",
       "      <th>right_eye_inner_corner_y</th>\n",
       "      <th>...</th>\n",
       "      <th>nose_tip_y</th>\n",
       "      <th>mouth_left_corner_x</th>\n",
       "      <th>mouth_left_corner_y</th>\n",
       "      <th>mouth_right_corner_x</th>\n",
       "      <th>mouth_right_corner_y</th>\n",
       "      <th>mouth_center_top_lip_x</th>\n",
       "      <th>mouth_center_top_lip_y</th>\n",
       "      <th>mouth_center_bottom_lip_x</th>\n",
       "      <th>mouth_center_bottom_lip_y</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.328960</td>\n",
       "      <td>36.912768</td>\n",
       "      <td>32.007040</td>\n",
       "      <td>35.196608</td>\n",
       "      <td>59.751040</td>\n",
       "      <td>38.342848</td>\n",
       "      <td>71.477760</td>\n",
       "      <td>37.198784</td>\n",
       "      <td>36.869120</td>\n",
       "      <td>36.912768</td>\n",
       "      <td>...</td>\n",
       "      <td>62.940800</td>\n",
       "      <td>58.606720</td>\n",
       "      <td>76.955520</td>\n",
       "      <td>31.434880</td>\n",
       "      <td>75.811840</td>\n",
       "      <td>45.163520</td>\n",
       "      <td>74.095360</td>\n",
       "      <td>44.019840</td>\n",
       "      <td>84.392320</td>\n",
       "      <td>[0.5372549019607843, 0.5411764705882353, 0.537...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64.918419</td>\n",
       "      <td>38.881725</td>\n",
       "      <td>28.223425</td>\n",
       "      <td>36.297772</td>\n",
       "      <td>58.457677</td>\n",
       "      <td>39.399090</td>\n",
       "      <td>71.378587</td>\n",
       "      <td>39.915880</td>\n",
       "      <td>33.908695</td>\n",
       "      <td>37.331353</td>\n",
       "      <td>...</td>\n",
       "      <td>59.813174</td>\n",
       "      <td>56.907305</td>\n",
       "      <td>83.587257</td>\n",
       "      <td>32.616431</td>\n",
       "      <td>82.295569</td>\n",
       "      <td>45.278659</td>\n",
       "      <td>77.385772</td>\n",
       "      <td>45.278659</td>\n",
       "      <td>92.373269</td>\n",
       "      <td>[0.7450980392156863, 0.4823529411764706, 0.572...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.690269</td>\n",
       "      <td>35.696894</td>\n",
       "      <td>29.502277</td>\n",
       "      <td>37.127950</td>\n",
       "      <td>60.322981</td>\n",
       "      <td>36.359420</td>\n",
       "      <td>75.983503</td>\n",
       "      <td>37.477234</td>\n",
       "      <td>39.095652</td>\n",
       "      <td>37.684472</td>\n",
       "      <td>...</td>\n",
       "      <td>60.597097</td>\n",
       "      <td>68.056859</td>\n",
       "      <td>71.180585</td>\n",
       "      <td>33.458101</td>\n",
       "      <td>74.460088</td>\n",
       "      <td>50.136717</td>\n",
       "      <td>76.991396</td>\n",
       "      <td>49.879042</td>\n",
       "      <td>77.060266</td>\n",
       "      <td>[0.0196078431372549, 0.00784313725490196, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65.265185</td>\n",
       "      <td>35.172741</td>\n",
       "      <td>29.512889</td>\n",
       "      <td>33.319111</td>\n",
       "      <td>59.173926</td>\n",
       "      <td>36.232296</td>\n",
       "      <td>70.826667</td>\n",
       "      <td>36.497185</td>\n",
       "      <td>35.604148</td>\n",
       "      <td>34.113778</td>\n",
       "      <td>...</td>\n",
       "      <td>55.829926</td>\n",
       "      <td>58.644741</td>\n",
       "      <td>71.455407</td>\n",
       "      <td>33.749926</td>\n",
       "      <td>70.395852</td>\n",
       "      <td>46.197333</td>\n",
       "      <td>67.747556</td>\n",
       "      <td>45.932444</td>\n",
       "      <td>78.340741</td>\n",
       "      <td>[0.43137254901960786, 0.44313725490196076, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62.477241</td>\n",
       "      <td>41.666207</td>\n",
       "      <td>27.873103</td>\n",
       "      <td>34.604138</td>\n",
       "      <td>58.637241</td>\n",
       "      <td>40.960000</td>\n",
       "      <td>72.376497</td>\n",
       "      <td>44.003752</td>\n",
       "      <td>39.313655</td>\n",
       "      <td>37.846069</td>\n",
       "      <td>...</td>\n",
       "      <td>55.906545</td>\n",
       "      <td>57.770074</td>\n",
       "      <td>77.269048</td>\n",
       "      <td>32.047118</td>\n",
       "      <td>73.298886</td>\n",
       "      <td>47.632311</td>\n",
       "      <td>73.206557</td>\n",
       "      <td>47.724641</td>\n",
       "      <td>74.166782</td>\n",
       "      <td>[0.27450980392156865, 0.32941176470588235, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>65.476354</td>\n",
       "      <td>39.960816</td>\n",
       "      <td>30.590259</td>\n",
       "      <td>35.764680</td>\n",
       "      <td>59.183673</td>\n",
       "      <td>40.359184</td>\n",
       "      <td>72.593197</td>\n",
       "      <td>41.142857</td>\n",
       "      <td>35.804082</td>\n",
       "      <td>36.457143</td>\n",
       "      <td>...</td>\n",
       "      <td>55.580952</td>\n",
       "      <td>57.662966</td>\n",
       "      <td>77.396136</td>\n",
       "      <td>27.432925</td>\n",
       "      <td>72.925551</td>\n",
       "      <td>43.114286</td>\n",
       "      <td>73.676190</td>\n",
       "      <td>42.813605</td>\n",
       "      <td>75.427211</td>\n",
       "      <td>[0.8862745098039215, 0.8823529411764706, 0.866...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>68.143680</td>\n",
       "      <td>40.385280</td>\n",
       "      <td>29.429440</td>\n",
       "      <td>38.747520</td>\n",
       "      <td>60.996480</td>\n",
       "      <td>40.832000</td>\n",
       "      <td>76.035200</td>\n",
       "      <td>42.470080</td>\n",
       "      <td>37.618880</td>\n",
       "      <td>39.491840</td>\n",
       "      <td>...</td>\n",
       "      <td>57.509120</td>\n",
       "      <td>63.825600</td>\n",
       "      <td>79.248640</td>\n",
       "      <td>33.152000</td>\n",
       "      <td>78.355200</td>\n",
       "      <td>49.725120</td>\n",
       "      <td>73.580480</td>\n",
       "      <td>49.530880</td>\n",
       "      <td>83.268800</td>\n",
       "      <td>[0.6980392156862745, 0.30196078431372547, 0.18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>63.812741</td>\n",
       "      <td>36.945185</td>\n",
       "      <td>31.237926</td>\n",
       "      <td>36.680296</td>\n",
       "      <td>59.045333</td>\n",
       "      <td>36.945185</td>\n",
       "      <td>69.639111</td>\n",
       "      <td>37.474963</td>\n",
       "      <td>36.269630</td>\n",
       "      <td>37.210074</td>\n",
       "      <td>...</td>\n",
       "      <td>59.985778</td>\n",
       "      <td>62.488296</td>\n",
       "      <td>70.049185</td>\n",
       "      <td>36.004741</td>\n",
       "      <td>69.784296</td>\n",
       "      <td>49.246815</td>\n",
       "      <td>66.077037</td>\n",
       "      <td>49.511704</td>\n",
       "      <td>75.345778</td>\n",
       "      <td>[0.803921568627451, 0.8117647058823529, 0.8156...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>59.210904</td>\n",
       "      <td>34.925801</td>\n",
       "      <td>30.399355</td>\n",
       "      <td>42.995118</td>\n",
       "      <td>53.374645</td>\n",
       "      <td>37.602033</td>\n",
       "      <td>64.831565</td>\n",
       "      <td>33.696265</td>\n",
       "      <td>36.809501</td>\n",
       "      <td>42.665471</td>\n",
       "      <td>...</td>\n",
       "      <td>56.709023</td>\n",
       "      <td>67.113590</td>\n",
       "      <td>70.542162</td>\n",
       "      <td>40.077170</td>\n",
       "      <td>79.616248</td>\n",
       "      <td>57.191154</td>\n",
       "      <td>75.232758</td>\n",
       "      <td>56.219962</td>\n",
       "      <td>75.862721</td>\n",
       "      <td>[0.5450980392156862, 0.5568627450980392, 0.549...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>67.295312</td>\n",
       "      <td>34.149161</td>\n",
       "      <td>30.030452</td>\n",
       "      <td>35.695484</td>\n",
       "      <td>57.399398</td>\n",
       "      <td>36.159312</td>\n",
       "      <td>77.346065</td>\n",
       "      <td>35.076817</td>\n",
       "      <td>39.617376</td>\n",
       "      <td>36.623140</td>\n",
       "      <td>...</td>\n",
       "      <td>59.817290</td>\n",
       "      <td>64.975828</td>\n",
       "      <td>73.424172</td>\n",
       "      <td>35.132903</td>\n",
       "      <td>75.279828</td>\n",
       "      <td>47.657634</td>\n",
       "      <td>72.187183</td>\n",
       "      <td>48.430796</td>\n",
       "      <td>80.382280</td>\n",
       "      <td>[0.6627450980392157, 0.43137254901960786, 0.27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>67.569951</td>\n",
       "      <td>37.167805</td>\n",
       "      <td>28.590439</td>\n",
       "      <td>35.860098</td>\n",
       "      <td>60.506341</td>\n",
       "      <td>36.906146</td>\n",
       "      <td>73.325268</td>\n",
       "      <td>37.952780</td>\n",
       "      <td>34.607415</td>\n",
       "      <td>36.383415</td>\n",
       "      <td>...</td>\n",
       "      <td>52.341073</td>\n",
       "      <td>60.768000</td>\n",
       "      <td>74.839024</td>\n",
       "      <td>33.561366</td>\n",
       "      <td>74.577366</td>\n",
       "      <td>47.688000</td>\n",
       "      <td>68.298732</td>\n",
       "      <td>47.426341</td>\n",
       "      <td>81.379317</td>\n",
       "      <td>[0.6705882352941176, 0.6784313725490196, 0.686...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>65.718621</td>\n",
       "      <td>38.017655</td>\n",
       "      <td>29.472828</td>\n",
       "      <td>37.277793</td>\n",
       "      <td>59.060690</td>\n",
       "      <td>37.647724</td>\n",
       "      <td>71.265931</td>\n",
       "      <td>37.647724</td>\n",
       "      <td>35.020138</td>\n",
       "      <td>38.017655</td>\n",
       "      <td>...</td>\n",
       "      <td>55.030345</td>\n",
       "      <td>62.389241</td>\n",
       "      <td>76.482207</td>\n",
       "      <td>32.061517</td>\n",
       "      <td>75.372414</td>\n",
       "      <td>45.376552</td>\n",
       "      <td>69.825103</td>\n",
       "      <td>45.376552</td>\n",
       "      <td>83.139310</td>\n",
       "      <td>[0.9098039215686274, 0.9137254901960784, 0.913...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>66.454252</td>\n",
       "      <td>39.431841</td>\n",
       "      <td>30.444079</td>\n",
       "      <td>36.860185</td>\n",
       "      <td>60.738119</td>\n",
       "      <td>39.717934</td>\n",
       "      <td>73.027391</td>\n",
       "      <td>40.575576</td>\n",
       "      <td>36.160212</td>\n",
       "      <td>37.431735</td>\n",
       "      <td>...</td>\n",
       "      <td>60.294993</td>\n",
       "      <td>59.881113</td>\n",
       "      <td>82.872795</td>\n",
       "      <td>35.017113</td>\n",
       "      <td>82.015788</td>\n",
       "      <td>47.305748</td>\n",
       "      <td>78.014305</td>\n",
       "      <td>47.591841</td>\n",
       "      <td>89.732026</td>\n",
       "      <td>[0.2627450980392157, 0.28627450980392155, 0.31...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>64.332493</td>\n",
       "      <td>34.607277</td>\n",
       "      <td>32.889863</td>\n",
       "      <td>37.251945</td>\n",
       "      <td>59.630466</td>\n",
       "      <td>35.488833</td>\n",
       "      <td>69.033863</td>\n",
       "      <td>34.313359</td>\n",
       "      <td>37.591233</td>\n",
       "      <td>37.545797</td>\n",
       "      <td>...</td>\n",
       "      <td>60.466849</td>\n",
       "      <td>62.275726</td>\n",
       "      <td>71.927014</td>\n",
       "      <td>36.122301</td>\n",
       "      <td>73.690521</td>\n",
       "      <td>50.520986</td>\n",
       "      <td>69.870247</td>\n",
       "      <td>50.814904</td>\n",
       "      <td>77.510137</td>\n",
       "      <td>[0.984313725490196, 0.9725490196078431, 0.9725...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>65.268000</td>\n",
       "      <td>37.630857</td>\n",
       "      <td>31.813714</td>\n",
       "      <td>37.375429</td>\n",
       "      <td>60.416000</td>\n",
       "      <td>37.630857</td>\n",
       "      <td>72.418857</td>\n",
       "      <td>38.907429</td>\n",
       "      <td>36.921714</td>\n",
       "      <td>37.375429</td>\n",
       "      <td>...</td>\n",
       "      <td>60.869714</td>\n",
       "      <td>62.203429</td>\n",
       "      <td>69.808000</td>\n",
       "      <td>35.644571</td>\n",
       "      <td>68.530857</td>\n",
       "      <td>49.434857</td>\n",
       "      <td>64.956000</td>\n",
       "      <td>49.434857</td>\n",
       "      <td>77.469143</td>\n",
       "      <td>[0.8117647058823529, 0.8235294117647058, 0.831...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>67.728819</td>\n",
       "      <td>35.194648</td>\n",
       "      <td>27.803959</td>\n",
       "      <td>34.399126</td>\n",
       "      <td>59.616328</td>\n",
       "      <td>34.717270</td>\n",
       "      <td>76.967427</td>\n",
       "      <td>36.511126</td>\n",
       "      <td>37.029461</td>\n",
       "      <td>35.035413</td>\n",
       "      <td>...</td>\n",
       "      <td>58.848000</td>\n",
       "      <td>62.479618</td>\n",
       "      <td>79.095809</td>\n",
       "      <td>29.394676</td>\n",
       "      <td>78.141379</td>\n",
       "      <td>45.937147</td>\n",
       "      <td>74.801038</td>\n",
       "      <td>45.937147</td>\n",
       "      <td>83.549488</td>\n",
       "      <td>[0.3215686274509804, 0.16862745098039217, 0.11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>65.848167</td>\n",
       "      <td>32.065800</td>\n",
       "      <td>28.089537</td>\n",
       "      <td>39.300468</td>\n",
       "      <td>58.094677</td>\n",
       "      <td>36.245190</td>\n",
       "      <td>73.716950</td>\n",
       "      <td>31.028158</td>\n",
       "      <td>36.275378</td>\n",
       "      <td>40.395757</td>\n",
       "      <td>...</td>\n",
       "      <td>54.491308</td>\n",
       "      <td>69.076342</td>\n",
       "      <td>71.554749</td>\n",
       "      <td>39.391282</td>\n",
       "      <td>77.685059</td>\n",
       "      <td>55.103653</td>\n",
       "      <td>73.487730</td>\n",
       "      <td>55.048425</td>\n",
       "      <td>74.316150</td>\n",
       "      <td>[0.1843137254901961, 0.19607843137254902, 0.20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>67.042909</td>\n",
       "      <td>39.317950</td>\n",
       "      <td>28.749223</td>\n",
       "      <td>38.254017</td>\n",
       "      <td>60.011901</td>\n",
       "      <td>39.095008</td>\n",
       "      <td>72.360992</td>\n",
       "      <td>40.027240</td>\n",
       "      <td>35.840529</td>\n",
       "      <td>38.254017</td>\n",
       "      <td>...</td>\n",
       "      <td>54.955636</td>\n",
       "      <td>63.497256</td>\n",
       "      <td>74.775273</td>\n",
       "      <td>32.294876</td>\n",
       "      <td>74.775273</td>\n",
       "      <td>48.250711</td>\n",
       "      <td>70.874975</td>\n",
       "      <td>48.605355</td>\n",
       "      <td>82.221223</td>\n",
       "      <td>[0.39215686274509803, 0.3764705882352941, 0.35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>66.761855</td>\n",
       "      <td>41.286311</td>\n",
       "      <td>26.704609</td>\n",
       "      <td>42.826962</td>\n",
       "      <td>60.497273</td>\n",
       "      <td>41.609855</td>\n",
       "      <td>74.983972</td>\n",
       "      <td>42.062616</td>\n",
       "      <td>35.446920</td>\n",
       "      <td>42.515377</td>\n",
       "      <td>...</td>\n",
       "      <td>60.698574</td>\n",
       "      <td>66.080554</td>\n",
       "      <td>77.072720</td>\n",
       "      <td>30.316069</td>\n",
       "      <td>77.977910</td>\n",
       "      <td>47.785744</td>\n",
       "      <td>74.367114</td>\n",
       "      <td>48.456083</td>\n",
       "      <td>88.109730</td>\n",
       "      <td>[0.9882352941176471, 0.592156862745098, 0.1294...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>64.918095</td>\n",
       "      <td>38.856686</td>\n",
       "      <td>30.528000</td>\n",
       "      <td>38.856686</td>\n",
       "      <td>59.470476</td>\n",
       "      <td>39.197181</td>\n",
       "      <td>70.707048</td>\n",
       "      <td>39.197181</td>\n",
       "      <td>35.975619</td>\n",
       "      <td>39.537676</td>\n",
       "      <td>...</td>\n",
       "      <td>57.584000</td>\n",
       "      <td>62.534857</td>\n",
       "      <td>76.992762</td>\n",
       "      <td>32.911238</td>\n",
       "      <td>77.673905</td>\n",
       "      <td>47.552762</td>\n",
       "      <td>71.545143</td>\n",
       "      <td>47.552762</td>\n",
       "      <td>82.781714</td>\n",
       "      <td>[0.7803921568627451, 0.7764705882352941, 0.776...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>66.562684</td>\n",
       "      <td>35.949832</td>\n",
       "      <td>30.302555</td>\n",
       "      <td>35.119277</td>\n",
       "      <td>59.366400</td>\n",
       "      <td>36.503535</td>\n",
       "      <td>72.099097</td>\n",
       "      <td>35.949832</td>\n",
       "      <td>36.115819</td>\n",
       "      <td>35.396067</td>\n",
       "      <td>...</td>\n",
       "      <td>59.292697</td>\n",
       "      <td>58.812697</td>\n",
       "      <td>79.959948</td>\n",
       "      <td>38.330013</td>\n",
       "      <td>78.852542</td>\n",
       "      <td>48.294194</td>\n",
       "      <td>74.977858</td>\n",
       "      <td>48.017961</td>\n",
       "      <td>86.326297</td>\n",
       "      <td>[0.6078431372549019, 0.611764705882353, 0.6, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>66.134190</td>\n",
       "      <td>36.215671</td>\n",
       "      <td>29.301130</td>\n",
       "      <td>38.449759</td>\n",
       "      <td>58.079714</td>\n",
       "      <td>38.361572</td>\n",
       "      <td>74.188666</td>\n",
       "      <td>36.656610</td>\n",
       "      <td>36.797084</td>\n",
       "      <td>39.919554</td>\n",
       "      <td>...</td>\n",
       "      <td>62.807838</td>\n",
       "      <td>71.874864</td>\n",
       "      <td>71.162400</td>\n",
       "      <td>28.472350</td>\n",
       "      <td>73.372467</td>\n",
       "      <td>48.416204</td>\n",
       "      <td>77.366563</td>\n",
       "      <td>48.948751</td>\n",
       "      <td>81.999715</td>\n",
       "      <td>[0.5058823529411764, 0.27450980392156865, 0.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>65.483586</td>\n",
       "      <td>34.600717</td>\n",
       "      <td>28.867862</td>\n",
       "      <td>35.710262</td>\n",
       "      <td>59.935448</td>\n",
       "      <td>34.600717</td>\n",
       "      <td>71.401655</td>\n",
       "      <td>35.340414</td>\n",
       "      <td>35.524966</td>\n",
       "      <td>35.710262</td>\n",
       "      <td>...</td>\n",
       "      <td>42.737379</td>\n",
       "      <td>61.415172</td>\n",
       "      <td>70.846345</td>\n",
       "      <td>34.046069</td>\n",
       "      <td>71.586207</td>\n",
       "      <td>47.730207</td>\n",
       "      <td>59.011034</td>\n",
       "      <td>48.470069</td>\n",
       "      <td>76.764414</td>\n",
       "      <td>[0.1568627450980392, 0.16470588235294117, 0.14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>66.163575</td>\n",
       "      <td>35.678498</td>\n",
       "      <td>29.652217</td>\n",
       "      <td>39.500697</td>\n",
       "      <td>58.626091</td>\n",
       "      <td>38.378094</td>\n",
       "      <td>72.907218</td>\n",
       "      <td>36.594222</td>\n",
       "      <td>35.879997</td>\n",
       "      <td>41.131146</td>\n",
       "      <td>...</td>\n",
       "      <td>56.138759</td>\n",
       "      <td>63.705296</td>\n",
       "      <td>77.094084</td>\n",
       "      <td>36.651063</td>\n",
       "      <td>79.905554</td>\n",
       "      <td>49.327340</td>\n",
       "      <td>76.526858</td>\n",
       "      <td>49.450650</td>\n",
       "      <td>78.006579</td>\n",
       "      <td>[0.5294117647058824, 0.5294117647058824, 0.549...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>64.016263</td>\n",
       "      <td>34.724546</td>\n",
       "      <td>31.122081</td>\n",
       "      <td>37.467787</td>\n",
       "      <td>57.269372</td>\n",
       "      <td>36.108523</td>\n",
       "      <td>71.158575</td>\n",
       "      <td>34.600976</td>\n",
       "      <td>38.610388</td>\n",
       "      <td>37.789068</td>\n",
       "      <td>...</td>\n",
       "      <td>60.802689</td>\n",
       "      <td>63.200192</td>\n",
       "      <td>81.190748</td>\n",
       "      <td>35.871244</td>\n",
       "      <td>82.558335</td>\n",
       "      <td>51.233806</td>\n",
       "      <td>81.760576</td>\n",
       "      <td>51.598495</td>\n",
       "      <td>82.581128</td>\n",
       "      <td>[0.6823529411764706, 0.6078431372549019, 0.576...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>64.603001</td>\n",
       "      <td>37.483965</td>\n",
       "      <td>29.791182</td>\n",
       "      <td>40.781992</td>\n",
       "      <td>57.905137</td>\n",
       "      <td>38.598733</td>\n",
       "      <td>73.129331</td>\n",
       "      <td>37.232011</td>\n",
       "      <td>36.463336</td>\n",
       "      <td>40.629791</td>\n",
       "      <td>...</td>\n",
       "      <td>59.529116</td>\n",
       "      <td>66.393776</td>\n",
       "      <td>74.326374</td>\n",
       "      <td>33.083900</td>\n",
       "      <td>75.428884</td>\n",
       "      <td>51.427789</td>\n",
       "      <td>76.531394</td>\n",
       "      <td>51.404332</td>\n",
       "      <td>77.094378</td>\n",
       "      <td>[0.054901960784313725, 0.058823529411764705, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>65.537032</td>\n",
       "      <td>37.160826</td>\n",
       "      <td>30.592258</td>\n",
       "      <td>36.814839</td>\n",
       "      <td>60.001548</td>\n",
       "      <td>37.852800</td>\n",
       "      <td>71.073290</td>\n",
       "      <td>37.852800</td>\n",
       "      <td>35.781677</td>\n",
       "      <td>37.852800</td>\n",
       "      <td>...</td>\n",
       "      <td>57.574452</td>\n",
       "      <td>61.731097</td>\n",
       "      <td>77.642323</td>\n",
       "      <td>33.706065</td>\n",
       "      <td>76.258065</td>\n",
       "      <td>46.577806</td>\n",
       "      <td>72.213677</td>\n",
       "      <td>46.567742</td>\n",
       "      <td>84.692129</td>\n",
       "      <td>[0.7529411764705882, 0.7647058823529411, 0.756...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>66.636399</td>\n",
       "      <td>35.699413</td>\n",
       "      <td>31.299077</td>\n",
       "      <td>37.282863</td>\n",
       "      <td>57.663517</td>\n",
       "      <td>37.810679</td>\n",
       "      <td>72.764878</td>\n",
       "      <td>36.333321</td>\n",
       "      <td>38.187084</td>\n",
       "      <td>38.496841</td>\n",
       "      <td>...</td>\n",
       "      <td>58.133743</td>\n",
       "      <td>63.786700</td>\n",
       "      <td>73.496535</td>\n",
       "      <td>34.734869</td>\n",
       "      <td>76.703245</td>\n",
       "      <td>50.218011</td>\n",
       "      <td>75.458850</td>\n",
       "      <td>50.672694</td>\n",
       "      <td>76.798967</td>\n",
       "      <td>[0.11372549019607843, 0.0784313725490196, 0.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>65.989935</td>\n",
       "      <td>38.147303</td>\n",
       "      <td>28.968774</td>\n",
       "      <td>37.109342</td>\n",
       "      <td>59.762323</td>\n",
       "      <td>39.185342</td>\n",
       "      <td>71.525419</td>\n",
       "      <td>39.531329</td>\n",
       "      <td>33.812129</td>\n",
       "      <td>37.801316</td>\n",
       "      <td>...</td>\n",
       "      <td>51.165987</td>\n",
       "      <td>60.107613</td>\n",
       "      <td>77.244387</td>\n",
       "      <td>33.120774</td>\n",
       "      <td>76.898323</td>\n",
       "      <td>46.272000</td>\n",
       "      <td>71.218839</td>\n",
       "      <td>46.268129</td>\n",
       "      <td>85.202323</td>\n",
       "      <td>[0.7058823529411765, 0.7058823529411765, 0.705...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>66.254503</td>\n",
       "      <td>38.220018</td>\n",
       "      <td>30.844408</td>\n",
       "      <td>40.852014</td>\n",
       "      <td>59.771994</td>\n",
       "      <td>38.780536</td>\n",
       "      <td>73.784936</td>\n",
       "      <td>38.707425</td>\n",
       "      <td>38.886618</td>\n",
       "      <td>41.315050</td>\n",
       "      <td>...</td>\n",
       "      <td>59.911056</td>\n",
       "      <td>67.217521</td>\n",
       "      <td>76.338716</td>\n",
       "      <td>36.998308</td>\n",
       "      <td>77.031916</td>\n",
       "      <td>51.143932</td>\n",
       "      <td>80.216307</td>\n",
       "      <td>51.468870</td>\n",
       "      <td>81.104470</td>\n",
       "      <td>[0.08627450980392157, 0.08627450980392157, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>65.677452</td>\n",
       "      <td>35.232000</td>\n",
       "      <td>31.518573</td>\n",
       "      <td>38.511287</td>\n",
       "      <td>59.392204</td>\n",
       "      <td>37.417987</td>\n",
       "      <td>72.235414</td>\n",
       "      <td>35.778650</td>\n",
       "      <td>38.077146</td>\n",
       "      <td>39.057936</td>\n",
       "      <td>...</td>\n",
       "      <td>54.907108</td>\n",
       "      <td>68.410089</td>\n",
       "      <td>69.117554</td>\n",
       "      <td>35.891159</td>\n",
       "      <td>72.123516</td>\n",
       "      <td>50.920968</td>\n",
       "      <td>66.930955</td>\n",
       "      <td>51.740331</td>\n",
       "      <td>78.681478</td>\n",
       "      <td>[0.9333333333333333, 0.9254901960784314, 0.921...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2111</th>\n",
       "      <td>64.595178</td>\n",
       "      <td>37.784219</td>\n",
       "      <td>30.230795</td>\n",
       "      <td>37.283836</td>\n",
       "      <td>57.422137</td>\n",
       "      <td>38.284603</td>\n",
       "      <td>73.103014</td>\n",
       "      <td>36.950137</td>\n",
       "      <td>37.904219</td>\n",
       "      <td>37.450521</td>\n",
       "      <td>...</td>\n",
       "      <td>61.972932</td>\n",
       "      <td>68.265205</td>\n",
       "      <td>72.649315</td>\n",
       "      <td>26.060384</td>\n",
       "      <td>71.481534</td>\n",
       "      <td>47.579836</td>\n",
       "      <td>74.984877</td>\n",
       "      <td>47.079452</td>\n",
       "      <td>87.829808</td>\n",
       "      <td>[0.9882352941176471, 1.0, 0.6352941176470588, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2112</th>\n",
       "      <td>68.518902</td>\n",
       "      <td>42.963451</td>\n",
       "      <td>32.345725</td>\n",
       "      <td>33.990275</td>\n",
       "      <td>61.508392</td>\n",
       "      <td>41.842196</td>\n",
       "      <td>73.005176</td>\n",
       "      <td>45.206588</td>\n",
       "      <td>38.234353</td>\n",
       "      <td>35.673098</td>\n",
       "      <td>...</td>\n",
       "      <td>49.693490</td>\n",
       "      <td>55.339294</td>\n",
       "      <td>76.052078</td>\n",
       "      <td>28.139294</td>\n",
       "      <td>69.882980</td>\n",
       "      <td>44.964392</td>\n",
       "      <td>65.396706</td>\n",
       "      <td>41.318902</td>\n",
       "      <td>78.015373</td>\n",
       "      <td>[0.5803921568627451, 0.5803921568627451, 0.584...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113</th>\n",
       "      <td>63.996901</td>\n",
       "      <td>34.344955</td>\n",
       "      <td>32.309927</td>\n",
       "      <td>41.225873</td>\n",
       "      <td>56.510827</td>\n",
       "      <td>37.613006</td>\n",
       "      <td>71.987182</td>\n",
       "      <td>32.764325</td>\n",
       "      <td>38.318445</td>\n",
       "      <td>40.850241</td>\n",
       "      <td>...</td>\n",
       "      <td>61.261017</td>\n",
       "      <td>69.804855</td>\n",
       "      <td>70.991522</td>\n",
       "      <td>37.481168</td>\n",
       "      <td>77.383535</td>\n",
       "      <td>51.123635</td>\n",
       "      <td>76.489169</td>\n",
       "      <td>51.345149</td>\n",
       "      <td>80.334818</td>\n",
       "      <td>[0.35294117647058826, 0.34901960784313724, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>69.231582</td>\n",
       "      <td>39.570384</td>\n",
       "      <td>32.892166</td>\n",
       "      <td>36.837849</td>\n",
       "      <td>57.634409</td>\n",
       "      <td>40.233487</td>\n",
       "      <td>77.493088</td>\n",
       "      <td>41.265745</td>\n",
       "      <td>39.274962</td>\n",
       "      <td>39.840246</td>\n",
       "      <td>...</td>\n",
       "      <td>61.146721</td>\n",
       "      <td>63.584756</td>\n",
       "      <td>80.359160</td>\n",
       "      <td>27.540926</td>\n",
       "      <td>77.650501</td>\n",
       "      <td>42.960427</td>\n",
       "      <td>79.898764</td>\n",
       "      <td>42.542608</td>\n",
       "      <td>82.903080</td>\n",
       "      <td>[0.3333333333333333, 0.35294117647058826, 0.34...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>64.837120</td>\n",
       "      <td>34.638784</td>\n",
       "      <td>32.231040</td>\n",
       "      <td>38.929088</td>\n",
       "      <td>59.402880</td>\n",
       "      <td>35.210816</td>\n",
       "      <td>70.271360</td>\n",
       "      <td>34.066752</td>\n",
       "      <td>37.093120</td>\n",
       "      <td>37.212992</td>\n",
       "      <td>...</td>\n",
       "      <td>44.363520</td>\n",
       "      <td>67.411200</td>\n",
       "      <td>66.673280</td>\n",
       "      <td>37.379200</td>\n",
       "      <td>70.391680</td>\n",
       "      <td>50.822400</td>\n",
       "      <td>62.382720</td>\n",
       "      <td>51.393920</td>\n",
       "      <td>70.963200</td>\n",
       "      <td>[0.9568627450980393, 0.9411764705882353, 0.874...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>69.839934</td>\n",
       "      <td>33.257805</td>\n",
       "      <td>26.071373</td>\n",
       "      <td>34.111969</td>\n",
       "      <td>61.592830</td>\n",
       "      <td>36.792278</td>\n",
       "      <td>78.113547</td>\n",
       "      <td>34.946694</td>\n",
       "      <td>34.289024</td>\n",
       "      <td>37.351903</td>\n",
       "      <td>...</td>\n",
       "      <td>63.767384</td>\n",
       "      <td>66.599347</td>\n",
       "      <td>79.611252</td>\n",
       "      <td>31.628029</td>\n",
       "      <td>80.026034</td>\n",
       "      <td>48.582249</td>\n",
       "      <td>81.996249</td>\n",
       "      <td>48.504477</td>\n",
       "      <td>84.303475</td>\n",
       "      <td>[0.8549019607843137, 0.8431372549019608, 0.850...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>62.383349</td>\n",
       "      <td>42.238789</td>\n",
       "      <td>29.105771</td>\n",
       "      <td>40.252791</td>\n",
       "      <td>56.995482</td>\n",
       "      <td>42.656333</td>\n",
       "      <td>72.115224</td>\n",
       "      <td>43.769461</td>\n",
       "      <td>38.890445</td>\n",
       "      <td>41.366887</td>\n",
       "      <td>...</td>\n",
       "      <td>62.624247</td>\n",
       "      <td>65.081148</td>\n",
       "      <td>78.085298</td>\n",
       "      <td>29.461616</td>\n",
       "      <td>77.525616</td>\n",
       "      <td>50.776512</td>\n",
       "      <td>79.674702</td>\n",
       "      <td>51.136777</td>\n",
       "      <td>80.268079</td>\n",
       "      <td>[0.0392156862745098, 0.027450980392156862, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118</th>\n",
       "      <td>65.308022</td>\n",
       "      <td>37.972411</td>\n",
       "      <td>28.088043</td>\n",
       "      <td>37.642897</td>\n",
       "      <td>58.061838</td>\n",
       "      <td>36.984389</td>\n",
       "      <td>73.213232</td>\n",
       "      <td>38.630919</td>\n",
       "      <td>37.310789</td>\n",
       "      <td>36.984389</td>\n",
       "      <td>...</td>\n",
       "      <td>53.453319</td>\n",
       "      <td>61.355416</td>\n",
       "      <td>74.204368</td>\n",
       "      <td>31.052627</td>\n",
       "      <td>74.533881</td>\n",
       "      <td>47.192043</td>\n",
       "      <td>72.227805</td>\n",
       "      <td>45.874508</td>\n",
       "      <td>81.780065</td>\n",
       "      <td>[0.4117647058823529, 0.36470588235294116, 0.31...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>71.017401</td>\n",
       "      <td>36.537853</td>\n",
       "      <td>28.658079</td>\n",
       "      <td>35.751412</td>\n",
       "      <td>61.634350</td>\n",
       "      <td>37.324294</td>\n",
       "      <td>77.227571</td>\n",
       "      <td>37.731073</td>\n",
       "      <td>34.298757</td>\n",
       "      <td>36.700565</td>\n",
       "      <td>...</td>\n",
       "      <td>63.385580</td>\n",
       "      <td>63.863012</td>\n",
       "      <td>86.160987</td>\n",
       "      <td>26.466911</td>\n",
       "      <td>86.434579</td>\n",
       "      <td>45.503978</td>\n",
       "      <td>84.614597</td>\n",
       "      <td>45.618356</td>\n",
       "      <td>85.758377</td>\n",
       "      <td>[0.4470588235294118, 0.16470588235294117, 0.18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2120</th>\n",
       "      <td>64.957762</td>\n",
       "      <td>38.197259</td>\n",
       "      <td>30.754909</td>\n",
       "      <td>36.097343</td>\n",
       "      <td>58.657343</td>\n",
       "      <td>39.097510</td>\n",
       "      <td>71.258182</td>\n",
       "      <td>38.797427</td>\n",
       "      <td>37.055329</td>\n",
       "      <td>37.597091</td>\n",
       "      <td>...</td>\n",
       "      <td>57.824895</td>\n",
       "      <td>57.457007</td>\n",
       "      <td>80.500364</td>\n",
       "      <td>34.655329</td>\n",
       "      <td>78.999944</td>\n",
       "      <td>47.256168</td>\n",
       "      <td>72.099357</td>\n",
       "      <td>46.355916</td>\n",
       "      <td>87.400951</td>\n",
       "      <td>[0.5098039215686274, 0.4666666666666667, 0.415...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>65.151634</td>\n",
       "      <td>35.893303</td>\n",
       "      <td>28.904229</td>\n",
       "      <td>38.142994</td>\n",
       "      <td>57.152091</td>\n",
       "      <td>37.393097</td>\n",
       "      <td>71.651109</td>\n",
       "      <td>37.143223</td>\n",
       "      <td>37.403520</td>\n",
       "      <td>39.143040</td>\n",
       "      <td>...</td>\n",
       "      <td>58.391589</td>\n",
       "      <td>63.151817</td>\n",
       "      <td>75.890469</td>\n",
       "      <td>33.153737</td>\n",
       "      <td>76.890240</td>\n",
       "      <td>48.152777</td>\n",
       "      <td>73.640503</td>\n",
       "      <td>48.152777</td>\n",
       "      <td>81.389897</td>\n",
       "      <td>[1.0, 0.9882352941176471, 1.0, 0.6352941176470...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>66.142171</td>\n",
       "      <td>38.460343</td>\n",
       "      <td>28.959086</td>\n",
       "      <td>38.460343</td>\n",
       "      <td>60.012800</td>\n",
       "      <td>38.051657</td>\n",
       "      <td>72.680229</td>\n",
       "      <td>39.277714</td>\n",
       "      <td>34.679771</td>\n",
       "      <td>38.051657</td>\n",
       "      <td>...</td>\n",
       "      <td>53.578971</td>\n",
       "      <td>63.690971</td>\n",
       "      <td>75.643429</td>\n",
       "      <td>34.679771</td>\n",
       "      <td>75.643429</td>\n",
       "      <td>47.346286</td>\n",
       "      <td>70.331429</td>\n",
       "      <td>48.572343</td>\n",
       "      <td>84.632686</td>\n",
       "      <td>[0.3843137254901961, 0.3803921568627451, 0.376...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>62.618245</td>\n",
       "      <td>37.040737</td>\n",
       "      <td>30.518331</td>\n",
       "      <td>37.658037</td>\n",
       "      <td>57.062676</td>\n",
       "      <td>38.275338</td>\n",
       "      <td>67.557065</td>\n",
       "      <td>37.040737</td>\n",
       "      <td>35.147741</td>\n",
       "      <td>38.583988</td>\n",
       "      <td>...</td>\n",
       "      <td>60.498509</td>\n",
       "      <td>62.309525</td>\n",
       "      <td>71.918504</td>\n",
       "      <td>30.209612</td>\n",
       "      <td>71.918504</td>\n",
       "      <td>46.259568</td>\n",
       "      <td>68.523281</td>\n",
       "      <td>46.568288</td>\n",
       "      <td>77.783482</td>\n",
       "      <td>[0.996078431372549, 0.9921568627450981, 0.9960...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>64.200000</td>\n",
       "      <td>38.685333</td>\n",
       "      <td>31.545600</td>\n",
       "      <td>36.540267</td>\n",
       "      <td>58.479467</td>\n",
       "      <td>38.923733</td>\n",
       "      <td>71.350400</td>\n",
       "      <td>40.353600</td>\n",
       "      <td>37.266133</td>\n",
       "      <td>37.017067</td>\n",
       "      <td>...</td>\n",
       "      <td>58.468267</td>\n",
       "      <td>57.764267</td>\n",
       "      <td>69.909333</td>\n",
       "      <td>34.644267</td>\n",
       "      <td>67.764267</td>\n",
       "      <td>46.561600</td>\n",
       "      <td>65.857067</td>\n",
       "      <td>45.608533</td>\n",
       "      <td>73.722667</td>\n",
       "      <td>[0.6549019607843137, 0.6627450980392157, 0.678...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>68.282904</td>\n",
       "      <td>38.892841</td>\n",
       "      <td>28.385427</td>\n",
       "      <td>36.433529</td>\n",
       "      <td>61.451006</td>\n",
       "      <td>39.439490</td>\n",
       "      <td>73.474854</td>\n",
       "      <td>39.712815</td>\n",
       "      <td>34.944000</td>\n",
       "      <td>37.800153</td>\n",
       "      <td>...</td>\n",
       "      <td>59.934573</td>\n",
       "      <td>61.177682</td>\n",
       "      <td>72.505070</td>\n",
       "      <td>28.112102</td>\n",
       "      <td>70.591796</td>\n",
       "      <td>46.694522</td>\n",
       "      <td>70.591796</td>\n",
       "      <td>46.147873</td>\n",
       "      <td>83.162293</td>\n",
       "      <td>[0.027450980392156862, 0.050980392156862744, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>65.294400</td>\n",
       "      <td>37.934827</td>\n",
       "      <td>32.640533</td>\n",
       "      <td>36.266347</td>\n",
       "      <td>60.050667</td>\n",
       "      <td>38.411520</td>\n",
       "      <td>71.014933</td>\n",
       "      <td>38.411520</td>\n",
       "      <td>38.598933</td>\n",
       "      <td>37.219733</td>\n",
       "      <td>...</td>\n",
       "      <td>55.334400</td>\n",
       "      <td>63.387733</td>\n",
       "      <td>74.402667</td>\n",
       "      <td>31.210133</td>\n",
       "      <td>73.687467</td>\n",
       "      <td>47.179733</td>\n",
       "      <td>68.682133</td>\n",
       "      <td>47.179733</td>\n",
       "      <td>82.268267</td>\n",
       "      <td>[0.9490196078431372, 0.9450980392156862, 0.945...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>65.918849</td>\n",
       "      <td>39.034014</td>\n",
       "      <td>31.966619</td>\n",
       "      <td>36.564259</td>\n",
       "      <td>59.745151</td>\n",
       "      <td>39.650763</td>\n",
       "      <td>72.400576</td>\n",
       "      <td>39.650763</td>\n",
       "      <td>38.448345</td>\n",
       "      <td>37.490417</td>\n",
       "      <td>...</td>\n",
       "      <td>58.787914</td>\n",
       "      <td>62.523626</td>\n",
       "      <td>75.764029</td>\n",
       "      <td>30.731741</td>\n",
       "      <td>73.911712</td>\n",
       "      <td>46.781698</td>\n",
       "      <td>69.899050</td>\n",
       "      <td>45.856230</td>\n",
       "      <td>81.937036</td>\n",
       "      <td>[0.7725490196078432, 0.7725490196078432, 0.772...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>65.878430</td>\n",
       "      <td>38.828860</td>\n",
       "      <td>28.188112</td>\n",
       "      <td>36.824523</td>\n",
       "      <td>60.264673</td>\n",
       "      <td>38.828860</td>\n",
       "      <td>71.893234</td>\n",
       "      <td>38.828860</td>\n",
       "      <td>33.800972</td>\n",
       "      <td>37.626617</td>\n",
       "      <td>...</td>\n",
       "      <td>60.138168</td>\n",
       "      <td>61.467813</td>\n",
       "      <td>74.915888</td>\n",
       "      <td>31.796636</td>\n",
       "      <td>74.514841</td>\n",
       "      <td>47.032822</td>\n",
       "      <td>72.510505</td>\n",
       "      <td>47.433869</td>\n",
       "      <td>80.930692</td>\n",
       "      <td>[0.2784313725490196, 0.24705882352941178, 0.32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>65.216509</td>\n",
       "      <td>31.811910</td>\n",
       "      <td>32.605888</td>\n",
       "      <td>39.122837</td>\n",
       "      <td>56.801133</td>\n",
       "      <td>36.053331</td>\n",
       "      <td>73.127738</td>\n",
       "      <td>30.415811</td>\n",
       "      <td>39.376455</td>\n",
       "      <td>39.984509</td>\n",
       "      <td>...</td>\n",
       "      <td>57.279699</td>\n",
       "      <td>71.809215</td>\n",
       "      <td>71.742867</td>\n",
       "      <td>40.589246</td>\n",
       "      <td>76.323626</td>\n",
       "      <td>55.380075</td>\n",
       "      <td>75.756754</td>\n",
       "      <td>55.644819</td>\n",
       "      <td>79.070251</td>\n",
       "      <td>[0.39215686274509803, 0.39215686274509803, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>67.671771</td>\n",
       "      <td>34.955794</td>\n",
       "      <td>30.898286</td>\n",
       "      <td>34.036457</td>\n",
       "      <td>61.849371</td>\n",
       "      <td>35.262309</td>\n",
       "      <td>73.188343</td>\n",
       "      <td>35.875200</td>\n",
       "      <td>37.333714</td>\n",
       "      <td>35.262309</td>\n",
       "      <td>...</td>\n",
       "      <td>53.649600</td>\n",
       "      <td>62.155886</td>\n",
       "      <td>76.020343</td>\n",
       "      <td>35.494629</td>\n",
       "      <td>74.794286</td>\n",
       "      <td>48.365486</td>\n",
       "      <td>71.116800</td>\n",
       "      <td>48.365486</td>\n",
       "      <td>80.923200</td>\n",
       "      <td>[0.7215686274509804, 0.7294117647058823, 0.733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>64.789807</td>\n",
       "      <td>36.317367</td>\n",
       "      <td>31.209965</td>\n",
       "      <td>36.108364</td>\n",
       "      <td>58.008815</td>\n",
       "      <td>37.524941</td>\n",
       "      <td>70.549006</td>\n",
       "      <td>36.038696</td>\n",
       "      <td>36.295709</td>\n",
       "      <td>37.269493</td>\n",
       "      <td>...</td>\n",
       "      <td>62.670537</td>\n",
       "      <td>61.504143</td>\n",
       "      <td>78.493107</td>\n",
       "      <td>33.199243</td>\n",
       "      <td>78.284958</td>\n",
       "      <td>47.124772</td>\n",
       "      <td>79.169125</td>\n",
       "      <td>47.206464</td>\n",
       "      <td>80.326629</td>\n",
       "      <td>[0.00784313725490196, 0.00784313725490196, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>70.453782</td>\n",
       "      <td>35.399760</td>\n",
       "      <td>33.190876</td>\n",
       "      <td>37.576631</td>\n",
       "      <td>61.054822</td>\n",
       "      <td>37.986395</td>\n",
       "      <td>77.332693</td>\n",
       "      <td>33.552749</td>\n",
       "      <td>41.104442</td>\n",
       "      <td>38.959584</td>\n",
       "      <td>...</td>\n",
       "      <td>61.537104</td>\n",
       "      <td>62.098119</td>\n",
       "      <td>70.957183</td>\n",
       "      <td>25.978711</td>\n",
       "      <td>72.758864</td>\n",
       "      <td>46.719488</td>\n",
       "      <td>73.359424</td>\n",
       "      <td>45.368227</td>\n",
       "      <td>83.032733</td>\n",
       "      <td>[0.11764705882352941, 0.10980392156862745, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>67.331615</td>\n",
       "      <td>37.120890</td>\n",
       "      <td>30.969166</td>\n",
       "      <td>39.419665</td>\n",
       "      <td>56.712927</td>\n",
       "      <td>39.795393</td>\n",
       "      <td>72.634473</td>\n",
       "      <td>37.355992</td>\n",
       "      <td>36.193656</td>\n",
       "      <td>40.464563</td>\n",
       "      <td>...</td>\n",
       "      <td>61.228919</td>\n",
       "      <td>64.187779</td>\n",
       "      <td>74.325939</td>\n",
       "      <td>30.419251</td>\n",
       "      <td>74.686807</td>\n",
       "      <td>46.560804</td>\n",
       "      <td>76.983614</td>\n",
       "      <td>46.747826</td>\n",
       "      <td>78.548387</td>\n",
       "      <td>[0.17647058823529413, 0.2, 0.20392156862745098...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>65.701053</td>\n",
       "      <td>37.328000</td>\n",
       "      <td>24.303158</td>\n",
       "      <td>39.586526</td>\n",
       "      <td>58.550737</td>\n",
       "      <td>38.080842</td>\n",
       "      <td>73.980632</td>\n",
       "      <td>36.951579</td>\n",
       "      <td>31.453474</td>\n",
       "      <td>39.210105</td>\n",
       "      <td>...</td>\n",
       "      <td>51.253053</td>\n",
       "      <td>66.077474</td>\n",
       "      <td>78.349474</td>\n",
       "      <td>31.453474</td>\n",
       "      <td>80.608000</td>\n",
       "      <td>46.883368</td>\n",
       "      <td>70.822737</td>\n",
       "      <td>48.765474</td>\n",
       "      <td>86.252632</td>\n",
       "      <td>[0.14901960784313725, 0.12941176470588237, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>65.039859</td>\n",
       "      <td>36.251247</td>\n",
       "      <td>28.020559</td>\n",
       "      <td>37.465860</td>\n",
       "      <td>57.000175</td>\n",
       "      <td>37.966492</td>\n",
       "      <td>72.882036</td>\n",
       "      <td>37.756311</td>\n",
       "      <td>35.202620</td>\n",
       "      <td>38.970925</td>\n",
       "      <td>...</td>\n",
       "      <td>61.261376</td>\n",
       "      <td>64.381940</td>\n",
       "      <td>73.795596</td>\n",
       "      <td>28.765916</td>\n",
       "      <td>74.572255</td>\n",
       "      <td>47.102424</td>\n",
       "      <td>76.254251</td>\n",
       "      <td>47.033489</td>\n",
       "      <td>77.104440</td>\n",
       "      <td>[0.11372549019607843, 0.10196078431372549, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>67.386832</td>\n",
       "      <td>43.982609</td>\n",
       "      <td>28.986832</td>\n",
       "      <td>35.091180</td>\n",
       "      <td>61.101118</td>\n",
       "      <td>44.142609</td>\n",
       "      <td>76.598261</td>\n",
       "      <td>49.422609</td>\n",
       "      <td>38.472547</td>\n",
       "      <td>38.908323</td>\n",
       "      <td>...</td>\n",
       "      <td>54.733913</td>\n",
       "      <td>57.318048</td>\n",
       "      <td>88.512085</td>\n",
       "      <td>21.157054</td>\n",
       "      <td>79.725146</td>\n",
       "      <td>43.033043</td>\n",
       "      <td>77.715280</td>\n",
       "      <td>38.083123</td>\n",
       "      <td>91.435528</td>\n",
       "      <td>[0.2627450980392157, 0.2627450980392157, 0.262...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>65.340468</td>\n",
       "      <td>36.966234</td>\n",
       "      <td>31.630753</td>\n",
       "      <td>36.688208</td>\n",
       "      <td>59.211429</td>\n",
       "      <td>38.916779</td>\n",
       "      <td>72.026805</td>\n",
       "      <td>38.359481</td>\n",
       "      <td>37.481143</td>\n",
       "      <td>39.195429</td>\n",
       "      <td>...</td>\n",
       "      <td>55.353351</td>\n",
       "      <td>62.275948</td>\n",
       "      <td>79.034182</td>\n",
       "      <td>32.188052</td>\n",
       "      <td>77.362286</td>\n",
       "      <td>47.449558</td>\n",
       "      <td>72.938805</td>\n",
       "      <td>47.510649</td>\n",
       "      <td>83.212675</td>\n",
       "      <td>[0.4823529411764706, 0.48627450980392156, 0.48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2138</th>\n",
       "      <td>64.407877</td>\n",
       "      <td>34.752960</td>\n",
       "      <td>30.085662</td>\n",
       "      <td>34.422942</td>\n",
       "      <td>59.127877</td>\n",
       "      <td>35.082978</td>\n",
       "      <td>70.678892</td>\n",
       "      <td>35.082978</td>\n",
       "      <td>36.025846</td>\n",
       "      <td>35.743015</td>\n",
       "      <td>...</td>\n",
       "      <td>50.264123</td>\n",
       "      <td>62.428062</td>\n",
       "      <td>71.055508</td>\n",
       "      <td>36.025846</td>\n",
       "      <td>71.715692</td>\n",
       "      <td>47.906954</td>\n",
       "      <td>65.775508</td>\n",
       "      <td>47.576862</td>\n",
       "      <td>77.985969</td>\n",
       "      <td>[0.7725490196078432, 0.7764705882352941, 0.776...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>67.837594</td>\n",
       "      <td>37.900752</td>\n",
       "      <td>32.052692</td>\n",
       "      <td>32.525474</td>\n",
       "      <td>58.750877</td>\n",
       "      <td>38.209524</td>\n",
       "      <td>76.192080</td>\n",
       "      <td>39.801464</td>\n",
       "      <td>38.460150</td>\n",
       "      <td>35.629073</td>\n",
       "      <td>...</td>\n",
       "      <td>63.235231</td>\n",
       "      <td>59.191407</td>\n",
       "      <td>78.752023</td>\n",
       "      <td>27.968493</td>\n",
       "      <td>72.951235</td>\n",
       "      <td>40.006874</td>\n",
       "      <td>79.381024</td>\n",
       "      <td>39.832152</td>\n",
       "      <td>81.023416</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2140 rows  31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      left_eye_center_x  left_eye_center_y  right_eye_center_x  \\\n",
       "0             66.328960          36.912768           32.007040   \n",
       "1             64.918419          38.881725           28.223425   \n",
       "2             67.690269          35.696894           29.502277   \n",
       "3             65.265185          35.172741           29.512889   \n",
       "4             62.477241          41.666207           27.873103   \n",
       "5             65.476354          39.960816           30.590259   \n",
       "6             68.143680          40.385280           29.429440   \n",
       "7             63.812741          36.945185           31.237926   \n",
       "8             59.210904          34.925801           30.399355   \n",
       "9             67.295312          34.149161           30.030452   \n",
       "10            67.569951          37.167805           28.590439   \n",
       "11            65.718621          38.017655           29.472828   \n",
       "12            66.454252          39.431841           30.444079   \n",
       "13            64.332493          34.607277           32.889863   \n",
       "14            65.268000          37.630857           31.813714   \n",
       "15            67.728819          35.194648           27.803959   \n",
       "16            65.848167          32.065800           28.089537   \n",
       "17            67.042909          39.317950           28.749223   \n",
       "18            66.761855          41.286311           26.704609   \n",
       "19            64.918095          38.856686           30.528000   \n",
       "20            66.562684          35.949832           30.302555   \n",
       "21            66.134190          36.215671           29.301130   \n",
       "22            65.483586          34.600717           28.867862   \n",
       "23            66.163575          35.678498           29.652217   \n",
       "24            64.016263          34.724546           31.122081   \n",
       "25            64.603001          37.483965           29.791182   \n",
       "26            65.537032          37.160826           30.592258   \n",
       "27            66.636399          35.699413           31.299077   \n",
       "28            65.989935          38.147303           28.968774   \n",
       "29            66.254503          38.220018           30.844408   \n",
       "...                 ...                ...                 ...   \n",
       "2110          65.677452          35.232000           31.518573   \n",
       "2111          64.595178          37.784219           30.230795   \n",
       "2112          68.518902          42.963451           32.345725   \n",
       "2113          63.996901          34.344955           32.309927   \n",
       "2114          69.231582          39.570384           32.892166   \n",
       "2115          64.837120          34.638784           32.231040   \n",
       "2116          69.839934          33.257805           26.071373   \n",
       "2117          62.383349          42.238789           29.105771   \n",
       "2118          65.308022          37.972411           28.088043   \n",
       "2119          71.017401          36.537853           28.658079   \n",
       "2120          64.957762          38.197259           30.754909   \n",
       "2121          65.151634          35.893303           28.904229   \n",
       "2122          66.142171          38.460343           28.959086   \n",
       "2123          62.618245          37.040737           30.518331   \n",
       "2124          64.200000          38.685333           31.545600   \n",
       "2125          68.282904          38.892841           28.385427   \n",
       "2126          65.294400          37.934827           32.640533   \n",
       "2127          65.918849          39.034014           31.966619   \n",
       "2128          65.878430          38.828860           28.188112   \n",
       "2129          65.216509          31.811910           32.605888   \n",
       "2130          67.671771          34.955794           30.898286   \n",
       "2131          64.789807          36.317367           31.209965   \n",
       "2132          70.453782          35.399760           33.190876   \n",
       "2133          67.331615          37.120890           30.969166   \n",
       "2134          65.701053          37.328000           24.303158   \n",
       "2135          65.039859          36.251247           28.020559   \n",
       "2136          67.386832          43.982609           28.986832   \n",
       "2137          65.340468          36.966234           31.630753   \n",
       "2138          64.407877          34.752960           30.085662   \n",
       "2139          67.837594          37.900752           32.052692   \n",
       "\n",
       "      right_eye_center_y  left_eye_inner_corner_x  left_eye_inner_corner_y  \\\n",
       "0              35.196608                59.751040                38.342848   \n",
       "1              36.297772                58.457677                39.399090   \n",
       "2              37.127950                60.322981                36.359420   \n",
       "3              33.319111                59.173926                36.232296   \n",
       "4              34.604138                58.637241                40.960000   \n",
       "5              35.764680                59.183673                40.359184   \n",
       "6              38.747520                60.996480                40.832000   \n",
       "7              36.680296                59.045333                36.945185   \n",
       "8              42.995118                53.374645                37.602033   \n",
       "9              35.695484                57.399398                36.159312   \n",
       "10             35.860098                60.506341                36.906146   \n",
       "11             37.277793                59.060690                37.647724   \n",
       "12             36.860185                60.738119                39.717934   \n",
       "13             37.251945                59.630466                35.488833   \n",
       "14             37.375429                60.416000                37.630857   \n",
       "15             34.399126                59.616328                34.717270   \n",
       "16             39.300468                58.094677                36.245190   \n",
       "17             38.254017                60.011901                39.095008   \n",
       "18             42.826962                60.497273                41.609855   \n",
       "19             38.856686                59.470476                39.197181   \n",
       "20             35.119277                59.366400                36.503535   \n",
       "21             38.449759                58.079714                38.361572   \n",
       "22             35.710262                59.935448                34.600717   \n",
       "23             39.500697                58.626091                38.378094   \n",
       "24             37.467787                57.269372                36.108523   \n",
       "25             40.781992                57.905137                38.598733   \n",
       "26             36.814839                60.001548                37.852800   \n",
       "27             37.282863                57.663517                37.810679   \n",
       "28             37.109342                59.762323                39.185342   \n",
       "29             40.852014                59.771994                38.780536   \n",
       "...                  ...                      ...                      ...   \n",
       "2110           38.511287                59.392204                37.417987   \n",
       "2111           37.283836                57.422137                38.284603   \n",
       "2112           33.990275                61.508392                41.842196   \n",
       "2113           41.225873                56.510827                37.613006   \n",
       "2114           36.837849                57.634409                40.233487   \n",
       "2115           38.929088                59.402880                35.210816   \n",
       "2116           34.111969                61.592830                36.792278   \n",
       "2117           40.252791                56.995482                42.656333   \n",
       "2118           37.642897                58.061838                36.984389   \n",
       "2119           35.751412                61.634350                37.324294   \n",
       "2120           36.097343                58.657343                39.097510   \n",
       "2121           38.142994                57.152091                37.393097   \n",
       "2122           38.460343                60.012800                38.051657   \n",
       "2123           37.658037                57.062676                38.275338   \n",
       "2124           36.540267                58.479467                38.923733   \n",
       "2125           36.433529                61.451006                39.439490   \n",
       "2126           36.266347                60.050667                38.411520   \n",
       "2127           36.564259                59.745151                39.650763   \n",
       "2128           36.824523                60.264673                38.828860   \n",
       "2129           39.122837                56.801133                36.053331   \n",
       "2130           34.036457                61.849371                35.262309   \n",
       "2131           36.108364                58.008815                37.524941   \n",
       "2132           37.576631                61.054822                37.986395   \n",
       "2133           39.419665                56.712927                39.795393   \n",
       "2134           39.586526                58.550737                38.080842   \n",
       "2135           37.465860                57.000175                37.966492   \n",
       "2136           35.091180                61.101118                44.142609   \n",
       "2137           36.688208                59.211429                38.916779   \n",
       "2138           34.422942                59.127877                35.082978   \n",
       "2139           32.525474                58.750877                38.209524   \n",
       "\n",
       "      left_eye_outer_corner_x  left_eye_outer_corner_y  \\\n",
       "0                   71.477760                37.198784   \n",
       "1                   71.378587                39.915880   \n",
       "2                   75.983503                37.477234   \n",
       "3                   70.826667                36.497185   \n",
       "4                   72.376497                44.003752   \n",
       "5                   72.593197                41.142857   \n",
       "6                   76.035200                42.470080   \n",
       "7                   69.639111                37.474963   \n",
       "8                   64.831565                33.696265   \n",
       "9                   77.346065                35.076817   \n",
       "10                  73.325268                37.952780   \n",
       "11                  71.265931                37.647724   \n",
       "12                  73.027391                40.575576   \n",
       "13                  69.033863                34.313359   \n",
       "14                  72.418857                38.907429   \n",
       "15                  76.967427                36.511126   \n",
       "16                  73.716950                31.028158   \n",
       "17                  72.360992                40.027240   \n",
       "18                  74.983972                42.062616   \n",
       "19                  70.707048                39.197181   \n",
       "20                  72.099097                35.949832   \n",
       "21                  74.188666                36.656610   \n",
       "22                  71.401655                35.340414   \n",
       "23                  72.907218                36.594222   \n",
       "24                  71.158575                34.600976   \n",
       "25                  73.129331                37.232011   \n",
       "26                  71.073290                37.852800   \n",
       "27                  72.764878                36.333321   \n",
       "28                  71.525419                39.531329   \n",
       "29                  73.784936                38.707425   \n",
       "...                       ...                      ...   \n",
       "2110                72.235414                35.778650   \n",
       "2111                73.103014                36.950137   \n",
       "2112                73.005176                45.206588   \n",
       "2113                71.987182                32.764325   \n",
       "2114                77.493088                41.265745   \n",
       "2115                70.271360                34.066752   \n",
       "2116                78.113547                34.946694   \n",
       "2117                72.115224                43.769461   \n",
       "2118                73.213232                38.630919   \n",
       "2119                77.227571                37.731073   \n",
       "2120                71.258182                38.797427   \n",
       "2121                71.651109                37.143223   \n",
       "2122                72.680229                39.277714   \n",
       "2123                67.557065                37.040737   \n",
       "2124                71.350400                40.353600   \n",
       "2125                73.474854                39.712815   \n",
       "2126                71.014933                38.411520   \n",
       "2127                72.400576                39.650763   \n",
       "2128                71.893234                38.828860   \n",
       "2129                73.127738                30.415811   \n",
       "2130                73.188343                35.875200   \n",
       "2131                70.549006                36.038696   \n",
       "2132                77.332693                33.552749   \n",
       "2133                72.634473                37.355992   \n",
       "2134                73.980632                36.951579   \n",
       "2135                72.882036                37.756311   \n",
       "2136                76.598261                49.422609   \n",
       "2137                72.026805                38.359481   \n",
       "2138                70.678892                35.082978   \n",
       "2139                76.192080                39.801464   \n",
       "\n",
       "      right_eye_inner_corner_x  right_eye_inner_corner_y  ...  nose_tip_y  \\\n",
       "0                    36.869120                 36.912768  ...   62.940800   \n",
       "1                    33.908695                 37.331353  ...   59.813174   \n",
       "2                    39.095652                 37.684472  ...   60.597097   \n",
       "3                    35.604148                 34.113778  ...   55.829926   \n",
       "4                    39.313655                 37.846069  ...   55.906545   \n",
       "5                    35.804082                 36.457143  ...   55.580952   \n",
       "6                    37.618880                 39.491840  ...   57.509120   \n",
       "7                    36.269630                 37.210074  ...   59.985778   \n",
       "8                    36.809501                 42.665471  ...   56.709023   \n",
       "9                    39.617376                 36.623140  ...   59.817290   \n",
       "10                   34.607415                 36.383415  ...   52.341073   \n",
       "11                   35.020138                 38.017655  ...   55.030345   \n",
       "12                   36.160212                 37.431735  ...   60.294993   \n",
       "13                   37.591233                 37.545797  ...   60.466849   \n",
       "14                   36.921714                 37.375429  ...   60.869714   \n",
       "15                   37.029461                 35.035413  ...   58.848000   \n",
       "16                   36.275378                 40.395757  ...   54.491308   \n",
       "17                   35.840529                 38.254017  ...   54.955636   \n",
       "18                   35.446920                 42.515377  ...   60.698574   \n",
       "19                   35.975619                 39.537676  ...   57.584000   \n",
       "20                   36.115819                 35.396067  ...   59.292697   \n",
       "21                   36.797084                 39.919554  ...   62.807838   \n",
       "22                   35.524966                 35.710262  ...   42.737379   \n",
       "23                   35.879997                 41.131146  ...   56.138759   \n",
       "24                   38.610388                 37.789068  ...   60.802689   \n",
       "25                   36.463336                 40.629791  ...   59.529116   \n",
       "26                   35.781677                 37.852800  ...   57.574452   \n",
       "27                   38.187084                 38.496841  ...   58.133743   \n",
       "28                   33.812129                 37.801316  ...   51.165987   \n",
       "29                   38.886618                 41.315050  ...   59.911056   \n",
       "...                        ...                       ...  ...         ...   \n",
       "2110                 38.077146                 39.057936  ...   54.907108   \n",
       "2111                 37.904219                 37.450521  ...   61.972932   \n",
       "2112                 38.234353                 35.673098  ...   49.693490   \n",
       "2113                 38.318445                 40.850241  ...   61.261017   \n",
       "2114                 39.274962                 39.840246  ...   61.146721   \n",
       "2115                 37.093120                 37.212992  ...   44.363520   \n",
       "2116                 34.289024                 37.351903  ...   63.767384   \n",
       "2117                 38.890445                 41.366887  ...   62.624247   \n",
       "2118                 37.310789                 36.984389  ...   53.453319   \n",
       "2119                 34.298757                 36.700565  ...   63.385580   \n",
       "2120                 37.055329                 37.597091  ...   57.824895   \n",
       "2121                 37.403520                 39.143040  ...   58.391589   \n",
       "2122                 34.679771                 38.051657  ...   53.578971   \n",
       "2123                 35.147741                 38.583988  ...   60.498509   \n",
       "2124                 37.266133                 37.017067  ...   58.468267   \n",
       "2125                 34.944000                 37.800153  ...   59.934573   \n",
       "2126                 38.598933                 37.219733  ...   55.334400   \n",
       "2127                 38.448345                 37.490417  ...   58.787914   \n",
       "2128                 33.800972                 37.626617  ...   60.138168   \n",
       "2129                 39.376455                 39.984509  ...   57.279699   \n",
       "2130                 37.333714                 35.262309  ...   53.649600   \n",
       "2131                 36.295709                 37.269493  ...   62.670537   \n",
       "2132                 41.104442                 38.959584  ...   61.537104   \n",
       "2133                 36.193656                 40.464563  ...   61.228919   \n",
       "2134                 31.453474                 39.210105  ...   51.253053   \n",
       "2135                 35.202620                 38.970925  ...   61.261376   \n",
       "2136                 38.472547                 38.908323  ...   54.733913   \n",
       "2137                 37.481143                 39.195429  ...   55.353351   \n",
       "2138                 36.025846                 35.743015  ...   50.264123   \n",
       "2139                 38.460150                 35.629073  ...   63.235231   \n",
       "\n",
       "      mouth_left_corner_x  mouth_left_corner_y  mouth_right_corner_x  \\\n",
       "0               58.606720            76.955520             31.434880   \n",
       "1               56.907305            83.587257             32.616431   \n",
       "2               68.056859            71.180585             33.458101   \n",
       "3               58.644741            71.455407             33.749926   \n",
       "4               57.770074            77.269048             32.047118   \n",
       "5               57.662966            77.396136             27.432925   \n",
       "6               63.825600            79.248640             33.152000   \n",
       "7               62.488296            70.049185             36.004741   \n",
       "8               67.113590            70.542162             40.077170   \n",
       "9               64.975828            73.424172             35.132903   \n",
       "10              60.768000            74.839024             33.561366   \n",
       "11              62.389241            76.482207             32.061517   \n",
       "12              59.881113            82.872795             35.017113   \n",
       "13              62.275726            71.927014             36.122301   \n",
       "14              62.203429            69.808000             35.644571   \n",
       "15              62.479618            79.095809             29.394676   \n",
       "16              69.076342            71.554749             39.391282   \n",
       "17              63.497256            74.775273             32.294876   \n",
       "18              66.080554            77.072720             30.316069   \n",
       "19              62.534857            76.992762             32.911238   \n",
       "20              58.812697            79.959948             38.330013   \n",
       "21              71.874864            71.162400             28.472350   \n",
       "22              61.415172            70.846345             34.046069   \n",
       "23              63.705296            77.094084             36.651063   \n",
       "24              63.200192            81.190748             35.871244   \n",
       "25              66.393776            74.326374             33.083900   \n",
       "26              61.731097            77.642323             33.706065   \n",
       "27              63.786700            73.496535             34.734869   \n",
       "28              60.107613            77.244387             33.120774   \n",
       "29              67.217521            76.338716             36.998308   \n",
       "...                   ...                  ...                   ...   \n",
       "2110            68.410089            69.117554             35.891159   \n",
       "2111            68.265205            72.649315             26.060384   \n",
       "2112            55.339294            76.052078             28.139294   \n",
       "2113            69.804855            70.991522             37.481168   \n",
       "2114            63.584756            80.359160             27.540926   \n",
       "2115            67.411200            66.673280             37.379200   \n",
       "2116            66.599347            79.611252             31.628029   \n",
       "2117            65.081148            78.085298             29.461616   \n",
       "2118            61.355416            74.204368             31.052627   \n",
       "2119            63.863012            86.160987             26.466911   \n",
       "2120            57.457007            80.500364             34.655329   \n",
       "2121            63.151817            75.890469             33.153737   \n",
       "2122            63.690971            75.643429             34.679771   \n",
       "2123            62.309525            71.918504             30.209612   \n",
       "2124            57.764267            69.909333             34.644267   \n",
       "2125            61.177682            72.505070             28.112102   \n",
       "2126            63.387733            74.402667             31.210133   \n",
       "2127            62.523626            75.764029             30.731741   \n",
       "2128            61.467813            74.915888             31.796636   \n",
       "2129            71.809215            71.742867             40.589246   \n",
       "2130            62.155886            76.020343             35.494629   \n",
       "2131            61.504143            78.493107             33.199243   \n",
       "2132            62.098119            70.957183             25.978711   \n",
       "2133            64.187779            74.325939             30.419251   \n",
       "2134            66.077474            78.349474             31.453474   \n",
       "2135            64.381940            73.795596             28.765916   \n",
       "2136            57.318048            88.512085             21.157054   \n",
       "2137            62.275948            79.034182             32.188052   \n",
       "2138            62.428062            71.055508             36.025846   \n",
       "2139            59.191407            78.752023             27.968493   \n",
       "\n",
       "      mouth_right_corner_y  mouth_center_top_lip_x  mouth_center_top_lip_y  \\\n",
       "0                75.811840               45.163520               74.095360   \n",
       "1                82.295569               45.278659               77.385772   \n",
       "2                74.460088               50.136717               76.991396   \n",
       "3                70.395852               46.197333               67.747556   \n",
       "4                73.298886               47.632311               73.206557   \n",
       "5                72.925551               43.114286               73.676190   \n",
       "6                78.355200               49.725120               73.580480   \n",
       "7                69.784296               49.246815               66.077037   \n",
       "8                79.616248               57.191154               75.232758   \n",
       "9                75.279828               47.657634               72.187183   \n",
       "10               74.577366               47.688000               68.298732   \n",
       "11               75.372414               45.376552               69.825103   \n",
       "12               82.015788               47.305748               78.014305   \n",
       "13               73.690521               50.520986               69.870247   \n",
       "14               68.530857               49.434857               64.956000   \n",
       "15               78.141379               45.937147               74.801038   \n",
       "16               77.685059               55.103653               73.487730   \n",
       "17               74.775273               48.250711               70.874975   \n",
       "18               77.977910               47.785744               74.367114   \n",
       "19               77.673905               47.552762               71.545143   \n",
       "20               78.852542               48.294194               74.977858   \n",
       "21               73.372467               48.416204               77.366563   \n",
       "22               71.586207               47.730207               59.011034   \n",
       "23               79.905554               49.327340               76.526858   \n",
       "24               82.558335               51.233806               81.760576   \n",
       "25               75.428884               51.427789               76.531394   \n",
       "26               76.258065               46.577806               72.213677   \n",
       "27               76.703245               50.218011               75.458850   \n",
       "28               76.898323               46.272000               71.218839   \n",
       "29               77.031916               51.143932               80.216307   \n",
       "...                    ...                     ...                     ...   \n",
       "2110             72.123516               50.920968               66.930955   \n",
       "2111             71.481534               47.579836               74.984877   \n",
       "2112             69.882980               44.964392               65.396706   \n",
       "2113             77.383535               51.123635               76.489169   \n",
       "2114             77.650501               42.960427               79.898764   \n",
       "2115             70.391680               50.822400               62.382720   \n",
       "2116             80.026034               48.582249               81.996249   \n",
       "2117             77.525616               50.776512               79.674702   \n",
       "2118             74.533881               47.192043               72.227805   \n",
       "2119             86.434579               45.503978               84.614597   \n",
       "2120             78.999944               47.256168               72.099357   \n",
       "2121             76.890240               48.152777               73.640503   \n",
       "2122             75.643429               47.346286               70.331429   \n",
       "2123             71.918504               46.259568               68.523281   \n",
       "2124             67.764267               46.561600               65.857067   \n",
       "2125             70.591796               46.694522               70.591796   \n",
       "2126             73.687467               47.179733               68.682133   \n",
       "2127             73.911712               46.781698               69.899050   \n",
       "2128             74.514841               47.032822               72.510505   \n",
       "2129             76.323626               55.380075               75.756754   \n",
       "2130             74.794286               48.365486               71.116800   \n",
       "2131             78.284958               47.124772               79.169125   \n",
       "2132             72.758864               46.719488               73.359424   \n",
       "2133             74.686807               46.560804               76.983614   \n",
       "2134             80.608000               46.883368               70.822737   \n",
       "2135             74.572255               47.102424               76.254251   \n",
       "2136             79.725146               43.033043               77.715280   \n",
       "2137             77.362286               47.449558               72.938805   \n",
       "2138             71.715692               47.906954               65.775508   \n",
       "2139             72.951235               40.006874               79.381024   \n",
       "\n",
       "      mouth_center_bottom_lip_x  mouth_center_bottom_lip_y  \\\n",
       "0                     44.019840                  84.392320   \n",
       "1                     45.278659                  92.373269   \n",
       "2                     49.879042                  77.060266   \n",
       "3                     45.932444                  78.340741   \n",
       "4                     47.724641                  74.166782   \n",
       "5                     42.813605                  75.427211   \n",
       "6                     49.530880                  83.268800   \n",
       "7                     49.511704                  75.345778   \n",
       "8                     56.219962                  75.862721   \n",
       "9                     48.430796                  80.382280   \n",
       "10                    47.426341                  81.379317   \n",
       "11                    45.376552                  83.139310   \n",
       "12                    47.591841                  89.732026   \n",
       "13                    50.814904                  77.510137   \n",
       "14                    49.434857                  77.469143   \n",
       "15                    45.937147                  83.549488   \n",
       "16                    55.048425                  74.316150   \n",
       "17                    48.605355                  82.221223   \n",
       "18                    48.456083                  88.109730   \n",
       "19                    47.552762                  82.781714   \n",
       "20                    48.017961                  86.326297   \n",
       "21                    48.948751                  81.999715   \n",
       "22                    48.470069                  76.764414   \n",
       "23                    49.450650                  78.006579   \n",
       "24                    51.598495                  82.581128   \n",
       "25                    51.404332                  77.094378   \n",
       "26                    46.567742                  84.692129   \n",
       "27                    50.672694                  76.798967   \n",
       "28                    46.268129                  85.202323   \n",
       "29                    51.468870                  81.104470   \n",
       "...                         ...                        ...   \n",
       "2110                  51.740331                  78.681478   \n",
       "2111                  47.079452                  87.829808   \n",
       "2112                  41.318902                  78.015373   \n",
       "2113                  51.345149                  80.334818   \n",
       "2114                  42.542608                  82.903080   \n",
       "2115                  51.393920                  70.963200   \n",
       "2116                  48.504477                  84.303475   \n",
       "2117                  51.136777                  80.268079   \n",
       "2118                  45.874508                  81.780065   \n",
       "2119                  45.618356                  85.758377   \n",
       "2120                  46.355916                  87.400951   \n",
       "2121                  48.152777                  81.389897   \n",
       "2122                  48.572343                  84.632686   \n",
       "2123                  46.568288                  77.783482   \n",
       "2124                  45.608533                  73.722667   \n",
       "2125                  46.147873                  83.162293   \n",
       "2126                  47.179733                  82.268267   \n",
       "2127                  45.856230                  81.937036   \n",
       "2128                  47.433869                  80.930692   \n",
       "2129                  55.644819                  79.070251   \n",
       "2130                  48.365486                  80.923200   \n",
       "2131                  47.206464                  80.326629   \n",
       "2132                  45.368227                  83.032733   \n",
       "2133                  46.747826                  78.548387   \n",
       "2134                  48.765474                  86.252632   \n",
       "2135                  47.033489                  77.104440   \n",
       "2136                  38.083123                  91.435528   \n",
       "2137                  47.510649                  83.212675   \n",
       "2138                  47.576862                  77.985969   \n",
       "2139                  39.832152                  81.023416   \n",
       "\n",
       "                                                  Image  \n",
       "0     [0.5372549019607843, 0.5411764705882353, 0.537...  \n",
       "1     [0.7450980392156863, 0.4823529411764706, 0.572...  \n",
       "2     [0.0196078431372549, 0.00784313725490196, 0.01...  \n",
       "3     [0.43137254901960786, 0.44313725490196076, 0.3...  \n",
       "4     [0.27450980392156865, 0.32941176470588235, 0.3...  \n",
       "5     [0.8862745098039215, 0.8823529411764706, 0.866...  \n",
       "6     [0.6980392156862745, 0.30196078431372547, 0.18...  \n",
       "7     [0.803921568627451, 0.8117647058823529, 0.8156...  \n",
       "8     [0.5450980392156862, 0.5568627450980392, 0.549...  \n",
       "9     [0.6627450980392157, 0.43137254901960786, 0.27...  \n",
       "10    [0.6705882352941176, 0.6784313725490196, 0.686...  \n",
       "11    [0.9098039215686274, 0.9137254901960784, 0.913...  \n",
       "12    [0.2627450980392157, 0.28627450980392155, 0.31...  \n",
       "13    [0.984313725490196, 0.9725490196078431, 0.9725...  \n",
       "14    [0.8117647058823529, 0.8235294117647058, 0.831...  \n",
       "15    [0.3215686274509804, 0.16862745098039217, 0.11...  \n",
       "16    [0.1843137254901961, 0.19607843137254902, 0.20...  \n",
       "17    [0.39215686274509803, 0.3764705882352941, 0.35...  \n",
       "18    [0.9882352941176471, 0.592156862745098, 0.1294...  \n",
       "19    [0.7803921568627451, 0.7764705882352941, 0.776...  \n",
       "20    [0.6078431372549019, 0.611764705882353, 0.6, 0...  \n",
       "21    [0.5058823529411764, 0.27450980392156865, 0.10...  \n",
       "22    [0.1568627450980392, 0.16470588235294117, 0.14...  \n",
       "23    [0.5294117647058824, 0.5294117647058824, 0.549...  \n",
       "24    [0.6823529411764706, 0.6078431372549019, 0.576...  \n",
       "25    [0.054901960784313725, 0.058823529411764705, 0...  \n",
       "26    [0.7529411764705882, 0.7647058823529411, 0.756...  \n",
       "27    [0.11372549019607843, 0.0784313725490196, 0.09...  \n",
       "28    [0.7058823529411765, 0.7058823529411765, 0.705...  \n",
       "29    [0.08627450980392157, 0.08627450980392157, 0.0...  \n",
       "...                                                 ...  \n",
       "2110  [0.9333333333333333, 0.9254901960784314, 0.921...  \n",
       "2111  [0.9882352941176471, 1.0, 0.6352941176470588, ...  \n",
       "2112  [0.5803921568627451, 0.5803921568627451, 0.584...  \n",
       "2113  [0.35294117647058826, 0.34901960784313724, 0.3...  \n",
       "2114  [0.3333333333333333, 0.35294117647058826, 0.34...  \n",
       "2115  [0.9568627450980393, 0.9411764705882353, 0.874...  \n",
       "2116  [0.8549019607843137, 0.8431372549019608, 0.850...  \n",
       "2117  [0.0392156862745098, 0.027450980392156862, 0.0...  \n",
       "2118  [0.4117647058823529, 0.36470588235294116, 0.31...  \n",
       "2119  [0.4470588235294118, 0.16470588235294117, 0.18...  \n",
       "2120  [0.5098039215686274, 0.4666666666666667, 0.415...  \n",
       "2121  [1.0, 0.9882352941176471, 1.0, 0.6352941176470...  \n",
       "2122  [0.3843137254901961, 0.3803921568627451, 0.376...  \n",
       "2123  [0.996078431372549, 0.9921568627450981, 0.9960...  \n",
       "2124  [0.6549019607843137, 0.6627450980392157, 0.678...  \n",
       "2125  [0.027450980392156862, 0.050980392156862744, 0...  \n",
       "2126  [0.9490196078431372, 0.9450980392156862, 0.945...  \n",
       "2127  [0.7725490196078432, 0.7725490196078432, 0.772...  \n",
       "2128  [0.2784313725490196, 0.24705882352941178, 0.32...  \n",
       "2129  [0.39215686274509803, 0.39215686274509803, 0.3...  \n",
       "2130  [0.7215686274509804, 0.7294117647058823, 0.733...  \n",
       "2131  [0.00784313725490196, 0.00784313725490196, 0.0...  \n",
       "2132  [0.11764705882352941, 0.10980392156862745, 0.0...  \n",
       "2133  [0.17647058823529413, 0.2, 0.20392156862745098...  \n",
       "2134  [0.14901960784313725, 0.12941176470588237, 0.1...  \n",
       "2135  [0.11372549019607843, 0.10196078431372549, 0.0...  \n",
       "2136  [0.2627450980392157, 0.2627450980392157, 0.262...  \n",
       "2137  [0.4823529411764706, 0.48627450980392156, 0.48...  \n",
       "2138  [0.7725490196078432, 0.7764705882352941, 0.776...  \n",
       "2139  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  \n",
       "\n",
       "[2140 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nostache_nonan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2140, 96, 96, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Neural Net\n",
    "CNNs are combinations of convolution layers, pooling layers and dropout layers followed by one or two fully connected layers once the number of dimensions has been sufficiently reduced.\n",
    "\n",
    "1. Let's include just one hidden layer and one output layer\n",
    "2. The input layer will reduce our flattened 96x96 matrix (i.e., 9216 in length) to a predetermined number of hidden units\n",
    "3. We will then run sensitivities to # of hidden units, activation, optimizer, and learning rate\n",
    "4. We will judge our model based on RMSE error and run time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model():\n",
    "    '''\n",
    "    Simple function that retruns a keras cnn model \n",
    "    '''\n",
    "    cnn_model = tf.keras.models.Sequential()\n",
    "    cnn_model.add(tf.keras.layers.InputLayer(input_shape=(96, 96, 1)))\n",
    "    cnn_model.add(tf.keras.layers.Conv2D(32, (3, 3), padding='valid', activation='relu'))\n",
    "    cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    cnn_model.add(tf.keras.layers.Conv2D(64, (2, 2), padding='valid', activation='relu'))\n",
    "    cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    cnn_model.add(tf.keras.layers.Conv2D(128, (2, 2), padding='valid', activation='relu'))\n",
    "    cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    cnn_model.add(tf.keras.layers.Flatten())\n",
    "    cnn_model.add(tf.keras.layers.Dense(500))\n",
    "    cnn_model.add(tf.keras.layers.Activation('relu'))\n",
    "    cnn_model.add(tf.keras.layers.Dense(500))\n",
    "    cnn_model.add(tf.keras.layers.Activation('relu'))\n",
    "    cnn_model.add(tf.keras.layers.Dense(30))\n",
    "    cnn_model.add(tf.keras.layers.Activation('linear'))\n",
    "\n",
    "    print(50*\"=\")\n",
    "    print(cnn_model.summary())\n",
    "    print(50*\"=\")\n",
    "  \n",
    "    return cnn_model\n",
    "   \n",
    "class TimeHistory(callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bad_cnn_model():\n",
    "    '''\n",
    "    Simple function that retruns a keras cnn model \n",
    "    '''\n",
    "    cnn_model = tf.keras.models.Sequential()\n",
    "    cnn_model.add(tf.keras.layers.InputLayer(input_shape=(96, 96, 1)))\n",
    "    cnn_model.add(tf.keras.layers.Conv2D(32, (3, 3), padding='valid', activation='relu'))\n",
    "    cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    cnn_model.add(tf.keras.layers.Conv2D(64, (2, 2), padding='valid', activation='relu'))\n",
    "    cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    cnn_model.add(tf.keras.layers.Conv2D(128, (2, 2), padding='valid', activation='relu'))\n",
    "    cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    cnn_model.add(tf.keras.layers.Flatten())\n",
    "    cnn_model.add(tf.keras.layers.Dense(500))\n",
    "    cnn_model.add(tf.keras.layers.Activation('relu'))\n",
    "    cnn_model.add(tf.keras.layers.Dense(500))\n",
    "    cnn_model.add(tf.keras.layers.Activation('relu'))\n",
    "    cnn_model.add(tf.keras.layers.Dense(30))\n",
    "    cnn_model.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "    print(50*\"=\")\n",
    "    print(cnn_model.summary())\n",
    "    print(50*\"=\")\n",
    "  \n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define our optimizers for our initial study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "sgd = optimizers.SGD(lr=0.01, momentum=0.9, decay=0.0, nesterov=True)\n",
    "nadam = optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "adagrad = optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "\n",
    "opt_list = {'adam':adam,'sgd':sgd, 'nadam':nadam, 'adagrad':adagrad}\n",
    "#opt_list = {'adam':adam}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up our first DOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_callback = TimeHistory()\n",
    "cnn_base_df = pd.DataFrame()\n",
    "for opt_name, opt in opt_list.items():\n",
    "    model = create_cnn_model()\n",
    "    model.compile(\n",
    "          optimizer=opt_list['adam'],\n",
    "          loss='mean_squared_error',\n",
    "          metrics=['mean_squared_error'])\n",
    "    history = model.fit(\n",
    "        X.astype(np.float32), y.astype(np.float32),\n",
    "        epochs=200,\n",
    "        validation_split=0.15, callbacks=[time_callback])\n",
    "    times = time_callback.times\n",
    "    \n",
    "    # Convert to dataframe\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "    hist['RMSE'] = np.sqrt(hist.mean_squared_error)\n",
    "    hist['val_RMSE'] = np.sqrt(hist.val_mean_squared_error)\n",
    "    hist['times'] = times\n",
    "    hist['layers'] = 3\n",
    "    hist['pooling'] = 'yes'\n",
    "    hist['fc_layer'] = 500\n",
    "    hist['activation'] = 'relu'\n",
    "    hist['optimizer'] = opt_name\n",
    "    hist['lrate'] = opt.get_config()['learning_rate']\n",
    "    \n",
    "    # Keep concatenating to dataframe\n",
    "    cnn_base_df = pd.concat([cnn_base_df,hist])\n",
    "\n",
    "    # Re-pickle after every model to retain progress\n",
    "    cnn_base_df.to_pickle(\"OutputData/cnn_base_df.pkl\")\n",
    "\n",
    "    # Save models.\n",
    "    filename = \"cnn_model_{}\".format( opt_name)\n",
    "    model.save(\"Models/\"+filename+\".h5\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run with RELU output activation to show issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 94, 94, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 47, 47, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 46, 46, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 22, 128)       32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 15488)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 500)               7744500   \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                15030     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30)                0         \n",
      "=================================================================\n",
      "Total params: 8,051,502\n",
      "Trainable params: 8,051,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "==================================================\n",
      "Train on 1819 samples, validate on 321 samples\n",
      "Epoch 1/200\n",
      "1819/1819 [==============================] - 11s 6ms/sample - loss: 1136.8494 - mean_squared_error: 1136.8495 - val_loss: 855.8803 - val_mean_squared_error: 855.8804\n",
      "Epoch 2/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 854.1168 - mean_squared_error: 854.1167 - val_loss: 849.6436 - val_mean_squared_error: 849.6435\n",
      "Epoch 3/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 852.2807 - mean_squared_error: 852.2808 - val_loss: 848.3191 - val_mean_squared_error: 848.3190\n",
      "Epoch 4/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 851.9528 - mean_squared_error: 851.9528 - val_loss: 849.2169 - val_mean_squared_error: 849.2170\n",
      "Epoch 5/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 851.5517 - mean_squared_error: 851.5518 - val_loss: 847.9320 - val_mean_squared_error: 847.9321\n",
      "Epoch 6/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 851.4817 - mean_squared_error: 851.4814 - val_loss: 849.5399 - val_mean_squared_error: 849.5399\n",
      "Epoch 7/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 851.3949 - mean_squared_error: 851.3950 - val_loss: 847.5840 - val_mean_squared_error: 847.5839\n",
      "Epoch 8/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 851.0484 - mean_squared_error: 851.0485 - val_loss: 847.4014 - val_mean_squared_error: 847.4014\n",
      "Epoch 9/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 850.6343 - mean_squared_error: 850.6343 - val_loss: 847.0830 - val_mean_squared_error: 847.0831\n",
      "Epoch 10/200\n",
      "1819/1819 [==============================] - 12s 6ms/sample - loss: 640.4651 - mean_squared_error: 640.4651 - val_loss: 580.8364 - val_mean_squared_error: 580.8364\n",
      "Epoch 11/200\n",
      "1819/1819 [==============================] - 11s 6ms/sample - loss: 580.7968 - mean_squared_error: 580.7969 - val_loss: 579.2298 - val_mean_squared_error: 579.2298\n",
      "Epoch 12/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 580.1653 - mean_squared_error: 580.1653 - val_loss: 578.2584 - val_mean_squared_error: 578.2584\n",
      "Epoch 13/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 579.3193 - mean_squared_error: 579.3193 - val_loss: 577.3527 - val_mean_squared_error: 577.3528\n",
      "Epoch 14/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 579.5249 - mean_squared_error: 579.5249 - val_loss: 577.8096 - val_mean_squared_error: 577.8096\n",
      "Epoch 15/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 578.7251 - mean_squared_error: 578.7252 - val_loss: 576.7818 - val_mean_squared_error: 576.7819\n",
      "Epoch 16/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 578.5945 - mean_squared_error: 578.5945 - val_loss: 576.9123 - val_mean_squared_error: 576.9123\n",
      "Epoch 17/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 578.2800 - mean_squared_error: 578.2799 - val_loss: 580.9127 - val_mean_squared_error: 580.9127\n",
      "Epoch 18/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 578.0044 - mean_squared_error: 578.0043 - val_loss: 577.2202 - val_mean_squared_error: 577.2202\n",
      "Epoch 19/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 577.5489 - mean_squared_error: 577.5489 - val_loss: 575.5420 - val_mean_squared_error: 575.5420\n",
      "Epoch 20/200\n",
      "1819/1819 [==============================] - 11s 6ms/sample - loss: 577.3465 - mean_squared_error: 577.3466 - val_loss: 576.3696 - val_mean_squared_error: 576.3696\n",
      "Epoch 21/200\n",
      "1819/1819 [==============================] - 11s 6ms/sample - loss: 577.0270 - mean_squared_error: 577.0269 - val_loss: 575.1997 - val_mean_squared_error: 575.1996\n",
      "Epoch 22/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 576.7668 - mean_squared_error: 576.7668 - val_loss: 576.2057 - val_mean_squared_error: 576.2057\n",
      "Epoch 23/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 576.6802 - mean_squared_error: 576.6802 - val_loss: 575.0573 - val_mean_squared_error: 575.0573\n",
      "Epoch 24/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 576.4606 - mean_squared_error: 576.4606 - val_loss: 574.8453 - val_mean_squared_error: 574.8453\n",
      "Epoch 25/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 576.5632 - mean_squared_error: 576.5632 - val_loss: 575.0125 - val_mean_squared_error: 575.0125\n",
      "Epoch 26/200\n",
      "1819/1819 [==============================] - 11s 6ms/sample - loss: 576.3722 - mean_squared_error: 576.3722 - val_loss: 575.2928 - val_mean_squared_error: 575.2927\n",
      "Epoch 27/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 576.3514 - mean_squared_error: 576.3514 - val_loss: 575.1370 - val_mean_squared_error: 575.1370\n",
      "Epoch 28/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 576.1768 - mean_squared_error: 576.1769 - val_loss: 574.7695 - val_mean_squared_error: 574.7695\n",
      "Epoch 29/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 575.9532 - mean_squared_error: 575.9532 - val_loss: 574.6900 - val_mean_squared_error: 574.6900\n",
      "Epoch 30/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 576.0125 - mean_squared_error: 576.0125 - val_loss: 574.6477 - val_mean_squared_error: 574.6476\n",
      "Epoch 31/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 575.8953 - mean_squared_error: 575.8953 - val_loss: 574.7131 - val_mean_squared_error: 574.7131\n",
      "Epoch 32/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 575.7618 - mean_squared_error: 575.7617 - val_loss: 575.7829 - val_mean_squared_error: 575.7829\n",
      "Epoch 33/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 575.7968 - mean_squared_error: 575.7968 - val_loss: 574.7803 - val_mean_squared_error: 574.7803\n",
      "Epoch 34/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 575.5687 - mean_squared_error: 575.5687 - val_loss: 574.5277 - val_mean_squared_error: 574.5276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 575.5777 - mean_squared_error: 575.5776 - val_loss: 574.2953 - val_mean_squared_error: 574.2953\n",
      "Epoch 36/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 575.6989 - mean_squared_error: 575.6989 - val_loss: 574.2664 - val_mean_squared_error: 574.2664\n",
      "Epoch 37/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 575.5464 - mean_squared_error: 575.5464 - val_loss: 574.8460 - val_mean_squared_error: 574.8460\n",
      "Epoch 38/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 575.6901 - mean_squared_error: 575.6901 - val_loss: 574.2470 - val_mean_squared_error: 574.2469\n",
      "Epoch 39/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 575.6243 - mean_squared_error: 575.6243 - val_loss: 574.6216 - val_mean_squared_error: 574.6215\n",
      "Epoch 40/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 575.3692 - mean_squared_error: 575.3691 - val_loss: 574.2426 - val_mean_squared_error: 574.2427\n",
      "Epoch 41/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 575.3615 - mean_squared_error: 575.3616 - val_loss: 574.2111 - val_mean_squared_error: 574.2110\n",
      "Epoch 42/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 575.3245 - mean_squared_error: 575.3244 - val_loss: 574.3727 - val_mean_squared_error: 574.3727\n",
      "Epoch 43/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 575.3164 - mean_squared_error: 575.3165 - val_loss: 574.2523 - val_mean_squared_error: 574.2523\n",
      "Epoch 44/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 575.4353 - mean_squared_error: 575.4354 - val_loss: 574.3151 - val_mean_squared_error: 574.3152\n",
      "Epoch 45/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 575.1434 - mean_squared_error: 575.1434 - val_loss: 574.1735 - val_mean_squared_error: 574.1735\n",
      "Epoch 46/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 575.5884 - mean_squared_error: 575.5885 - val_loss: 574.8253 - val_mean_squared_error: 574.8253\n",
      "Epoch 47/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 575.0921 - mean_squared_error: 575.0920 - val_loss: 574.3031 - val_mean_squared_error: 574.3031\n",
      "Epoch 48/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 575.1393 - mean_squared_error: 575.1393 - val_loss: 573.9924 - val_mean_squared_error: 573.9924\n",
      "Epoch 49/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.9722 - mean_squared_error: 574.9722 - val_loss: 574.1260 - val_mean_squared_error: 574.1260\n",
      "Epoch 50/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.9997 - mean_squared_error: 574.9998 - val_loss: 574.1156 - val_mean_squared_error: 574.1157\n",
      "Epoch 51/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.9147 - mean_squared_error: 574.9147 - val_loss: 573.9513 - val_mean_squared_error: 573.9513\n",
      "Epoch 52/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.8637 - mean_squared_error: 574.8637 - val_loss: 574.0152 - val_mean_squared_error: 574.0151\n",
      "Epoch 53/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 575.1209 - mean_squared_error: 575.1209 - val_loss: 574.0964 - val_mean_squared_error: 574.0964\n",
      "Epoch 54/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 576.4738 - mean_squared_error: 576.4739 - val_loss: 574.1220 - val_mean_squared_error: 574.1220\n",
      "Epoch 55/200\n",
      "1819/1819 [==============================] - 11s 6ms/sample - loss: 574.8645 - mean_squared_error: 574.8644 - val_loss: 573.9557 - val_mean_squared_error: 573.9557\n",
      "Epoch 56/200\n",
      "1819/1819 [==============================] - 11s 6ms/sample - loss: 574.8280 - mean_squared_error: 574.8280 - val_loss: 573.9390 - val_mean_squared_error: 573.9390\n",
      "Epoch 57/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.7643 - mean_squared_error: 574.7643 - val_loss: 573.9336 - val_mean_squared_error: 573.9337\n",
      "Epoch 58/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 574.6722 - mean_squared_error: 574.6721 - val_loss: 573.8763 - val_mean_squared_error: 573.8763\n",
      "Epoch 59/200\n",
      "1819/1819 [==============================] - 11s 6ms/sample - loss: 574.6399 - mean_squared_error: 574.6399 - val_loss: 573.8788 - val_mean_squared_error: 573.8788\n",
      "Epoch 60/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.6620 - mean_squared_error: 574.6620 - val_loss: 573.9092 - val_mean_squared_error: 573.9092\n",
      "Epoch 61/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 574.6542 - mean_squared_error: 574.6542 - val_loss: 573.9623 - val_mean_squared_error: 573.9624\n",
      "Epoch 62/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.7320 - mean_squared_error: 574.7320 - val_loss: 573.8726 - val_mean_squared_error: 573.8727\n",
      "Epoch 63/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.6465 - mean_squared_error: 574.6465 - val_loss: 573.9342 - val_mean_squared_error: 573.9342\n",
      "Epoch 64/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.7627 - mean_squared_error: 574.7628 - val_loss: 573.7703 - val_mean_squared_error: 573.7703\n",
      "Epoch 65/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.6756 - mean_squared_error: 574.6755 - val_loss: 573.8711 - val_mean_squared_error: 573.8711\n",
      "Epoch 66/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.7680 - mean_squared_error: 574.7681 - val_loss: 573.7467 - val_mean_squared_error: 573.7468\n",
      "Epoch 67/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.6297 - mean_squared_error: 574.6298 - val_loss: 573.7634 - val_mean_squared_error: 573.7634\n",
      "Epoch 68/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.5602 - mean_squared_error: 574.5602 - val_loss: 573.8575 - val_mean_squared_error: 573.8575\n",
      "Epoch 69/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.6249 - mean_squared_error: 574.6249 - val_loss: 573.9137 - val_mean_squared_error: 573.9138\n",
      "Epoch 70/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 574.5462 - mean_squared_error: 574.5461 - val_loss: 574.1561 - val_mean_squared_error: 574.1561\n",
      "Epoch 71/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.4776 - mean_squared_error: 574.4777 - val_loss: 573.8123 - val_mean_squared_error: 573.8124\n",
      "Epoch 72/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 574.6029 - mean_squared_error: 574.6029 - val_loss: 573.8376 - val_mean_squared_error: 573.8376\n",
      "Epoch 73/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 574.4182 - mean_squared_error: 574.4182 - val_loss: 573.7841 - val_mean_squared_error: 573.7841\n",
      "Epoch 74/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 574.4512 - mean_squared_error: 574.4511 - val_loss: 573.7293 - val_mean_squared_error: 573.7292\n",
      "Epoch 75/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.3893 - mean_squared_error: 574.3893 - val_loss: 573.7393 - val_mean_squared_error: 573.7393\n",
      "Epoch 76/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.4253 - mean_squared_error: 574.4253 - val_loss: 573.7671 - val_mean_squared_error: 573.7672\n",
      "Epoch 77/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 574.5272 - mean_squared_error: 574.5272 - val_loss: 573.7662 - val_mean_squared_error: 573.7663\n",
      "Epoch 78/200\n",
      "1819/1819 [==============================] - 11s 6ms/sample - loss: 574.5465 - mean_squared_error: 574.5465 - val_loss: 573.7606 - val_mean_squared_error: 573.7607\n",
      "Epoch 79/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.3424 - mean_squared_error: 574.3424 - val_loss: 573.7087 - val_mean_squared_error: 573.7087\n",
      "Epoch 80/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 574.8993 - mean_squared_error: 574.8992 - val_loss: 574.8229 - val_mean_squared_error: 574.8229\n",
      "Epoch 81/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 574.9220 - mean_squared_error: 574.9220 - val_loss: 573.9140 - val_mean_squared_error: 573.9140\n",
      "Epoch 82/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.3111 - mean_squared_error: 574.3110 - val_loss: 573.7217 - val_mean_squared_error: 573.7217\n",
      "Epoch 83/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.2437 - mean_squared_error: 574.2437 - val_loss: 573.7361 - val_mean_squared_error: 573.7361\n",
      "Epoch 84/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 574.3328 - mean_squared_error: 574.3328 - val_loss: 573.8613 - val_mean_squared_error: 573.8613\n",
      "Epoch 85/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 574.2774 - mean_squared_error: 574.2773 - val_loss: 573.9860 - val_mean_squared_error: 573.9860\n",
      "Epoch 86/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 574.2960 - mean_squared_error: 574.2960 - val_loss: 573.8534 - val_mean_squared_error: 573.8534\n",
      "Epoch 87/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.2645 - mean_squared_error: 574.2645 - val_loss: 573.8662 - val_mean_squared_error: 573.8662\n",
      "Epoch 88/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.2344 - mean_squared_error: 574.2343 - val_loss: 573.7309 - val_mean_squared_error: 573.7309\n",
      "Epoch 89/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.2722 - mean_squared_error: 574.2723 - val_loss: 573.7634 - val_mean_squared_error: 573.7634\n",
      "Epoch 90/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.3090 - mean_squared_error: 574.3089 - val_loss: 573.8009 - val_mean_squared_error: 573.8009\n",
      "Epoch 91/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.8667 - mean_squared_error: 574.8667 - val_loss: 574.7641 - val_mean_squared_error: 574.7642\n",
      "Epoch 92/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.6729 - mean_squared_error: 574.6729 - val_loss: 573.8453 - val_mean_squared_error: 573.8453\n",
      "Epoch 93/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.1955 - mean_squared_error: 574.1955 - val_loss: 573.7902 - val_mean_squared_error: 573.7902\n",
      "Epoch 94/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.2512 - mean_squared_error: 574.2513 - val_loss: 573.7857 - val_mean_squared_error: 573.7857\n",
      "Epoch 95/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 574.1162 - mean_squared_error: 574.1162 - val_loss: 573.7322 - val_mean_squared_error: 573.7322\n",
      "Epoch 96/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.1201 - mean_squared_error: 574.1201 - val_loss: 574.2646 - val_mean_squared_error: 574.2645\n",
      "Epoch 97/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.1874 - mean_squared_error: 574.1874 - val_loss: 573.7507 - val_mean_squared_error: 573.7507\n",
      "Epoch 98/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.1656 - mean_squared_error: 574.1655 - val_loss: 573.7477 - val_mean_squared_error: 573.7477\n",
      "Epoch 99/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.1412 - mean_squared_error: 574.1412 - val_loss: 573.7442 - val_mean_squared_error: 573.7442\n",
      "Epoch 100/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.0870 - mean_squared_error: 574.0870 - val_loss: 573.7127 - val_mean_squared_error: 573.7127\n",
      "Epoch 101/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 574.1474 - mean_squared_error: 574.1473 - val_loss: 573.8835 - val_mean_squared_error: 573.8835\n",
      "Epoch 102/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 574.2642 - mean_squared_error: 574.2642 - val_loss: 573.8072 - val_mean_squared_error: 573.8072\n",
      "Epoch 103/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.0863 - mean_squared_error: 574.0862 - val_loss: 574.3461 - val_mean_squared_error: 574.3461\n",
      "Epoch 104/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.3496 - mean_squared_error: 574.3495 - val_loss: 573.7923 - val_mean_squared_error: 573.7923\n",
      "Epoch 105/200\n",
      "1819/1819 [==============================] - 11s 6ms/sample - loss: 574.0950 - mean_squared_error: 574.0951 - val_loss: 573.8038 - val_mean_squared_error: 573.8038\n",
      "Epoch 106/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.0601 - mean_squared_error: 574.0600 - val_loss: 573.8378 - val_mean_squared_error: 573.8378\n",
      "Epoch 107/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.1172 - mean_squared_error: 574.1171 - val_loss: 573.8787 - val_mean_squared_error: 573.8787\n",
      "Epoch 108/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.3242 - mean_squared_error: 574.3242 - val_loss: 573.9236 - val_mean_squared_error: 573.9236\n",
      "Epoch 109/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.1446 - mean_squared_error: 574.1445 - val_loss: 573.8499 - val_mean_squared_error: 573.8499\n",
      "Epoch 110/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.0075 - mean_squared_error: 574.0074 - val_loss: 573.8018 - val_mean_squared_error: 573.8018\n",
      "Epoch 111/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.0674 - mean_squared_error: 574.0674 - val_loss: 573.8064 - val_mean_squared_error: 573.8064\n",
      "Epoch 112/200\n",
      "1819/1819 [==============================] - 11s 6ms/sample - loss: 574.0113 - mean_squared_error: 574.0113 - val_loss: 573.7683 - val_mean_squared_error: 573.7682\n",
      "Epoch 113/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.0346 - mean_squared_error: 574.0346 - val_loss: 573.8173 - val_mean_squared_error: 573.8173\n",
      "Epoch 114/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 574.0101 - mean_squared_error: 574.0101 - val_loss: 573.8352 - val_mean_squared_error: 573.8352\n",
      "Epoch 115/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.1996 - mean_squared_error: 574.1996 - val_loss: 573.7723 - val_mean_squared_error: 573.7724\n",
      "Epoch 116/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 574.0608 - mean_squared_error: 574.0607 - val_loss: 573.7778 - val_mean_squared_error: 573.7778\n",
      "Epoch 117/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.0747 - mean_squared_error: 574.0747 - val_loss: 573.7918 - val_mean_squared_error: 573.7918\n",
      "Epoch 118/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.0526 - mean_squared_error: 574.0526 - val_loss: 574.4644 - val_mean_squared_error: 574.4644\n",
      "Epoch 119/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.1541 - mean_squared_error: 574.1541 - val_loss: 573.8672 - val_mean_squared_error: 573.8672\n",
      "Epoch 120/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.1111 - mean_squared_error: 574.1111 - val_loss: 573.8076 - val_mean_squared_error: 573.8076\n",
      "Epoch 121/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.6169 - mean_squared_error: 574.6169 - val_loss: 574.1345 - val_mean_squared_error: 574.1345\n",
      "Epoch 122/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 574.7866 - mean_squared_error: 574.7866 - val_loss: 574.5916 - val_mean_squared_error: 574.5917\n",
      "Epoch 123/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 574.2613 - mean_squared_error: 574.2613 - val_loss: 573.7793 - val_mean_squared_error: 573.7793\n",
      "Epoch 124/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.9584 - mean_squared_error: 573.9584 - val_loss: 573.8054 - val_mean_squared_error: 573.8054\n",
      "Epoch 125/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.9420 - mean_squared_error: 573.9420 - val_loss: 573.7637 - val_mean_squared_error: 573.7637\n",
      "Epoch 126/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.9290 - mean_squared_error: 573.9290 - val_loss: 573.7572 - val_mean_squared_error: 573.7571\n",
      "Epoch 127/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 573.9944 - mean_squared_error: 573.9945 - val_loss: 573.8156 - val_mean_squared_error: 573.8156\n",
      "Epoch 128/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.9754 - mean_squared_error: 573.9754 - val_loss: 573.8170 - val_mean_squared_error: 573.8170\n",
      "Epoch 129/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.9351 - mean_squared_error: 573.9350 - val_loss: 573.7995 - val_mean_squared_error: 573.7995\n",
      "Epoch 130/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.9019 - mean_squared_error: 573.9019 - val_loss: 573.8474 - val_mean_squared_error: 573.8474\n",
      "Epoch 131/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.0116 - mean_squared_error: 574.0117 - val_loss: 573.8295 - val_mean_squared_error: 573.8295\n",
      "Epoch 132/200\n",
      "1819/1819 [==============================] - 11s 6ms/sample - loss: 573.9431 - mean_squared_error: 573.9429 - val_loss: 573.8243 - val_mean_squared_error: 573.8242\n",
      "Epoch 133/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.9699 - mean_squared_error: 573.9698 - val_loss: 573.7898 - val_mean_squared_error: 573.7897\n",
      "Epoch 134/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.9405 - mean_squared_error: 573.9406 - val_loss: 573.7750 - val_mean_squared_error: 573.7750\n",
      "Epoch 135/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 573.8934 - mean_squared_error: 573.8934 - val_loss: 573.7912 - val_mean_squared_error: 573.7913\n",
      "Epoch 136/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.8917 - mean_squared_error: 573.8917 - val_loss: 573.8231 - val_mean_squared_error: 573.8231\n",
      "Epoch 137/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.9058 - mean_squared_error: 573.9059 - val_loss: 573.7748 - val_mean_squared_error: 573.7748\n",
      "Epoch 138/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.0814 - mean_squared_error: 574.0814 - val_loss: 574.1177 - val_mean_squared_error: 574.1177\n",
      "Epoch 139/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.1465 - mean_squared_error: 574.1465 - val_loss: 574.4320 - val_mean_squared_error: 574.4320\n",
      "Epoch 140/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.1394 - mean_squared_error: 574.1394 - val_loss: 573.8767 - val_mean_squared_error: 573.8767\n",
      "Epoch 141/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.9702 - mean_squared_error: 573.9700 - val_loss: 573.8980 - val_mean_squared_error: 573.8979\n",
      "Epoch 142/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.9095 - mean_squared_error: 573.9095 - val_loss: 573.8309 - val_mean_squared_error: 573.8309\n",
      "Epoch 143/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.9337 - mean_squared_error: 573.9337 - val_loss: 573.9422 - val_mean_squared_error: 573.9421\n",
      "Epoch 144/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.9271 - mean_squared_error: 573.9271 - val_loss: 573.7983 - val_mean_squared_error: 573.7983\n",
      "Epoch 145/200\n",
      "1819/1819 [==============================] - 11s 6ms/sample - loss: 573.8816 - mean_squared_error: 573.8816 - val_loss: 573.8404 - val_mean_squared_error: 573.8404\n",
      "Epoch 146/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.9015 - mean_squared_error: 573.9016 - val_loss: 573.8140 - val_mean_squared_error: 573.8140\n",
      "Epoch 147/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 573.9077 - mean_squared_error: 573.9077 - val_loss: 573.8185 - val_mean_squared_error: 573.8185\n",
      "Epoch 148/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.8566 - mean_squared_error: 573.8566 - val_loss: 573.8048 - val_mean_squared_error: 573.8049\n",
      "Epoch 149/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.8889 - mean_squared_error: 573.8890 - val_loss: 573.8284 - val_mean_squared_error: 573.8284\n",
      "Epoch 150/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.8897 - mean_squared_error: 573.8896 - val_loss: 573.8575 - val_mean_squared_error: 573.8575\n",
      "Epoch 151/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.1460 - mean_squared_error: 574.1461 - val_loss: 574.1187 - val_mean_squared_error: 574.1187\n",
      "Epoch 152/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.9917 - mean_squared_error: 573.9916 - val_loss: 573.8946 - val_mean_squared_error: 573.8946\n",
      "Epoch 153/200\n",
      "1819/1819 [==============================] - 11s 6ms/sample - loss: 573.8909 - mean_squared_error: 573.8910 - val_loss: 573.8027 - val_mean_squared_error: 573.8027\n",
      "Epoch 154/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.8785 - mean_squared_error: 573.8786 - val_loss: 573.7834 - val_mean_squared_error: 573.7834\n",
      "Epoch 155/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.8855 - mean_squared_error: 573.8855 - val_loss: 573.7994 - val_mean_squared_error: 573.7994\n",
      "Epoch 156/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 573.8478 - mean_squared_error: 573.8477 - val_loss: 573.7938 - val_mean_squared_error: 573.7939\n",
      "Epoch 157/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 573.9920 - mean_squared_error: 573.9920 - val_loss: 573.8411 - val_mean_squared_error: 573.8412\n",
      "Epoch 158/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.9395 - mean_squared_error: 573.9396 - val_loss: 573.8306 - val_mean_squared_error: 573.8306\n",
      "Epoch 159/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 573.8775 - mean_squared_error: 573.8776 - val_loss: 573.8040 - val_mean_squared_error: 573.8040\n",
      "Epoch 160/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.8656 - mean_squared_error: 573.8656 - val_loss: 573.8957 - val_mean_squared_error: 573.8957\n",
      "Epoch 161/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.8761 - mean_squared_error: 573.8760 - val_loss: 573.8174 - val_mean_squared_error: 573.8174\n",
      "Epoch 162/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.0086 - mean_squared_error: 574.0087 - val_loss: 573.8503 - val_mean_squared_error: 573.8503\n",
      "Epoch 163/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.1902 - mean_squared_error: 574.1902 - val_loss: 573.8465 - val_mean_squared_error: 573.8465\n",
      "Epoch 164/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.9572 - mean_squared_error: 573.9573 - val_loss: 573.8164 - val_mean_squared_error: 573.8164\n",
      "Epoch 165/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.8362 - mean_squared_error: 573.8361 - val_loss: 573.8616 - val_mean_squared_error: 573.8615\n",
      "Epoch 166/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 573.8176 - mean_squared_error: 573.8176 - val_loss: 573.8057 - val_mean_squared_error: 573.8057\n",
      "Epoch 167/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.8095 - mean_squared_error: 573.8096 - val_loss: 573.8569 - val_mean_squared_error: 573.8569\n",
      "Epoch 168/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.8253 - mean_squared_error: 573.8253 - val_loss: 573.8469 - val_mean_squared_error: 573.8469\n",
      "Epoch 169/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.8626 - mean_squared_error: 573.8626 - val_loss: 573.8233 - val_mean_squared_error: 573.8234\n",
      "Epoch 170/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 573.8433 - mean_squared_error: 573.8433 - val_loss: 573.9499 - val_mean_squared_error: 573.9499\n",
      "Epoch 171/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 573.8508 - mean_squared_error: 573.8509 - val_loss: 574.0175 - val_mean_squared_error: 574.0175\n",
      "Epoch 172/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.9241 - mean_squared_error: 573.9242 - val_loss: 573.8793 - val_mean_squared_error: 573.8793\n",
      "Epoch 173/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.9108 - mean_squared_error: 573.9108 - val_loss: 573.8758 - val_mean_squared_error: 573.8759\n",
      "Epoch 174/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.8455 - mean_squared_error: 573.8455 - val_loss: 573.8071 - val_mean_squared_error: 573.8071\n",
      "Epoch 175/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.8573 - mean_squared_error: 573.8573 - val_loss: 573.8284 - val_mean_squared_error: 573.8284\n",
      "Epoch 176/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 573.8751 - mean_squared_error: 573.8751 - val_loss: 573.8465 - val_mean_squared_error: 573.8465\n",
      "Epoch 177/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.8449 - mean_squared_error: 573.8448 - val_loss: 573.9102 - val_mean_squared_error: 573.9102\n",
      "Epoch 178/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 574.0977 - mean_squared_error: 574.0977 - val_loss: 574.2062 - val_mean_squared_error: 574.2062\n",
      "Epoch 179/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 573.9082 - mean_squared_error: 573.9082 - val_loss: 573.8092 - val_mean_squared_error: 573.8093\n",
      "Epoch 180/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.8808 - mean_squared_error: 573.8807 - val_loss: 573.9140 - val_mean_squared_error: 573.9139\n",
      "Epoch 181/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 573.8261 - mean_squared_error: 573.8261 - val_loss: 573.8096 - val_mean_squared_error: 573.8097\n",
      "Epoch 182/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 573.8104 - mean_squared_error: 573.8104 - val_loss: 573.8332 - val_mean_squared_error: 573.8333\n",
      "Epoch 183/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 568.3387 - mean_squared_error: 568.3387 - val_loss: 551.2824 - val_mean_squared_error: 551.2823\n",
      "Epoch 184/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 546.7077 - mean_squared_error: 546.7077 - val_loss: 544.7760 - val_mean_squared_error: 544.7761\n",
      "Epoch 185/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 545.2439 - mean_squared_error: 545.2440 - val_loss: 544.7545 - val_mean_squared_error: 544.7545\n",
      "Epoch 186/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 545.0679 - mean_squared_error: 545.0679 - val_loss: 544.5272 - val_mean_squared_error: 544.5272\n",
      "Epoch 187/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 544.9575 - mean_squared_error: 544.9575 - val_loss: 544.5059 - val_mean_squared_error: 544.5059\n",
      "Epoch 188/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 544.9907 - mean_squared_error: 544.9907 - val_loss: 544.5229 - val_mean_squared_error: 544.5229\n",
      "Epoch 189/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 544.8807 - mean_squared_error: 544.8807 - val_loss: 544.4798 - val_mean_squared_error: 544.4799\n",
      "Epoch 190/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 544.8615 - mean_squared_error: 544.8616 - val_loss: 544.5483 - val_mean_squared_error: 544.5482\n",
      "Epoch 191/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 544.8292 - mean_squared_error: 544.8293 - val_loss: 544.5105 - val_mean_squared_error: 544.5105\n",
      "Epoch 192/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 544.8031 - mean_squared_error: 544.8030 - val_loss: 544.4768 - val_mean_squared_error: 544.4769\n",
      "Epoch 193/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 544.7905 - mean_squared_error: 544.7906 - val_loss: 544.4884 - val_mean_squared_error: 544.4883\n",
      "Epoch 194/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 544.7903 - mean_squared_error: 544.7902 - val_loss: 544.5183 - val_mean_squared_error: 544.5182\n",
      "Epoch 195/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 544.7739 - mean_squared_error: 544.7738 - val_loss: 544.4968 - val_mean_squared_error: 544.4968\n",
      "Epoch 196/200\n",
      "1819/1819 [==============================] - 11s 6ms/sample - loss: 544.7595 - mean_squared_error: 544.7595 - val_loss: 544.5004 - val_mean_squared_error: 544.5004\n",
      "Epoch 197/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 544.7601 - mean_squared_error: 544.7602 - val_loss: 544.5281 - val_mean_squared_error: 544.5281\n",
      "Epoch 198/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 544.7572 - mean_squared_error: 544.7572 - val_loss: 544.5608 - val_mean_squared_error: 544.5608\n",
      "Epoch 199/200\n",
      "1819/1819 [==============================] - 10s 6ms/sample - loss: 544.7596 - mean_squared_error: 544.7596 - val_loss: 544.5064 - val_mean_squared_error: 544.5064\n",
      "Epoch 200/200\n",
      "1819/1819 [==============================] - 10s 5ms/sample - loss: 544.7698 - mean_squared_error: 544.7697 - val_loss: 544.5106 - val_mean_squared_error: 544.5107\n"
     ]
    }
   ],
   "source": [
    "time_callback = TimeHistory()\n",
    "cnn_relu_df = pd.DataFrame()\n",
    "for opt_name, opt in opt_list.items():\n",
    "    model = create_bad_cnn_model()\n",
    "    model.compile(\n",
    "          optimizer=opt_list['adam'],\n",
    "          loss='mean_squared_error',\n",
    "          metrics=['mean_squared_error'])\n",
    "    history = model.fit(\n",
    "        X.astype(np.float32), y.astype(np.float32),\n",
    "        epochs=200,\n",
    "        validation_split=0.15, callbacks=[time_callback])\n",
    "    times = time_callback.times\n",
    "    \n",
    "    # Convert to dataframe\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "    hist['RMSE'] = np.sqrt(hist.mean_squared_error)\n",
    "    hist['val_RMSE'] = np.sqrt(hist.val_mean_squared_error)\n",
    "    hist['times'] = times\n",
    "    hist['layers'] = 3\n",
    "    hist['pooling'] = 'yes'\n",
    "    hist['fc_layer'] = 500\n",
    "    hist['activation'] = 'relu'\n",
    "    hist['optimizer'] = opt_name\n",
    "    hist['lrate'] = opt.get_config()['learning_rate']\n",
    "    \n",
    "    # Keep concatenating to dataframe\n",
    "    cnn_relu_df = pd.concat([cnn_relu_df,hist])\n",
    "\n",
    "    # Re-pickle after every model to retain progress\n",
    "    cnn_relu_df.to_pickle(\"OutputData/cnn_relu_df.pkl\")\n",
    "\n",
    "    # Save models.\n",
    "    filename = \"bad_cnn_model_{}\".format( opt_name)\n",
    "    model.save(\"Models/\"+filename+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 30)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x2880 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(len(predictions), 1, figsize=(8,8*len(predictions)))\n",
    "axes = axes.flatten()\n",
    "xs = predictions[:,0:30:2]\n",
    "ys = predictions[:,1:30:2]\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(np.reshape(X[-5+i],(96,96)), origin='upper', cmap='gray')\n",
    "    ax.scatter(x=xs[i,:], y=ys[i,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_filter_cnn_model(start_filters=32):\n",
    "    '''\n",
    "    Simple function that retruns a keras cnn model \n",
    "    '''\n",
    "    cnn_model = tf.keras.models.Sequential()\n",
    "    cnn_model.add(tf.keras.layers.InputLayer(input_shape=(96, 96, 1)))\n",
    "    cnn_model.add(tf.keras.layers.Conv2D(start_filters, (3, 3), padding='valid', activation='relu'))\n",
    "    cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    cnn_model.add(tf.keras.layers.Conv2D(start_filters*2, (2, 2), padding='valid', activation='relu'))\n",
    "    cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    cnn_model.add(tf.keras.layers.Conv2D(start_filters*4, (2, 2), padding='valid', activation='relu'))\n",
    "    cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    cnn_model.add(tf.keras.layers.Flatten())\n",
    "    cnn_model.add(tf.keras.layers.Dense(500))\n",
    "    cnn_model.add(tf.keras.layers.Activation('relu'))\n",
    "    cnn_model.add(tf.keras.layers.Dense(500))\n",
    "    cnn_model.add(tf.keras.layers.Activation('relu'))\n",
    "    cnn_model.add(tf.keras.layers.Dense(30))\n",
    "    cnn_model.add(tf.keras.layers.Activation('linear'))\n",
    "\n",
    "    print(50*\"=\")\n",
    "    print(cnn_model.summary())\n",
    "    print(50*\"=\")\n",
    "  \n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 94, 94, 3)         30        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 47, 47, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 46, 46, 6)         78        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 23, 23, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 22, 22, 12)        300       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 11, 11, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1452)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 500)               726500    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 30)                15030     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 30)                0         \n",
      "=================================================================\n",
      "Total params: 992,438\n",
      "Trainable params: 992,438\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "==================================================\n",
      "Train on 1819 samples, validate on 321 samples\n",
      "Epoch 1/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 258.7116 - mean_squared_error: 258.7115 - val_loss: 13.1130 - val_mean_squared_error: 13.1130\n",
      "Epoch 2/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 11.8082 - mean_squared_error: 11.8082 - val_loss: 11.2580 - val_mean_squared_error: 11.2580\n",
      "Epoch 3/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.6730 - mean_squared_error: 10.6730 - val_loss: 10.2882 - val_mean_squared_error: 10.2882\n",
      "Epoch 4/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.2110 - mean_squared_error: 10.2110 - val_loss: 9.9089 - val_mean_squared_error: 9.9089\n",
      "Epoch 5/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.0186 - mean_squared_error: 10.0186 - val_loss: 10.4418 - val_mean_squared_error: 10.4418\n",
      "Epoch 6/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.0893 - mean_squared_error: 10.0893 - val_loss: 10.1247 - val_mean_squared_error: 10.1247\n",
      "Epoch 7/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 9.7248 - mean_squared_error: 9.7248 - val_loss: 9.6750 - val_mean_squared_error: 9.6750\n",
      "Epoch 8/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 9.9790 - mean_squared_error: 9.9790 - val_loss: 9.8008 - val_mean_squared_error: 9.8008\n",
      "Epoch 9/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.2551 - mean_squared_error: 10.2551 - val_loss: 9.5419 - val_mean_squared_error: 9.5419\n",
      "Epoch 10/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 9.9607 - mean_squared_error: 9.9607 - val_loss: 9.3511 - val_mean_squared_error: 9.3511\n",
      "Epoch 11/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 9.7058 - mean_squared_error: 9.7058 - val_loss: 9.4766 - val_mean_squared_error: 9.4766\n",
      "Epoch 12/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 9.4617 - mean_squared_error: 9.4617 - val_loss: 9.5255 - val_mean_squared_error: 9.5255\n",
      "Epoch 13/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 9.5200 - mean_squared_error: 9.5200 - val_loss: 9.3632 - val_mean_squared_error: 9.3632\n",
      "Epoch 14/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 9.4720 - mean_squared_error: 9.4720 - val_loss: 9.4502 - val_mean_squared_error: 9.4502\n",
      "Epoch 15/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 9.6445 - mean_squared_error: 9.6445 - val_loss: 10.2427 - val_mean_squared_error: 10.2427\n",
      "Epoch 16/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 9.6001 - mean_squared_error: 9.6001 - val_loss: 9.3055 - val_mean_squared_error: 9.3055\n",
      "Epoch 17/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 9.1979 - mean_squared_error: 9.1979 - val_loss: 9.3720 - val_mean_squared_error: 9.3720\n",
      "Epoch 18/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 9.3743 - mean_squared_error: 9.3743 - val_loss: 9.2350 - val_mean_squared_error: 9.2350\n",
      "Epoch 19/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 9.2070 - mean_squared_error: 9.2070 - val_loss: 9.2074 - val_mean_squared_error: 9.2074\n",
      "Epoch 20/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 9.3386 - mean_squared_error: 9.3386 - val_loss: 9.0283 - val_mean_squared_error: 9.0283\n",
      "Epoch 21/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 8.9311 - mean_squared_error: 8.9311 - val_loss: 9.0315 - val_mean_squared_error: 9.0315\n",
      "Epoch 22/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 8.9589 - mean_squared_error: 8.9589 - val_loss: 9.1571 - val_mean_squared_error: 9.1571\n",
      "Epoch 23/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 9.0697 - mean_squared_error: 9.0697 - val_loss: 8.9468 - val_mean_squared_error: 8.9468\n",
      "Epoch 24/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 8.6669 - mean_squared_error: 8.6669 - val_loss: 8.5946 - val_mean_squared_error: 8.5946\n",
      "Epoch 25/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 8.5148 - mean_squared_error: 8.5148 - val_loss: 8.6218 - val_mean_squared_error: 8.6218\n",
      "Epoch 26/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 8.4039 - mean_squared_error: 8.4039 - val_loss: 8.2029 - val_mean_squared_error: 8.2029\n",
      "Epoch 27/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 7.9331 - mean_squared_error: 7.9331 - val_loss: 7.8887 - val_mean_squared_error: 7.8887\n",
      "Epoch 28/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 7.7293 - mean_squared_error: 7.7293 - val_loss: 7.6196 - val_mean_squared_error: 7.6196\n",
      "Epoch 29/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 7.6154 - mean_squared_error: 7.6154 - val_loss: 7.3297 - val_mean_squared_error: 7.3297\n",
      "Epoch 30/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 7.0383 - mean_squared_error: 7.0383 - val_loss: 7.4628 - val_mean_squared_error: 7.4628\n",
      "Epoch 31/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 6.9081 - mean_squared_error: 6.9081 - val_loss: 7.0160 - val_mean_squared_error: 7.0160\n",
      "Epoch 32/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 6.6958 - mean_squared_error: 6.6958 - val_loss: 6.7334 - val_mean_squared_error: 6.7334\n",
      "Epoch 33/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 6.5907 - mean_squared_error: 6.5907 - val_loss: 6.9430 - val_mean_squared_error: 6.9430\n",
      "Epoch 34/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 6.3926 - mean_squared_error: 6.3926 - val_loss: 6.7473 - val_mean_squared_error: 6.7473\n",
      "Epoch 35/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 6.3976 - mean_squared_error: 6.3976 - val_loss: 6.4919 - val_mean_squared_error: 6.4919\n",
      "Epoch 36/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 6.0632 - mean_squared_error: 6.0632 - val_loss: 6.2737 - val_mean_squared_error: 6.2737\n",
      "Epoch 37/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 6.0540 - mean_squared_error: 6.0540 - val_loss: 6.7862 - val_mean_squared_error: 6.7862\n",
      "Epoch 38/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 6.0144 - mean_squared_error: 6.0144 - val_loss: 5.9547 - val_mean_squared_error: 5.9547\n",
      "Epoch 39/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 5.8032 - mean_squared_error: 5.8032 - val_loss: 5.8672 - val_mean_squared_error: 5.8672\n",
      "Epoch 40/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 5.6799 - mean_squared_error: 5.6799 - val_loss: 5.7687 - val_mean_squared_error: 5.7687\n",
      "Epoch 41/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 5.5644 - mean_squared_error: 5.5644 - val_loss: 5.7267 - val_mean_squared_error: 5.7267\n",
      "Epoch 42/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 5.3351 - mean_squared_error: 5.3351 - val_loss: 5.7852 - val_mean_squared_error: 5.7852\n",
      "Epoch 43/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 5.3089 - mean_squared_error: 5.3089 - val_loss: 6.5772 - val_mean_squared_error: 6.5772\n",
      "Epoch 44/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 5.4869 - mean_squared_error: 5.4869 - val_loss: 5.4408 - val_mean_squared_error: 5.4408\n",
      "Epoch 45/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 4.9178 - mean_squared_error: 4.9178 - val_loss: 5.4795 - val_mean_squared_error: 5.4795\n",
      "Epoch 46/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 4.7090 - mean_squared_error: 4.7090 - val_loss: 4.8586 - val_mean_squared_error: 4.8586\n",
      "Epoch 47/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 4.6362 - mean_squared_error: 4.6362 - val_loss: 4.8180 - val_mean_squared_error: 4.8180\n",
      "Epoch 48/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 4.4881 - mean_squared_error: 4.4881 - val_loss: 4.7041 - val_mean_squared_error: 4.7041\n",
      "Epoch 49/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 4.4174 - mean_squared_error: 4.4174 - val_loss: 4.6188 - val_mean_squared_error: 4.6188\n",
      "Epoch 50/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 4.2799 - mean_squared_error: 4.2799 - val_loss: 4.6301 - val_mean_squared_error: 4.6301\n",
      "Epoch 51/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 4.0684 - mean_squared_error: 4.0684 - val_loss: 4.3941 - val_mean_squared_error: 4.3941\n",
      "Epoch 52/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 4.0265 - mean_squared_error: 4.0265 - val_loss: 4.4233 - val_mean_squared_error: 4.4233\n",
      "Epoch 53/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 3.9352 - mean_squared_error: 3.9352 - val_loss: 4.3094 - val_mean_squared_error: 4.3094\n",
      "Epoch 54/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 3.8449 - mean_squared_error: 3.8449 - val_loss: 4.2176 - val_mean_squared_error: 4.2176\n",
      "Epoch 55/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 3.7532 - mean_squared_error: 3.7532 - val_loss: 4.3703 - val_mean_squared_error: 4.3703\n",
      "Epoch 56/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 3.6923 - mean_squared_error: 3.6923 - val_loss: 4.2068 - val_mean_squared_error: 4.2068\n",
      "Epoch 57/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 3.6600 - mean_squared_error: 3.6600 - val_loss: 4.0900 - val_mean_squared_error: 4.0900\n",
      "Epoch 58/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 3.5608 - mean_squared_error: 3.5608 - val_loss: 4.0895 - val_mean_squared_error: 4.0895\n",
      "Epoch 59/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 3.5173 - mean_squared_error: 3.5173 - val_loss: 3.9614 - val_mean_squared_error: 3.9614\n",
      "Epoch 60/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 3.3868 - mean_squared_error: 3.3868 - val_loss: 4.4445 - val_mean_squared_error: 4.4445\n",
      "Epoch 61/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 3.5037 - mean_squared_error: 3.5037 - val_loss: 5.1386 - val_mean_squared_error: 5.1386\n",
      "Epoch 62/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 3.4690 - mean_squared_error: 3.4690 - val_loss: 4.7891 - val_mean_squared_error: 4.7891\n",
      "Epoch 63/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 3.2694 - mean_squared_error: 3.2694 - val_loss: 3.9438 - val_mean_squared_error: 3.9438\n",
      "Epoch 64/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 3.5655 - mean_squared_error: 3.5655 - val_loss: 3.9427 - val_mean_squared_error: 3.9427\n",
      "Epoch 65/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 3.3049 - mean_squared_error: 3.3049 - val_loss: 3.8034 - val_mean_squared_error: 3.8034\n",
      "Epoch 66/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 3.0527 - mean_squared_error: 3.0527 - val_loss: 3.8714 - val_mean_squared_error: 3.8714\n",
      "Epoch 67/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 3.0488 - mean_squared_error: 3.0488 - val_loss: 5.2794 - val_mean_squared_error: 5.2794\n",
      "Epoch 68/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 3.0698 - mean_squared_error: 3.0698 - val_loss: 3.7786 - val_mean_squared_error: 3.7786\n",
      "Epoch 69/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.9099 - mean_squared_error: 2.9099 - val_loss: 3.6694 - val_mean_squared_error: 3.6694\n",
      "Epoch 70/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.8599 - mean_squared_error: 2.8599 - val_loss: 3.6533 - val_mean_squared_error: 3.6533\n",
      "Epoch 71/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.8978 - mean_squared_error: 2.8978 - val_loss: 4.1072 - val_mean_squared_error: 4.1072\n",
      "Epoch 72/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.9639 - mean_squared_error: 2.9639 - val_loss: 3.7590 - val_mean_squared_error: 3.7590\n",
      "Epoch 73/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.9082 - mean_squared_error: 2.9082 - val_loss: 3.9059 - val_mean_squared_error: 3.9059\n",
      "Epoch 74/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.7989 - mean_squared_error: 2.7989 - val_loss: 3.5592 - val_mean_squared_error: 3.5592\n",
      "Epoch 75/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.7400 - mean_squared_error: 2.7400 - val_loss: 4.0797 - val_mean_squared_error: 4.0797\n",
      "Epoch 76/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.7909 - mean_squared_error: 2.7909 - val_loss: 4.0940 - val_mean_squared_error: 4.0940\n",
      "Epoch 77/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.7850 - mean_squared_error: 2.7850 - val_loss: 3.6908 - val_mean_squared_error: 3.6908\n",
      "Epoch 78/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.6663 - mean_squared_error: 2.6663 - val_loss: 4.1180 - val_mean_squared_error: 4.1180\n",
      "Epoch 79/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.6809 - mean_squared_error: 2.6809 - val_loss: 3.7503 - val_mean_squared_error: 3.7503\n",
      "Epoch 80/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.7576 - mean_squared_error: 2.7576 - val_loss: 3.4454 - val_mean_squared_error: 3.4454\n",
      "Epoch 81/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.5318 - mean_squared_error: 2.5318 - val_loss: 4.0187 - val_mean_squared_error: 4.0187\n",
      "Epoch 82/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.8419 - mean_squared_error: 2.8419 - val_loss: 4.2463 - val_mean_squared_error: 4.2463\n",
      "Epoch 83/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.5175 - mean_squared_error: 2.5175 - val_loss: 3.4215 - val_mean_squared_error: 3.4215\n",
      "Epoch 84/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.5891 - mean_squared_error: 2.5891 - val_loss: 4.2831 - val_mean_squared_error: 4.2831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.4876 - mean_squared_error: 2.4876 - val_loss: 3.5072 - val_mean_squared_error: 3.5072\n",
      "Epoch 86/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.4113 - mean_squared_error: 2.4113 - val_loss: 3.7545 - val_mean_squared_error: 3.7545\n",
      "Epoch 87/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.3089 - mean_squared_error: 2.3089 - val_loss: 3.3849 - val_mean_squared_error: 3.3849\n",
      "Epoch 88/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.4857 - mean_squared_error: 2.4857 - val_loss: 3.5103 - val_mean_squared_error: 3.5103\n",
      "Epoch 89/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.3594 - mean_squared_error: 2.3594 - val_loss: 3.3016 - val_mean_squared_error: 3.3016\n",
      "Epoch 90/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.2927 - mean_squared_error: 2.2927 - val_loss: 3.5252 - val_mean_squared_error: 3.5252\n",
      "Epoch 91/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.2091 - mean_squared_error: 2.2091 - val_loss: 3.3338 - val_mean_squared_error: 3.3338\n",
      "Epoch 92/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.2060 - mean_squared_error: 2.2060 - val_loss: 3.3105 - val_mean_squared_error: 3.3105\n",
      "Epoch 93/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.1558 - mean_squared_error: 2.1558 - val_loss: 3.3463 - val_mean_squared_error: 3.3463\n",
      "Epoch 94/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.4927 - mean_squared_error: 2.4927 - val_loss: 3.3041 - val_mean_squared_error: 3.3041\n",
      "Epoch 95/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.1657 - mean_squared_error: 2.1657 - val_loss: 3.8084 - val_mean_squared_error: 3.8084\n",
      "Epoch 96/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.1337 - mean_squared_error: 2.1337 - val_loss: 3.2878 - val_mean_squared_error: 3.2878\n",
      "Epoch 97/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.0827 - mean_squared_error: 2.0827 - val_loss: 3.6139 - val_mean_squared_error: 3.6139\n",
      "Epoch 98/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.1815 - mean_squared_error: 2.1815 - val_loss: 3.3542 - val_mean_squared_error: 3.3542\n",
      "Epoch 99/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.9912 - mean_squared_error: 1.9912 - val_loss: 3.2280 - val_mean_squared_error: 3.2280\n",
      "Epoch 100/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.1666 - mean_squared_error: 2.1666 - val_loss: 3.8192 - val_mean_squared_error: 3.8192\n",
      "Epoch 101/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.1266 - mean_squared_error: 2.1266 - val_loss: 3.1767 - val_mean_squared_error: 3.1767\n",
      "Epoch 102/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.9780 - mean_squared_error: 1.9780 - val_loss: 3.2567 - val_mean_squared_error: 3.2567\n",
      "Epoch 103/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.0151 - mean_squared_error: 2.0151 - val_loss: 3.4073 - val_mean_squared_error: 3.4073\n",
      "Epoch 104/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.9571 - mean_squared_error: 1.9571 - val_loss: 3.2251 - val_mean_squared_error: 3.2251\n",
      "Epoch 105/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.9701 - mean_squared_error: 1.9701 - val_loss: 3.4033 - val_mean_squared_error: 3.4033\n",
      "Epoch 106/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.8629 - mean_squared_error: 1.8629 - val_loss: 3.1826 - val_mean_squared_error: 3.1826\n",
      "Epoch 107/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.0598 - mean_squared_error: 2.0598 - val_loss: 3.7099 - val_mean_squared_error: 3.7099\n",
      "Epoch 108/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2.0672 - mean_squared_error: 2.0672 - val_loss: 3.1471 - val_mean_squared_error: 3.1471\n",
      "Epoch 109/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.8228 - mean_squared_error: 1.8228 - val_loss: 3.2415 - val_mean_squared_error: 3.2415\n",
      "Epoch 110/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.8602 - mean_squared_error: 1.8602 - val_loss: 3.2399 - val_mean_squared_error: 3.2399\n",
      "Epoch 111/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.7267 - mean_squared_error: 1.7267 - val_loss: 3.1329 - val_mean_squared_error: 3.1329\n",
      "Epoch 112/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.8777 - mean_squared_error: 1.8777 - val_loss: 3.1312 - val_mean_squared_error: 3.1312\n",
      "Epoch 113/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.8136 - mean_squared_error: 1.8136 - val_loss: 3.2472 - val_mean_squared_error: 3.2472\n",
      "Epoch 114/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.7036 - mean_squared_error: 1.7036 - val_loss: 3.1998 - val_mean_squared_error: 3.1998\n",
      "Epoch 115/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.7433 - mean_squared_error: 1.7433 - val_loss: 3.2304 - val_mean_squared_error: 3.2304\n",
      "Epoch 116/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.6578 - mean_squared_error: 1.6578 - val_loss: 3.1783 - val_mean_squared_error: 3.1783\n",
      "Epoch 117/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.5803 - mean_squared_error: 1.5803 - val_loss: 3.1345 - val_mean_squared_error: 3.1345\n",
      "Epoch 118/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.5971 - mean_squared_error: 1.5971 - val_loss: 3.3728 - val_mean_squared_error: 3.3728\n",
      "Epoch 119/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.6637 - mean_squared_error: 1.6637 - val_loss: 3.1342 - val_mean_squared_error: 3.1342\n",
      "Epoch 120/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.7327 - mean_squared_error: 1.7327 - val_loss: 3.0949 - val_mean_squared_error: 3.0949\n",
      "Epoch 121/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.6723 - mean_squared_error: 1.6723 - val_loss: 3.1888 - val_mean_squared_error: 3.1888\n",
      "Epoch 122/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.5822 - mean_squared_error: 1.5822 - val_loss: 3.0624 - val_mean_squared_error: 3.0624\n",
      "Epoch 123/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.5336 - mean_squared_error: 1.5336 - val_loss: 3.1393 - val_mean_squared_error: 3.1393\n",
      "Epoch 124/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.5897 - mean_squared_error: 1.5897 - val_loss: 3.2355 - val_mean_squared_error: 3.2355\n",
      "Epoch 125/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.5179 - mean_squared_error: 1.5179 - val_loss: 3.3434 - val_mean_squared_error: 3.3434\n",
      "Epoch 126/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.4825 - mean_squared_error: 1.4825 - val_loss: 3.4307 - val_mean_squared_error: 3.4307\n",
      "Epoch 127/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.4802 - mean_squared_error: 1.4802 - val_loss: 3.0440 - val_mean_squared_error: 3.0440\n",
      "Epoch 128/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.4875 - mean_squared_error: 1.4875 - val_loss: 3.0411 - val_mean_squared_error: 3.0411\n",
      "Epoch 129/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.5170 - mean_squared_error: 1.5170 - val_loss: 3.3535 - val_mean_squared_error: 3.3535\n",
      "Epoch 130/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.3826 - mean_squared_error: 1.3826 - val_loss: 3.0996 - val_mean_squared_error: 3.0996\n",
      "Epoch 131/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.4116 - mean_squared_error: 1.4116 - val_loss: 3.1915 - val_mean_squared_error: 3.1915\n",
      "Epoch 132/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.3436 - mean_squared_error: 1.3436 - val_loss: 3.0346 - val_mean_squared_error: 3.0346\n",
      "Epoch 133/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.3814 - mean_squared_error: 1.3814 - val_loss: 3.1328 - val_mean_squared_error: 3.1328\n",
      "Epoch 134/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.4055 - mean_squared_error: 1.4055 - val_loss: 3.0882 - val_mean_squared_error: 3.0882\n",
      "Epoch 135/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.3848 - mean_squared_error: 1.3848 - val_loss: 3.2347 - val_mean_squared_error: 3.2347\n",
      "Epoch 136/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.5267 - mean_squared_error: 1.5267 - val_loss: 3.0914 - val_mean_squared_error: 3.0914\n",
      "Epoch 137/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.5202 - mean_squared_error: 1.5202 - val_loss: 3.0547 - val_mean_squared_error: 3.0547\n",
      "Epoch 138/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.4053 - mean_squared_error: 1.4053 - val_loss: 3.2465 - val_mean_squared_error: 3.2465\n",
      "Epoch 139/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.3885 - mean_squared_error: 1.3885 - val_loss: 3.0939 - val_mean_squared_error: 3.0939\n",
      "Epoch 140/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.2439 - mean_squared_error: 1.2439 - val_loss: 3.0742 - val_mean_squared_error: 3.0742\n",
      "Epoch 141/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.2506 - mean_squared_error: 1.2506 - val_loss: 3.1421 - val_mean_squared_error: 3.1421\n",
      "Epoch 142/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.2154 - mean_squared_error: 1.2154 - val_loss: 3.1138 - val_mean_squared_error: 3.1138\n",
      "Epoch 143/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.3595 - mean_squared_error: 1.3595 - val_loss: 3.2272 - val_mean_squared_error: 3.2272\n",
      "Epoch 144/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.2999 - mean_squared_error: 1.2999 - val_loss: 2.9883 - val_mean_squared_error: 2.9883\n",
      "Epoch 145/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.2508 - mean_squared_error: 1.2508 - val_loss: 3.0654 - val_mean_squared_error: 3.0654\n",
      "Epoch 146/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.1646 - mean_squared_error: 1.1646 - val_loss: 3.0853 - val_mean_squared_error: 3.0853\n",
      "Epoch 147/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.1974 - mean_squared_error: 1.1974 - val_loss: 3.1687 - val_mean_squared_error: 3.1687\n",
      "Epoch 148/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.1837 - mean_squared_error: 1.1837 - val_loss: 3.0131 - val_mean_squared_error: 3.0131\n",
      "Epoch 149/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.0917 - mean_squared_error: 1.0917 - val_loss: 2.9774 - val_mean_squared_error: 2.9774\n",
      "Epoch 150/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.1000 - mean_squared_error: 1.1000 - val_loss: 3.0656 - val_mean_squared_error: 3.0656\n",
      "Epoch 151/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.1101 - mean_squared_error: 1.1101 - val_loss: 3.0191 - val_mean_squared_error: 3.0191\n",
      "Epoch 152/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.0624 - mean_squared_error: 1.0624 - val_loss: 3.0915 - val_mean_squared_error: 3.0915\n",
      "Epoch 153/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.2478 - mean_squared_error: 1.2478 - val_loss: 4.6169 - val_mean_squared_error: 4.6169\n",
      "Epoch 154/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.3842 - mean_squared_error: 1.3842 - val_loss: 3.0636 - val_mean_squared_error: 3.0636\n",
      "Epoch 155/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.0437 - mean_squared_error: 1.0437 - val_loss: 3.0573 - val_mean_squared_error: 3.0573\n",
      "Epoch 156/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.1474 - mean_squared_error: 1.1474 - val_loss: 3.4364 - val_mean_squared_error: 3.4364\n",
      "Epoch 157/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.1957 - mean_squared_error: 1.1957 - val_loss: 3.0693 - val_mean_squared_error: 3.0693\n",
      "Epoch 158/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.0149 - mean_squared_error: 1.0149 - val_loss: 2.9561 - val_mean_squared_error: 2.9561\n",
      "Epoch 159/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.1232 - mean_squared_error: 1.1232 - val_loss: 2.9744 - val_mean_squared_error: 2.9744\n",
      "Epoch 160/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.9981 - mean_squared_error: 0.9981 - val_loss: 3.1143 - val_mean_squared_error: 3.1143\n",
      "Epoch 161/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.9528 - mean_squared_error: 0.9528 - val_loss: 3.2305 - val_mean_squared_error: 3.2305\n",
      "Epoch 162/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.9853 - mean_squared_error: 0.9853 - val_loss: 3.1923 - val_mean_squared_error: 3.1923\n",
      "Epoch 163/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1.0347 - mean_squared_error: 1.0347 - val_loss: 2.9766 - val_mean_squared_error: 2.9766\n",
      "Epoch 164/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.9752 - mean_squared_error: 0.9752 - val_loss: 3.0465 - val_mean_squared_error: 3.0465\n",
      "Epoch 165/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.9534 - mean_squared_error: 0.9534 - val_loss: 3.3952 - val_mean_squared_error: 3.3952\n",
      "Epoch 166/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.9865 - mean_squared_error: 0.9865 - val_loss: 2.9935 - val_mean_squared_error: 2.9935\n",
      "Epoch 167/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.9372 - mean_squared_error: 0.9372 - val_loss: 2.9821 - val_mean_squared_error: 2.9821\n",
      "Epoch 168/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.9272 - mean_squared_error: 0.9272 - val_loss: 3.1942 - val_mean_squared_error: 3.1942\n",
      "Epoch 169/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.9382 - mean_squared_error: 0.9382 - val_loss: 3.0267 - val_mean_squared_error: 3.0267\n",
      "Epoch 170/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.9019 - mean_squared_error: 0.9019 - val_loss: 3.0800 - val_mean_squared_error: 3.0800\n",
      "Epoch 171/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.9191 - mean_squared_error: 0.9191 - val_loss: 3.0239 - val_mean_squared_error: 3.0239\n",
      "Epoch 172/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.9144 - mean_squared_error: 0.9144 - val_loss: 3.0362 - val_mean_squared_error: 3.0362\n",
      "Epoch 173/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.9579 - mean_squared_error: 0.9579 - val_loss: 3.0692 - val_mean_squared_error: 3.0692\n",
      "Epoch 174/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.9803 - mean_squared_error: 0.9803 - val_loss: 3.0181 - val_mean_squared_error: 3.0181\n",
      "Epoch 175/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.9265 - mean_squared_error: 0.9265 - val_loss: 3.1491 - val_mean_squared_error: 3.1491\n",
      "Epoch 176/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.8868 - mean_squared_error: 0.8868 - val_loss: 3.2299 - val_mean_squared_error: 3.2299\n",
      "Epoch 177/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.9620 - mean_squared_error: 0.9620 - val_loss: 3.0101 - val_mean_squared_error: 3.0101\n",
      "Epoch 178/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.9453 - mean_squared_error: 0.9453 - val_loss: 3.3012 - val_mean_squared_error: 3.3012\n",
      "Epoch 179/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.8936 - mean_squared_error: 0.8936 - val_loss: 3.1856 - val_mean_squared_error: 3.1856\n",
      "Epoch 180/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.8727 - mean_squared_error: 0.8727 - val_loss: 3.3919 - val_mean_squared_error: 3.3919\n",
      "Epoch 181/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.8882 - mean_squared_error: 0.8882 - val_loss: 3.0707 - val_mean_squared_error: 3.0707\n",
      "Epoch 182/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.8087 - mean_squared_error: 0.8087 - val_loss: 3.0416 - val_mean_squared_error: 3.0416\n",
      "Epoch 183/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.7892 - mean_squared_error: 0.7892 - val_loss: 3.2756 - val_mean_squared_error: 3.2756\n",
      "Epoch 184/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.8630 - mean_squared_error: 0.8630 - val_loss: 3.0708 - val_mean_squared_error: 3.0708\n",
      "Epoch 185/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.7692 - mean_squared_error: 0.7692 - val_loss: 3.0278 - val_mean_squared_error: 3.0278\n",
      "Epoch 186/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.7665 - mean_squared_error: 0.7665 - val_loss: 3.1422 - val_mean_squared_error: 3.1422\n",
      "Epoch 187/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.8268 - mean_squared_error: 0.8268 - val_loss: 3.1105 - val_mean_squared_error: 3.1105\n",
      "Epoch 188/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.7736 - mean_squared_error: 0.7736 - val_loss: 3.0733 - val_mean_squared_error: 3.0733\n",
      "Epoch 189/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.7132 - mean_squared_error: 0.7132 - val_loss: 3.0460 - val_mean_squared_error: 3.0460\n",
      "Epoch 190/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.7266 - mean_squared_error: 0.7266 - val_loss: 3.0464 - val_mean_squared_error: 3.0464\n",
      "Epoch 191/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.8170 - mean_squared_error: 0.8170 - val_loss: 3.3011 - val_mean_squared_error: 3.3011\n",
      "Epoch 192/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.9008 - mean_squared_error: 0.9008 - val_loss: 3.0527 - val_mean_squared_error: 3.0527\n",
      "Epoch 193/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.8485 - mean_squared_error: 0.8485 - val_loss: 3.3645 - val_mean_squared_error: 3.3645\n",
      "Epoch 194/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.8781 - mean_squared_error: 0.8781 - val_loss: 3.1887 - val_mean_squared_error: 3.1887\n",
      "Epoch 195/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.7067 - mean_squared_error: 0.7067 - val_loss: 3.1556 - val_mean_squared_error: 3.1556\n",
      "Epoch 196/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.7021 - mean_squared_error: 0.7021 - val_loss: 3.1380 - val_mean_squared_error: 3.1380\n",
      "Epoch 197/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.6482 - mean_squared_error: 0.6482 - val_loss: 3.1583 - val_mean_squared_error: 3.1583\n",
      "Epoch 198/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.6892 - mean_squared_error: 0.6892 - val_loss: 3.0536 - val_mean_squared_error: 3.0536\n",
      "Epoch 199/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.6748 - mean_squared_error: 0.6748 - val_loss: 3.0844 - val_mean_squared_error: 3.0844\n",
      "Epoch 200/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 0.6576 - mean_squared_error: 0.6576 - val_loss: 3.0317 - val_mean_squared_error: 3.0317\n",
      "==================================================\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 94, 94, 3)         30        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 47, 47, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 46, 46, 6)         78        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 23, 23, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 22, 22, 12)        300       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 11, 11, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1452)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 500)               726500    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 30)                15030     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 30)                0         \n",
      "=================================================================\n",
      "Total params: 992,438\n",
      "Trainable params: 992,438\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "==================================================\n",
      "Train on 1819 samples, validate on 321 samples\n",
      "Epoch 1/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 33754093361.2988 - mean_squared_error: 33754095616.0000 - val_loss: 55062857.3209 - val_mean_squared_error: 55062860.0000\n",
      "Epoch 2/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 38630465.6833 - mean_squared_error: 38630468.0000 - val_loss: 25001081.6199 - val_mean_squared_error: 25001080.0000\n",
      "Epoch 3/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 17276676.2232 - mean_squared_error: 17276682.0000 - val_loss: 11125678.0374 - val_mean_squared_error: 11125679.0000\n",
      "Epoch 4/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 7687723.6130 - mean_squared_error: 7687725.0000 - val_loss: 4950497.9751 - val_mean_squared_error: 4950498.0000\n",
      "Epoch 5/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 3420771.8665 - mean_squared_error: 3420772.0000 - val_loss: 2202757.9369 - val_mean_squared_error: 2202758.0000\n",
      "Epoch 6/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1522129.0455 - mean_squared_error: 1522129.0000 - val_loss: 980124.9675 - val_mean_squared_error: 980125.0000\n",
      "Epoch 7/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 677299.9502 - mean_squared_error: 677300.0000 - val_loss: 436109.5103 - val_mean_squared_error: 436109.5625\n",
      "Epoch 8/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 301382.8331 - mean_squared_error: 301382.8750 - val_loss: 194042.8702 - val_mean_squared_error: 194042.8594\n",
      "Epoch 9/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 134109.7340 - mean_squared_error: 134109.7031 - val_loss: 86340.9910 - val_mean_squared_error: 86340.9922\n",
      "Epoch 10/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 59679.9185 - mean_squared_error: 59679.9336 - val_loss: 38418.5632 - val_mean_squared_error: 38418.5664\n",
      "Epoch 11/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 26561.3310 - mean_squared_error: 26561.3320 - val_loss: 17095.8724 - val_mean_squared_error: 17095.8730\n",
      "Epoch 12/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 11824.6118 - mean_squared_error: 11824.6133 - val_loss: 7609.8577 - val_mean_squared_error: 7609.8574\n",
      "Epoch 13/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 5267.1099 - mean_squared_error: 5267.1094 - val_loss: 3390.1809 - val_mean_squared_error: 3390.1812\n",
      "Epoch 14/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 2349.2026 - mean_squared_error: 2349.2024 - val_loss: 1512.8202 - val_mean_squared_error: 1512.8202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 1050.9138 - mean_squared_error: 1050.9138 - val_loss: 677.7497 - val_mean_squared_error: 677.7498\n",
      "Epoch 16/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 473.3040 - mean_squared_error: 473.3041 - val_loss: 306.5498 - val_mean_squared_error: 306.5498\n",
      "Epoch 17/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 216.2328 - mean_squared_error: 216.2328 - val_loss: 141.6104 - val_mean_squared_error: 141.6104\n",
      "Epoch 18/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 101.8305 - mean_squared_error: 101.8305 - val_loss: 68.3015 - val_mean_squared_error: 68.3015\n",
      "Epoch 19/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 50.9596 - mean_squared_error: 50.9596 - val_loss: 35.6806 - val_mean_squared_error: 35.6806\n",
      "Epoch 20/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 28.3154 - mean_squared_error: 28.3154 - val_loss: 21.2680 - val_mean_squared_error: 21.2680\n",
      "Epoch 21/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 18.2491 - mean_squared_error: 18.2491 - val_loss: 14.8801 - val_mean_squared_error: 14.8801\n",
      "Epoch 22/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 13.7718 - mean_squared_error: 13.7718 - val_loss: 12.0620 - val_mean_squared_error: 12.0620\n",
      "Epoch 23/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 11.7826 - mean_squared_error: 11.7826 - val_loss: 10.8208 - val_mean_squared_error: 10.8208\n",
      "Epoch 24/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.9005 - mean_squared_error: 10.9005 - val_loss: 10.2778 - val_mean_squared_error: 10.2778\n",
      "Epoch 25/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.5070 - mean_squared_error: 10.5070 - val_loss: 10.0467 - val_mean_squared_error: 10.0467\n",
      "Epoch 26/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.3309 - mean_squared_error: 10.3309 - val_loss: 9.9474 - val_mean_squared_error: 9.9474\n",
      "Epoch 27/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.2525 - mean_squared_error: 10.2525 - val_loss: 9.9065 - val_mean_squared_error: 9.9065\n",
      "Epoch 28/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.2183 - mean_squared_error: 10.2183 - val_loss: 9.8894 - val_mean_squared_error: 9.8894\n",
      "Epoch 29/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.2020 - mean_squared_error: 10.2020 - val_loss: 9.8845 - val_mean_squared_error: 9.8845\n",
      "Epoch 30/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1950 - mean_squared_error: 10.1950 - val_loss: 9.8821 - val_mean_squared_error: 9.8821\n",
      "Epoch 31/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1921 - mean_squared_error: 10.1921 - val_loss: 9.8815 - val_mean_squared_error: 9.8815\n",
      "Epoch 32/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1901 - mean_squared_error: 10.1901 - val_loss: 9.8823 - val_mean_squared_error: 9.8823\n",
      "Epoch 33/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1896 - mean_squared_error: 10.1896 - val_loss: 9.8826 - val_mean_squared_error: 9.8826\n",
      "Epoch 34/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1899 - mean_squared_error: 10.1899 - val_loss: 9.8829 - val_mean_squared_error: 9.8829\n",
      "Epoch 35/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1894 - mean_squared_error: 10.1894 - val_loss: 9.8832 - val_mean_squared_error: 9.8832\n",
      "Epoch 36/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1892 - mean_squared_error: 10.1892 - val_loss: 9.8834 - val_mean_squared_error: 9.8834\n",
      "Epoch 37/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1891 - mean_squared_error: 10.1891 - val_loss: 9.8840 - val_mean_squared_error: 9.8840\n",
      "Epoch 38/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1891 - mean_squared_error: 10.1891 - val_loss: 9.8831 - val_mean_squared_error: 9.8831\n",
      "Epoch 39/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1896 - mean_squared_error: 10.1896 - val_loss: 9.8837 - val_mean_squared_error: 9.8837\n",
      "Epoch 40/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1895 - mean_squared_error: 10.1895 - val_loss: 9.8835 - val_mean_squared_error: 9.8835\n",
      "Epoch 41/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1896 - mean_squared_error: 10.1896 - val_loss: 9.8838 - val_mean_squared_error: 9.8838\n",
      "Epoch 42/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1888 - mean_squared_error: 10.1888 - val_loss: 9.8837 - val_mean_squared_error: 9.8837\n",
      "Epoch 43/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1892 - mean_squared_error: 10.1892 - val_loss: 9.8834 - val_mean_squared_error: 9.8834\n",
      "Epoch 44/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1893 - mean_squared_error: 10.1893 - val_loss: 9.8838 - val_mean_squared_error: 9.8838\n",
      "Epoch 45/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1892 - mean_squared_error: 10.1892 - val_loss: 9.8836 - val_mean_squared_error: 9.8836\n",
      "Epoch 46/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1894 - mean_squared_error: 10.1894 - val_loss: 9.8835 - val_mean_squared_error: 9.8835\n",
      "Epoch 47/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1892 - mean_squared_error: 10.1892 - val_loss: 9.8839 - val_mean_squared_error: 9.8839\n",
      "Epoch 48/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1896 - mean_squared_error: 10.1896 - val_loss: 9.8839 - val_mean_squared_error: 9.8839\n",
      "Epoch 49/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1891 - mean_squared_error: 10.1891 - val_loss: 9.8834 - val_mean_squared_error: 9.8834\n",
      "Epoch 50/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1887 - mean_squared_error: 10.1887 - val_loss: 9.8837 - val_mean_squared_error: 9.8837\n",
      "Epoch 51/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1889 - mean_squared_error: 10.1889 - val_loss: 9.8832 - val_mean_squared_error: 9.8832\n",
      "Epoch 52/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1890 - mean_squared_error: 10.1890 - val_loss: 9.8839 - val_mean_squared_error: 9.8839\n",
      "Epoch 53/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1893 - mean_squared_error: 10.1893 - val_loss: 9.8831 - val_mean_squared_error: 9.8831\n",
      "Epoch 54/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1890 - mean_squared_error: 10.1890 - val_loss: 9.8836 - val_mean_squared_error: 9.8836\n",
      "Epoch 55/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1892 - mean_squared_error: 10.1892 - val_loss: 9.8837 - val_mean_squared_error: 9.8837\n",
      "Epoch 56/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1891 - mean_squared_error: 10.1891 - val_loss: 9.8838 - val_mean_squared_error: 9.8838\n",
      "Epoch 57/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1895 - mean_squared_error: 10.1895 - val_loss: 9.8837 - val_mean_squared_error: 9.8837\n",
      "Epoch 58/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1889 - mean_squared_error: 10.1889 - val_loss: 9.8831 - val_mean_squared_error: 9.8831\n",
      "Epoch 59/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1894 - mean_squared_error: 10.1894 - val_loss: 9.8838 - val_mean_squared_error: 9.8838\n",
      "Epoch 60/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1892 - mean_squared_error: 10.1892 - val_loss: 9.8836 - val_mean_squared_error: 9.8836\n",
      "Epoch 61/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1894 - mean_squared_error: 10.1894 - val_loss: 9.8846 - val_mean_squared_error: 9.8846\n",
      "Epoch 62/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1889 - mean_squared_error: 10.1889 - val_loss: 9.8837 - val_mean_squared_error: 9.8837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1895 - mean_squared_error: 10.1895 - val_loss: 9.8837 - val_mean_squared_error: 9.8837\n",
      "Epoch 64/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1891 - mean_squared_error: 10.1891 - val_loss: 9.8841 - val_mean_squared_error: 9.8841\n",
      "Epoch 65/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1890 - mean_squared_error: 10.1890 - val_loss: 9.8840 - val_mean_squared_error: 9.8840\n",
      "Epoch 66/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1893 - mean_squared_error: 10.1893 - val_loss: 9.8829 - val_mean_squared_error: 9.8829\n",
      "Epoch 67/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1892 - mean_squared_error: 10.1892 - val_loss: 9.8839 - val_mean_squared_error: 9.8839\n",
      "Epoch 68/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1890 - mean_squared_error: 10.1890 - val_loss: 9.8845 - val_mean_squared_error: 9.8845\n",
      "Epoch 69/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1893 - mean_squared_error: 10.1893 - val_loss: 9.8843 - val_mean_squared_error: 9.8843\n",
      "Epoch 70/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 10.1894 - mean_squared_error: 10.1894 - val_loss: 9.8844 - val_mean_squared_error: 9.8844\n",
      "Epoch 71/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1891 - mean_squared_error: 10.1891 - val_loss: 9.8838 - val_mean_squared_error: 9.8838\n",
      "Epoch 72/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1900 - mean_squared_error: 10.1900 - val_loss: 9.8841 - val_mean_squared_error: 9.8841\n",
      "Epoch 73/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1896 - mean_squared_error: 10.1896 - val_loss: 9.8845 - val_mean_squared_error: 9.8845\n",
      "Epoch 74/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 10.1893 - mean_squared_error: 10.1893 - val_loss: 9.8837 - val_mean_squared_error: 9.8837\n",
      "Epoch 75/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1899 - mean_squared_error: 10.1899 - val_loss: 9.8838 - val_mean_squared_error: 9.8838\n",
      "Epoch 76/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1892 - mean_squared_error: 10.1892 - val_loss: 9.8841 - val_mean_squared_error: 9.8841\n",
      "Epoch 77/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1890 - mean_squared_error: 10.1890 - val_loss: 9.8842 - val_mean_squared_error: 9.8842\n",
      "Epoch 78/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1896 - mean_squared_error: 10.1896 - val_loss: 9.8831 - val_mean_squared_error: 9.8831\n",
      "Epoch 79/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1903 - mean_squared_error: 10.1903 - val_loss: 9.8846 - val_mean_squared_error: 9.8846\n",
      "Epoch 80/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1892 - mean_squared_error: 10.1892 - val_loss: 9.8841 - val_mean_squared_error: 9.8841\n",
      "Epoch 81/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1899 - mean_squared_error: 10.1899 - val_loss: 9.8841 - val_mean_squared_error: 9.8841\n",
      "Epoch 82/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1891 - mean_squared_error: 10.1891 - val_loss: 9.8843 - val_mean_squared_error: 9.8843\n",
      "Epoch 83/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1893 - mean_squared_error: 10.1893 - val_loss: 9.8842 - val_mean_squared_error: 9.8842\n",
      "Epoch 84/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1895 - mean_squared_error: 10.1895 - val_loss: 9.8845 - val_mean_squared_error: 9.8845\n",
      "Epoch 85/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1890 - mean_squared_error: 10.1890 - val_loss: 9.8832 - val_mean_squared_error: 9.8832\n",
      "Epoch 86/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1891 - mean_squared_error: 10.1891 - val_loss: 9.8835 - val_mean_squared_error: 9.8835\n",
      "Epoch 87/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 10.1893 - mean_squared_error: 10.1893 - val_loss: 9.8837 - val_mean_squared_error: 9.8837\n",
      "Epoch 88/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 10.1890 - mean_squared_error: 10.1890 - val_loss: 9.8835 - val_mean_squared_error: 9.8835\n",
      "Epoch 89/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1892 - mean_squared_error: 10.1892 - val_loss: 9.8836 - val_mean_squared_error: 9.8836\n",
      "Epoch 90/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 10.1890 - mean_squared_error: 10.1890 - val_loss: 9.8836 - val_mean_squared_error: 9.8836\n",
      "Epoch 91/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1890 - mean_squared_error: 10.1890 - val_loss: 9.8835 - val_mean_squared_error: 9.8835\n",
      "Epoch 92/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1889 - mean_squared_error: 10.1889 - val_loss: 9.8842 - val_mean_squared_error: 9.8842\n",
      "Epoch 93/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1895 - mean_squared_error: 10.1895 - val_loss: 9.8832 - val_mean_squared_error: 9.8832\n",
      "Epoch 94/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1891 - mean_squared_error: 10.1891 - val_loss: 9.8843 - val_mean_squared_error: 9.8843\n",
      "Epoch 95/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1891 - mean_squared_error: 10.1891 - val_loss: 9.8843 - val_mean_squared_error: 9.8843\n",
      "Epoch 96/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1890 - mean_squared_error: 10.1890 - val_loss: 9.8841 - val_mean_squared_error: 9.8841\n",
      "Epoch 97/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1890 - mean_squared_error: 10.1890 - val_loss: 9.8838 - val_mean_squared_error: 9.8838\n",
      "Epoch 98/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1894 - mean_squared_error: 10.1894 - val_loss: 9.8837 - val_mean_squared_error: 9.8837\n",
      "Epoch 99/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1893 - mean_squared_error: 10.1893 - val_loss: 9.8838 - val_mean_squared_error: 9.8838\n",
      "Epoch 100/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1891 - mean_squared_error: 10.1891 - val_loss: 9.8840 - val_mean_squared_error: 9.8840\n",
      "Epoch 101/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 10.1890 - mean_squared_error: 10.1890 - val_loss: 9.8839 - val_mean_squared_error: 9.8839\n",
      "Epoch 102/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 10.1891 - mean_squared_error: 10.1891 - val_loss: 9.8837 - val_mean_squared_error: 9.8837\n",
      "Epoch 103/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1894 - mean_squared_error: 10.1894 - val_loss: 9.8840 - val_mean_squared_error: 9.8840\n",
      "Epoch 104/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 10.1894 - mean_squared_error: 10.1894 - val_loss: 9.8842 - val_mean_squared_error: 9.8842\n",
      "Epoch 105/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1890 - mean_squared_error: 10.1890 - val_loss: 9.8838 - val_mean_squared_error: 9.8838\n",
      "Epoch 106/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1893 - mean_squared_error: 10.1893 - val_loss: 9.8841 - val_mean_squared_error: 9.8841\n",
      "Epoch 107/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1894 - mean_squared_error: 10.1894 - val_loss: 9.8837 - val_mean_squared_error: 9.8837\n",
      "Epoch 108/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1893 - mean_squared_error: 10.1893 - val_loss: 9.8840 - val_mean_squared_error: 9.8840\n",
      "Epoch 109/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1891 - mean_squared_error: 10.1891 - val_loss: 9.8838 - val_mean_squared_error: 9.8838\n",
      "Epoch 110/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1893 - mean_squared_error: 10.1893 - val_loss: 9.8842 - val_mean_squared_error: 9.8842\n",
      "Epoch 111/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1890 - mean_squared_error: 10.1890 - val_loss: 9.8837 - val_mean_squared_error: 9.8837\n",
      "Epoch 112/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1889 - mean_squared_error: 10.1889 - val_loss: 9.8842 - val_mean_squared_error: 9.8842\n",
      "Epoch 113/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1893 - mean_squared_error: 10.1893 - val_loss: 9.8833 - val_mean_squared_error: 9.8833\n",
      "Epoch 114/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1892 - mean_squared_error: 10.1892 - val_loss: 9.8833 - val_mean_squared_error: 9.8833\n",
      "Epoch 115/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1888 - mean_squared_error: 10.1888 - val_loss: 9.8838 - val_mean_squared_error: 9.8838\n",
      "Epoch 116/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1891 - mean_squared_error: 10.1891 - val_loss: 9.8841 - val_mean_squared_error: 9.8841\n",
      "Epoch 117/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1894 - mean_squared_error: 10.1894 - val_loss: 9.8839 - val_mean_squared_error: 9.8839\n",
      "Epoch 118/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1895 - mean_squared_error: 10.1895 - val_loss: 9.8830 - val_mean_squared_error: 9.8830\n",
      "Epoch 119/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1889 - mean_squared_error: 10.1889 - val_loss: 9.8841 - val_mean_squared_error: 9.8841\n",
      "Epoch 120/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1889 - mean_squared_error: 10.1889 - val_loss: 9.8840 - val_mean_squared_error: 9.8840\n",
      "Epoch 121/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1891 - mean_squared_error: 10.1891 - val_loss: 9.8842 - val_mean_squared_error: 9.8842\n",
      "Epoch 122/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1893 - mean_squared_error: 10.1893 - val_loss: 9.8843 - val_mean_squared_error: 9.8843\n",
      "Epoch 123/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1892 - mean_squared_error: 10.1892 - val_loss: 9.8840 - val_mean_squared_error: 9.8840\n",
      "Epoch 124/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1891 - mean_squared_error: 10.1891 - val_loss: 9.8835 - val_mean_squared_error: 9.8835\n",
      "Epoch 125/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1894 - mean_squared_error: 10.1894 - val_loss: 9.8834 - val_mean_squared_error: 9.8834\n",
      "Epoch 126/200\n",
      "1819/1819 [==============================] - 2s 1ms/sample - loss: 10.1891 - mean_squared_error: 10.1891 - val_loss: 9.8839 - val_mean_squared_error: 9.8839\n",
      "Epoch 127/200\n",
      "1819/1819 [==============================] - 3s 1ms/sample - loss: 10.1894 - mean_squared_error: 10.1894 - val_loss: 9.8837 - val_mean_squared_error: 9.8837\n",
      "==================================================\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 94, 94, 5)         50        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 47, 47, 5)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 46, 46, 10)        210       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 23, 23, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 22, 22, 20)        820       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 11, 11, 20)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2420)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 500)               1210500   \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 30)                15030     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 30)                0         \n",
      "=================================================================\n",
      "Total params: 1,477,110\n",
      "Trainable params: 1,477,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "==================================================\n",
      "Train on 1819 samples, validate on 321 samples\n",
      "Epoch 1/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 232.4983 - mean_squared_error: 232.4984 - val_loss: 16.3830 - val_mean_squared_error: 16.3830\n",
      "Epoch 2/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 14.3561 - mean_squared_error: 14.3561 - val_loss: 13.0597 - val_mean_squared_error: 13.0597\n",
      "Epoch 3/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 12.1935 - mean_squared_error: 12.1935 - val_loss: 11.0513 - val_mean_squared_error: 11.0513\n",
      "Epoch 4/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 11.0716 - mean_squared_error: 11.0716 - val_loss: 11.7795 - val_mean_squared_error: 11.7795\n",
      "Epoch 5/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 11.2190 - mean_squared_error: 11.2190 - val_loss: 11.1910 - val_mean_squared_error: 11.1910\n",
      "Epoch 6/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 10.4268 - mean_squared_error: 10.4268 - val_loss: 10.8075 - val_mean_squared_error: 10.8075\n",
      "Epoch 7/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 10.1184 - mean_squared_error: 10.1184 - val_loss: 9.7514 - val_mean_squared_error: 9.7514\n",
      "Epoch 8/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 9.9823 - mean_squared_error: 9.9823 - val_loss: 9.4808 - val_mean_squared_error: 9.4808\n",
      "Epoch 9/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 10.2765 - mean_squared_error: 10.2765 - val_loss: 9.4538 - val_mean_squared_error: 9.4538\n",
      "Epoch 10/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 9.5277 - mean_squared_error: 9.5277 - val_loss: 9.7960 - val_mean_squared_error: 9.7960\n",
      "Epoch 11/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 9.5245 - mean_squared_error: 9.5245 - val_loss: 9.3252 - val_mean_squared_error: 9.3252\n",
      "Epoch 12/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 9.5917 - mean_squared_error: 9.5917 - val_loss: 9.3910 - val_mean_squared_error: 9.3910\n",
      "Epoch 13/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 9.2536 - mean_squared_error: 9.2536 - val_loss: 9.0150 - val_mean_squared_error: 9.0150\n",
      "Epoch 14/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 9.2246 - mean_squared_error: 9.2246 - val_loss: 8.9738 - val_mean_squared_error: 8.9738\n",
      "Epoch 15/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 9.1451 - mean_squared_error: 9.1451 - val_loss: 9.1198 - val_mean_squared_error: 9.1198\n",
      "Epoch 16/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 9.1101 - mean_squared_error: 9.1101 - val_loss: 9.4810 - val_mean_squared_error: 9.4810\n",
      "Epoch 17/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 9.0472 - mean_squared_error: 9.0472 - val_loss: 8.8540 - val_mean_squared_error: 8.8540\n",
      "Epoch 18/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 9.0974 - mean_squared_error: 9.0974 - val_loss: 8.8788 - val_mean_squared_error: 8.8788\n",
      "Epoch 19/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 8.9140 - mean_squared_error: 8.9140 - val_loss: 8.7684 - val_mean_squared_error: 8.7684\n",
      "Epoch 20/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 8.7044 - mean_squared_error: 8.7044 - val_loss: 8.9578 - val_mean_squared_error: 8.9578\n",
      "Epoch 21/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 8.5022 - mean_squared_error: 8.5022 - val_loss: 8.5452 - val_mean_squared_error: 8.5452\n",
      "Epoch 22/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 8.4160 - mean_squared_error: 8.4160 - val_loss: 8.5869 - val_mean_squared_error: 8.5869\n",
      "Epoch 23/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 8.3058 - mean_squared_error: 8.3058 - val_loss: 8.1946 - val_mean_squared_error: 8.1946\n",
      "Epoch 24/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 8.0228 - mean_squared_error: 8.0228 - val_loss: 8.4364 - val_mean_squared_error: 8.4364\n",
      "Epoch 25/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 8.0139 - mean_squared_error: 8.0139 - val_loss: 8.6059 - val_mean_squared_error: 8.6059\n",
      "Epoch 26/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 7.7522 - mean_squared_error: 7.7522 - val_loss: 7.8129 - val_mean_squared_error: 7.8129\n",
      "Epoch 27/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 7.6230 - mean_squared_error: 7.6230 - val_loss: 7.9358 - val_mean_squared_error: 7.9358\n",
      "Epoch 28/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 7.3756 - mean_squared_error: 7.3756 - val_loss: 7.5396 - val_mean_squared_error: 7.5396\n",
      "Epoch 29/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 7.2110 - mean_squared_error: 7.2110 - val_loss: 7.7049 - val_mean_squared_error: 7.7049\n",
      "Epoch 30/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 7.0750 - mean_squared_error: 7.0750 - val_loss: 7.1934 - val_mean_squared_error: 7.1934\n",
      "Epoch 31/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 6.8430 - mean_squared_error: 6.8430 - val_loss: 7.0024 - val_mean_squared_error: 7.0024\n",
      "Epoch 32/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 6.8571 - mean_squared_error: 6.8571 - val_loss: 7.1901 - val_mean_squared_error: 7.1901\n",
      "Epoch 33/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 7.0318 - mean_squared_error: 7.0318 - val_loss: 6.9615 - val_mean_squared_error: 6.9615\n",
      "Epoch 34/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 6.5267 - mean_squared_error: 6.5267 - val_loss: 6.9493 - val_mean_squared_error: 6.9493\n",
      "Epoch 35/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 6.4586 - mean_squared_error: 6.4586 - val_loss: 6.5019 - val_mean_squared_error: 6.5019\n",
      "Epoch 36/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 6.2097 - mean_squared_error: 6.2097 - val_loss: 6.4231 - val_mean_squared_error: 6.4231\n",
      "Epoch 37/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 6.0981 - mean_squared_error: 6.0981 - val_loss: 9.0183 - val_mean_squared_error: 9.0183\n",
      "Epoch 38/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 6.0522 - mean_squared_error: 6.0522 - val_loss: 6.3352 - val_mean_squared_error: 6.3352\n",
      "Epoch 39/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 5.7814 - mean_squared_error: 5.7814 - val_loss: 6.0979 - val_mean_squared_error: 6.0979\n",
      "Epoch 40/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 5.7264 - mean_squared_error: 5.7264 - val_loss: 6.7712 - val_mean_squared_error: 6.7712\n",
      "Epoch 41/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 5.9004 - mean_squared_error: 5.9004 - val_loss: 6.0606 - val_mean_squared_error: 6.0606\n",
      "Epoch 42/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 5.6194 - mean_squared_error: 5.6194 - val_loss: 5.9303 - val_mean_squared_error: 5.9303\n",
      "Epoch 43/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 5.3934 - mean_squared_error: 5.3934 - val_loss: 5.6200 - val_mean_squared_error: 5.6200\n",
      "Epoch 44/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 5.5425 - mean_squared_error: 5.5425 - val_loss: 6.1650 - val_mean_squared_error: 6.1650\n",
      "Epoch 45/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 5.3619 - mean_squared_error: 5.3619 - val_loss: 5.5800 - val_mean_squared_error: 5.5800\n",
      "Epoch 46/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 5.1601 - mean_squared_error: 5.1601 - val_loss: 5.8544 - val_mean_squared_error: 5.8544\n",
      "Epoch 47/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 5.1982 - mean_squared_error: 5.1982 - val_loss: 5.4362 - val_mean_squared_error: 5.4362\n",
      "Epoch 48/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 4.8900 - mean_squared_error: 4.8900 - val_loss: 5.8089 - val_mean_squared_error: 5.8089\n",
      "Epoch 49/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 5.1290 - mean_squared_error: 5.1290 - val_loss: 5.4613 - val_mean_squared_error: 5.4613\n",
      "Epoch 50/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 4.8148 - mean_squared_error: 4.8148 - val_loss: 5.2571 - val_mean_squared_error: 5.2571\n",
      "Epoch 51/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 4.7681 - mean_squared_error: 4.7681 - val_loss: 5.2404 - val_mean_squared_error: 5.2404\n",
      "Epoch 52/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 4.7184 - mean_squared_error: 4.7184 - val_loss: 6.2573 - val_mean_squared_error: 6.2573\n",
      "Epoch 53/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 4.6956 - mean_squared_error: 4.6956 - val_loss: 4.9681 - val_mean_squared_error: 4.9681\n",
      "Epoch 54/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 4.5663 - mean_squared_error: 4.5663 - val_loss: 5.8617 - val_mean_squared_error: 5.8617\n",
      "Epoch 55/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 4.4657 - mean_squared_error: 4.4657 - val_loss: 5.2308 - val_mean_squared_error: 5.2308\n",
      "Epoch 56/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 4.7932 - mean_squared_error: 4.7932 - val_loss: 5.1768 - val_mean_squared_error: 5.1768\n",
      "Epoch 57/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 4.5281 - mean_squared_error: 4.5281 - val_loss: 5.0168 - val_mean_squared_error: 5.0168\n",
      "Epoch 58/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 4.4263 - mean_squared_error: 4.4263 - val_loss: 4.6805 - val_mean_squared_error: 4.6805\n",
      "Epoch 59/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 4.3619 - mean_squared_error: 4.3619 - val_loss: 4.6870 - val_mean_squared_error: 4.6870\n",
      "Epoch 60/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 4.1897 - mean_squared_error: 4.1897 - val_loss: 4.9000 - val_mean_squared_error: 4.9000\n",
      "Epoch 61/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 4.1070 - mean_squared_error: 4.1070 - val_loss: 4.6746 - val_mean_squared_error: 4.6746\n",
      "Epoch 62/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 4.1350 - mean_squared_error: 4.1350 - val_loss: 5.3820 - val_mean_squared_error: 5.3820\n",
      "Epoch 63/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 4.0462 - mean_squared_error: 4.0462 - val_loss: 4.3876 - val_mean_squared_error: 4.3876\n",
      "Epoch 64/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 3.9083 - mean_squared_error: 3.9083 - val_loss: 4.5449 - val_mean_squared_error: 4.5449\n",
      "Epoch 65/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 4.0255 - mean_squared_error: 4.0255 - val_loss: 4.4332 - val_mean_squared_error: 4.4332\n",
      "Epoch 66/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: 3.9725 - mean_squared_error: 3.9725 - val_loss: 4.3071 - val_mean_squared_error: 4.3071\n",
      "Epoch 67/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 3.7984 - mean_squared_error: 3.7984 - val_loss: 4.1480 - val_mean_squared_error: 4.1480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 3.8082 - mean_squared_error: 3.8082 - val_loss: 4.3932 - val_mean_squared_error: 4.3932\n",
      "Epoch 69/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 3.8425 - mean_squared_error: 3.8425 - val_loss: 4.2441 - val_mean_squared_error: 4.2441\n",
      "Epoch 70/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 3.6345 - mean_squared_error: 3.6345 - val_loss: 4.8376 - val_mean_squared_error: 4.8376\n",
      "Epoch 71/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 3.7103 - mean_squared_error: 3.7103 - val_loss: 4.9922 - val_mean_squared_error: 4.9922\n",
      "Epoch 72/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 3.6714 - mean_squared_error: 3.6714 - val_loss: 4.1341 - val_mean_squared_error: 4.1341\n",
      "Epoch 73/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 3.5675 - mean_squared_error: 3.5675 - val_loss: 4.0222 - val_mean_squared_error: 4.0222\n",
      "Epoch 74/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 3.7151 - mean_squared_error: 3.7151 - val_loss: 4.2283 - val_mean_squared_error: 4.2283\n",
      "Epoch 75/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 3.4804 - mean_squared_error: 3.4804 - val_loss: 3.9282 - val_mean_squared_error: 3.9282\n",
      "Epoch 76/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 3.6050 - mean_squared_error: 3.6050 - val_loss: 4.9590 - val_mean_squared_error: 4.9590\n",
      "Epoch 77/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 3.5844 - mean_squared_error: 3.5844 - val_loss: 4.0998 - val_mean_squared_error: 4.0998\n",
      "Epoch 78/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 3.3956 - mean_squared_error: 3.3956 - val_loss: 3.9826 - val_mean_squared_error: 3.9826\n",
      "Epoch 79/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 3.3944 - mean_squared_error: 3.3944 - val_loss: 4.2354 - val_mean_squared_error: 4.2354\n",
      "Epoch 80/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 3.3551 - mean_squared_error: 3.3551 - val_loss: 4.4443 - val_mean_squared_error: 4.4443\n",
      "Epoch 81/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 3.3287 - mean_squared_error: 3.3287 - val_loss: 3.9694 - val_mean_squared_error: 3.9694\n",
      "Epoch 82/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 3.4820 - mean_squared_error: 3.4820 - val_loss: 4.0757 - val_mean_squared_error: 4.0757\n",
      "Epoch 83/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 3.2138 - mean_squared_error: 3.2138 - val_loss: 3.7527 - val_mean_squared_error: 3.7527\n",
      "Epoch 84/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 3.2317 - mean_squared_error: 3.2317 - val_loss: 3.8295 - val_mean_squared_error: 3.8295\n",
      "Epoch 85/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 3.2165 - mean_squared_error: 3.2165 - val_loss: 3.9025 - val_mean_squared_error: 3.9025\n",
      "Epoch 86/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 3.2577 - mean_squared_error: 3.2577 - val_loss: 3.9291 - val_mean_squared_error: 3.9291\n",
      "Epoch 87/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 3.2054 - mean_squared_error: 3.2054 - val_loss: 4.3497 - val_mean_squared_error: 4.3497\n",
      "Epoch 88/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 3.1563 - mean_squared_error: 3.1563 - val_loss: 3.8388 - val_mean_squared_error: 3.8388\n",
      "Epoch 89/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 3.1058 - mean_squared_error: 3.1058 - val_loss: 3.6593 - val_mean_squared_error: 3.6593\n",
      "Epoch 90/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 3.0574 - mean_squared_error: 3.0574 - val_loss: 3.6763 - val_mean_squared_error: 3.6763\n",
      "Epoch 91/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 3.0758 - mean_squared_error: 3.0758 - val_loss: 3.6642 - val_mean_squared_error: 3.6642\n",
      "Epoch 92/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.9625 - mean_squared_error: 2.9625 - val_loss: 3.6765 - val_mean_squared_error: 3.6765\n",
      "Epoch 93/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 3.1590 - mean_squared_error: 3.1590 - val_loss: 4.1599 - val_mean_squared_error: 4.1599\n",
      "Epoch 94/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 3.1881 - mean_squared_error: 3.1881 - val_loss: 3.7937 - val_mean_squared_error: 3.7937\n",
      "Epoch 95/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.8695 - mean_squared_error: 2.8695 - val_loss: 3.6360 - val_mean_squared_error: 3.6360\n",
      "Epoch 96/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.7902 - mean_squared_error: 2.7902 - val_loss: 3.7153 - val_mean_squared_error: 3.7153\n",
      "Epoch 97/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.7770 - mean_squared_error: 2.7770 - val_loss: 3.8314 - val_mean_squared_error: 3.8314\n",
      "Epoch 98/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.9309 - mean_squared_error: 2.9309 - val_loss: 3.5564 - val_mean_squared_error: 3.5563\n",
      "Epoch 99/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.8949 - mean_squared_error: 2.8949 - val_loss: 3.7136 - val_mean_squared_error: 3.7136\n",
      "Epoch 100/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.8927 - mean_squared_error: 2.8927 - val_loss: 4.0816 - val_mean_squared_error: 4.0816\n",
      "Epoch 101/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.7608 - mean_squared_error: 2.7608 - val_loss: 4.0647 - val_mean_squared_error: 4.0647\n",
      "Epoch 102/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.8081 - mean_squared_error: 2.8081 - val_loss: 3.4536 - val_mean_squared_error: 3.4536\n",
      "Epoch 103/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.6061 - mean_squared_error: 2.6061 - val_loss: 3.4660 - val_mean_squared_error: 3.4660\n",
      "Epoch 104/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.6786 - mean_squared_error: 2.6786 - val_loss: 3.4615 - val_mean_squared_error: 3.4615\n",
      "Epoch 105/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.6368 - mean_squared_error: 2.6368 - val_loss: 3.5571 - val_mean_squared_error: 3.5571\n",
      "Epoch 106/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.5545 - mean_squared_error: 2.5545 - val_loss: 3.5347 - val_mean_squared_error: 3.5347\n",
      "Epoch 107/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.5057 - mean_squared_error: 2.5057 - val_loss: 3.4437 - val_mean_squared_error: 3.4437\n",
      "Epoch 108/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.4623 - mean_squared_error: 2.4623 - val_loss: 3.4154 - val_mean_squared_error: 3.4154\n",
      "Epoch 109/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.4505 - mean_squared_error: 2.4505 - val_loss: 3.3548 - val_mean_squared_error: 3.3548\n",
      "Epoch 110/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.3766 - mean_squared_error: 2.3766 - val_loss: 3.3865 - val_mean_squared_error: 3.3865\n",
      "Epoch 111/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.4330 - mean_squared_error: 2.4330 - val_loss: 3.5121 - val_mean_squared_error: 3.5121\n",
      "Epoch 112/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.3694 - mean_squared_error: 2.3694 - val_loss: 3.3546 - val_mean_squared_error: 3.3546\n",
      "Epoch 113/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.3519 - mean_squared_error: 2.3519 - val_loss: 3.4479 - val_mean_squared_error: 3.4479\n",
      "Epoch 114/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.3326 - mean_squared_error: 2.3326 - val_loss: 3.3342 - val_mean_squared_error: 3.3342\n",
      "Epoch 115/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.3165 - mean_squared_error: 2.3165 - val_loss: 3.2095 - val_mean_squared_error: 3.2095\n",
      "Epoch 116/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.3204 - mean_squared_error: 2.3204 - val_loss: 3.1415 - val_mean_squared_error: 3.1415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.2437 - mean_squared_error: 2.2437 - val_loss: 3.4887 - val_mean_squared_error: 3.4887\n",
      "Epoch 118/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.2471 - mean_squared_error: 2.2471 - val_loss: 3.4721 - val_mean_squared_error: 3.4721\n",
      "Epoch 119/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.2592 - mean_squared_error: 2.2592 - val_loss: 3.2886 - val_mean_squared_error: 3.2886\n",
      "Epoch 120/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.2032 - mean_squared_error: 2.2032 - val_loss: 3.1801 - val_mean_squared_error: 3.1801\n",
      "Epoch 121/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.1056 - mean_squared_error: 2.1056 - val_loss: 3.2476 - val_mean_squared_error: 3.2476\n",
      "Epoch 122/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.0628 - mean_squared_error: 2.0628 - val_loss: 3.1301 - val_mean_squared_error: 3.1301\n",
      "Epoch 123/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.0536 - mean_squared_error: 2.0536 - val_loss: 3.2639 - val_mean_squared_error: 3.2639\n",
      "Epoch 124/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.0336 - mean_squared_error: 2.0336 - val_loss: 3.1176 - val_mean_squared_error: 3.1176\n",
      "Epoch 125/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.0066 - mean_squared_error: 2.0066 - val_loss: 3.2185 - val_mean_squared_error: 3.2185\n",
      "Epoch 126/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.0888 - mean_squared_error: 2.0888 - val_loss: 3.2372 - val_mean_squared_error: 3.2372\n",
      "Epoch 127/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 2.2882 - mean_squared_error: 2.2882 - val_loss: 3.2004 - val_mean_squared_error: 3.2004\n",
      "Epoch 128/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.9509 - mean_squared_error: 1.9509 - val_loss: 3.1317 - val_mean_squared_error: 3.1317\n",
      "Epoch 129/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.9636 - mean_squared_error: 1.9636 - val_loss: 3.2477 - val_mean_squared_error: 3.2477\n",
      "Epoch 130/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.9350 - mean_squared_error: 1.9350 - val_loss: 3.1630 - val_mean_squared_error: 3.1630\n",
      "Epoch 131/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.9125 - mean_squared_error: 1.9125 - val_loss: 3.1429 - val_mean_squared_error: 3.1429\n",
      "Epoch 132/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.9084 - mean_squared_error: 1.9084 - val_loss: 3.1570 - val_mean_squared_error: 3.1570\n",
      "Epoch 133/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.8168 - mean_squared_error: 1.8168 - val_loss: 3.0748 - val_mean_squared_error: 3.0748\n",
      "Epoch 134/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.8279 - mean_squared_error: 1.8279 - val_loss: 3.6463 - val_mean_squared_error: 3.6463\n",
      "Epoch 135/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.8770 - mean_squared_error: 1.8770 - val_loss: 3.1130 - val_mean_squared_error: 3.1130\n",
      "Epoch 136/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.8814 - mean_squared_error: 1.8814 - val_loss: 3.5021 - val_mean_squared_error: 3.5021\n",
      "Epoch 137/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.8080 - mean_squared_error: 1.8080 - val_loss: 3.1335 - val_mean_squared_error: 3.1335\n",
      "Epoch 138/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.8311 - mean_squared_error: 1.8311 - val_loss: 2.9989 - val_mean_squared_error: 2.9989\n",
      "Epoch 139/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.7683 - mean_squared_error: 1.7683 - val_loss: 3.1066 - val_mean_squared_error: 3.1066\n",
      "Epoch 140/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.8295 - mean_squared_error: 1.8295 - val_loss: 3.1336 - val_mean_squared_error: 3.1336\n",
      "Epoch 141/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.8854 - mean_squared_error: 1.8854 - val_loss: 3.0660 - val_mean_squared_error: 3.0660\n",
      "Epoch 142/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.7175 - mean_squared_error: 1.7175 - val_loss: 3.2397 - val_mean_squared_error: 3.2397\n",
      "Epoch 143/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.7664 - mean_squared_error: 1.7664 - val_loss: 3.0092 - val_mean_squared_error: 3.0092\n",
      "Epoch 144/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.6701 - mean_squared_error: 1.6701 - val_loss: 3.0862 - val_mean_squared_error: 3.0862\n",
      "Epoch 145/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.6568 - mean_squared_error: 1.6568 - val_loss: 3.0932 - val_mean_squared_error: 3.0932\n",
      "Epoch 146/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.5820 - mean_squared_error: 1.5820 - val_loss: 2.9662 - val_mean_squared_error: 2.9662\n",
      "Epoch 147/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.6789 - mean_squared_error: 1.6789 - val_loss: 3.3067 - val_mean_squared_error: 3.3067\n",
      "Epoch 148/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.6607 - mean_squared_error: 1.6607 - val_loss: 3.2400 - val_mean_squared_error: 3.2400\n",
      "Epoch 149/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.5684 - mean_squared_error: 1.5684 - val_loss: 3.0462 - val_mean_squared_error: 3.0462\n",
      "Epoch 150/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.6853 - mean_squared_error: 1.6853 - val_loss: 3.0120 - val_mean_squared_error: 3.0120\n",
      "Epoch 151/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.5696 - mean_squared_error: 1.5696 - val_loss: 2.9915 - val_mean_squared_error: 2.9915\n",
      "Epoch 152/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.5380 - mean_squared_error: 1.5380 - val_loss: 3.1229 - val_mean_squared_error: 3.1229\n",
      "Epoch 153/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.6025 - mean_squared_error: 1.6025 - val_loss: 3.0019 - val_mean_squared_error: 3.0019\n",
      "Epoch 154/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.5594 - mean_squared_error: 1.5594 - val_loss: 3.2529 - val_mean_squared_error: 3.2529\n",
      "Epoch 155/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.5440 - mean_squared_error: 1.5440 - val_loss: 2.9966 - val_mean_squared_error: 2.9966\n",
      "Epoch 156/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.4380 - mean_squared_error: 1.4380 - val_loss: 2.9564 - val_mean_squared_error: 2.9564\n",
      "Epoch 157/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.5991 - mean_squared_error: 1.5991 - val_loss: 3.2186 - val_mean_squared_error: 3.2186\n",
      "Epoch 158/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.4752 - mean_squared_error: 1.4752 - val_loss: 3.0977 - val_mean_squared_error: 3.0977\n",
      "Epoch 159/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.4400 - mean_squared_error: 1.4400 - val_loss: 2.8816 - val_mean_squared_error: 2.8816\n",
      "Epoch 160/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.5844 - mean_squared_error: 1.5844 - val_loss: 2.8765 - val_mean_squared_error: 2.8765\n",
      "Epoch 161/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.4535 - mean_squared_error: 1.4535 - val_loss: 3.0284 - val_mean_squared_error: 3.0284\n",
      "Epoch 162/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.4289 - mean_squared_error: 1.4289 - val_loss: 3.1699 - val_mean_squared_error: 3.1699\n",
      "Epoch 163/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.5034 - mean_squared_error: 1.5034 - val_loss: 2.9012 - val_mean_squared_error: 2.9012\n",
      "Epoch 164/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.4036 - mean_squared_error: 1.4036 - val_loss: 3.2057 - val_mean_squared_error: 3.2057\n",
      "Epoch 165/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.4032 - mean_squared_error: 1.4032 - val_loss: 3.1899 - val_mean_squared_error: 3.1899\n",
      "Epoch 166/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.3323 - mean_squared_error: 1.3323 - val_loss: 3.0060 - val_mean_squared_error: 3.0060\n",
      "Epoch 167/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.3365 - mean_squared_error: 1.3365 - val_loss: 3.0077 - val_mean_squared_error: 3.0077\n",
      "Epoch 168/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.3057 - mean_squared_error: 1.3057 - val_loss: 3.0532 - val_mean_squared_error: 3.0532\n",
      "Epoch 169/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.3339 - mean_squared_error: 1.3339 - val_loss: 3.0125 - val_mean_squared_error: 3.0125\n",
      "Epoch 170/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.3181 - mean_squared_error: 1.3181 - val_loss: 2.8841 - val_mean_squared_error: 2.8841\n",
      "Epoch 171/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.3609 - mean_squared_error: 1.3609 - val_loss: 2.9655 - val_mean_squared_error: 2.9655\n",
      "Epoch 172/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.3044 - mean_squared_error: 1.3044 - val_loss: 3.2257 - val_mean_squared_error: 3.2257\n",
      "Epoch 173/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.3385 - mean_squared_error: 1.3385 - val_loss: 2.9162 - val_mean_squared_error: 2.9162\n",
      "Epoch 174/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.2905 - mean_squared_error: 1.2905 - val_loss: 2.9456 - val_mean_squared_error: 2.9456\n",
      "Epoch 175/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.2628 - mean_squared_error: 1.2628 - val_loss: 2.8408 - val_mean_squared_error: 2.8408\n",
      "Epoch 176/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.2682 - mean_squared_error: 1.2682 - val_loss: 3.0551 - val_mean_squared_error: 3.0551\n",
      "Epoch 177/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.2100 - mean_squared_error: 1.2100 - val_loss: 2.9392 - val_mean_squared_error: 2.9392\n",
      "Epoch 178/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.2664 - mean_squared_error: 1.2664 - val_loss: 3.0462 - val_mean_squared_error: 3.0462\n",
      "Epoch 179/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.1921 - mean_squared_error: 1.1921 - val_loss: 2.8913 - val_mean_squared_error: 2.8913\n",
      "Epoch 180/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.2005 - mean_squared_error: 1.2005 - val_loss: 2.8301 - val_mean_squared_error: 2.8301\n",
      "Epoch 181/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.2046 - mean_squared_error: 1.2046 - val_loss: 2.9913 - val_mean_squared_error: 2.9913\n",
      "Epoch 182/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.1475 - mean_squared_error: 1.1475 - val_loss: 2.9238 - val_mean_squared_error: 2.9238\n",
      "Epoch 183/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.1304 - mean_squared_error: 1.1304 - val_loss: 2.9316 - val_mean_squared_error: 2.9316\n",
      "Epoch 184/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.1501 - mean_squared_error: 1.1501 - val_loss: 2.8826 - val_mean_squared_error: 2.8826\n",
      "Epoch 185/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.1899 - mean_squared_error: 1.1899 - val_loss: 3.0424 - val_mean_squared_error: 3.0424\n",
      "Epoch 186/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.1799 - mean_squared_error: 1.1799 - val_loss: 2.9207 - val_mean_squared_error: 2.9207\n",
      "Epoch 187/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.2117 - mean_squared_error: 1.2117 - val_loss: 3.0163 - val_mean_squared_error: 3.0163\n",
      "Epoch 188/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.0901 - mean_squared_error: 1.0901 - val_loss: 2.8999 - val_mean_squared_error: 2.8999\n",
      "Epoch 189/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.1032 - mean_squared_error: 1.1032 - val_loss: 2.9132 - val_mean_squared_error: 2.9132\n",
      "Epoch 190/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.0990 - mean_squared_error: 1.0990 - val_loss: 2.8541 - val_mean_squared_error: 2.8541\n",
      "Epoch 191/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.1391 - mean_squared_error: 1.1391 - val_loss: 3.1842 - val_mean_squared_error: 3.1842\n",
      "Epoch 192/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.1804 - mean_squared_error: 1.1804 - val_loss: 2.8699 - val_mean_squared_error: 2.8699\n",
      "Epoch 193/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.1062 - mean_squared_error: 1.1062 - val_loss: 2.8596 - val_mean_squared_error: 2.8596\n",
      "Epoch 194/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.1077 - mean_squared_error: 1.1077 - val_loss: 2.8490 - val_mean_squared_error: 2.8490\n",
      "Epoch 195/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.0070 - mean_squared_error: 1.0070 - val_loss: 3.1060 - val_mean_squared_error: 3.1060\n",
      "Epoch 196/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.0638 - mean_squared_error: 1.0638 - val_loss: 2.8510 - val_mean_squared_error: 2.8510\n",
      "Epoch 197/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.0288 - mean_squared_error: 1.0288 - val_loss: 2.9079 - val_mean_squared_error: 2.9079\n",
      "Epoch 198/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.0140 - mean_squared_error: 1.0140 - val_loss: 3.0444 - val_mean_squared_error: 3.0444\n",
      "Epoch 199/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 0.9860 - mean_squared_error: 0.9860 - val_loss: 2.8918 - val_mean_squared_error: 2.8918\n",
      "Epoch 200/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: 1.0462 - mean_squared_error: 1.0462 - val_loss: 2.9329 - val_mean_squared_error: 2.9329\n",
      "==================================================\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 94, 94, 5)         50        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 47, 47, 5)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 46, 46, 10)        210       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 23, 23, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 22, 22, 20)        820       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 11, 11, 20)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 2420)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 500)               1210500   \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 30)                15030     \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 30)                0         \n",
      "=================================================================\n",
      "Total params: 1,477,110\n",
      "Trainable params: 1,477,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1819 samples, validate on 321 samples\n",
      "Epoch 1/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 2/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 3/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 4/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 5/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 6/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 7/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 8/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 9/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 10/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 11/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 12/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 13/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 14/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 15/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 16/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 17/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 18/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 19/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 20/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 21/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 22/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 23/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 24/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 25/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 26/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 27/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 28/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 29/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 30/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 31/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 32/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 33/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 34/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 35/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 36/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 37/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 38/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 39/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 40/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 41/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 42/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 43/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 44/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 45/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 46/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 47/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 48/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 49/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 50/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 51/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 52/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 53/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 54/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 55/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 56/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 57/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 58/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 59/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 60/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 61/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 62/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 63/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 64/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 65/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 66/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 67/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 68/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 69/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 70/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 71/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 72/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 73/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 74/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 75/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 76/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 77/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 78/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 79/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 80/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 81/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 82/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 83/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 84/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 85/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 86/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 87/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 88/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 89/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 90/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 91/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 92/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 93/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 94/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 95/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 96/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 97/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 98/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 99/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 100/200\n",
      "1819/1819 [==============================] - 3s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "==================================================\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 94, 94, 12)        120       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 47, 47, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 46, 46, 24)        1176      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 23, 23, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 22, 22, 48)        4656      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 11, 11, 48)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 5808)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 500)               2904500   \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 30)                15030     \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 30)                0         \n",
      "=================================================================\n",
      "Total params: 3,175,982\n",
      "Trainable params: 3,175,982\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1819 samples, validate on 321 samples\n",
      "Epoch 1/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 752.3760 - mean_squared_error: 752.3762 - val_loss: 45.3117 - val_mean_squared_error: 45.3117\n",
      "Epoch 2/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 18.7290 - mean_squared_error: 18.7290 - val_loss: 10.9340 - val_mean_squared_error: 10.9340\n",
      "Epoch 3/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.8785 - mean_squared_error: 10.8785 - val_loss: 10.4603 - val_mean_squared_error: 10.4603\n",
      "Epoch 4/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.6031 - mean_squared_error: 10.6031 - val_loss: 10.6460 - val_mean_squared_error: 10.6460\n",
      "Epoch 5/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.4931 - mean_squared_error: 10.4931 - val_loss: 10.1670 - val_mean_squared_error: 10.1670\n",
      "Epoch 6/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.4340 - mean_squared_error: 10.4340 - val_loss: 10.0535 - val_mean_squared_error: 10.0535\n",
      "Epoch 7/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.4227 - mean_squared_error: 10.4227 - val_loss: 10.1592 - val_mean_squared_error: 10.1592\n",
      "Epoch 8/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.3820 - mean_squared_error: 10.3820 - val_loss: 9.9844 - val_mean_squared_error: 9.9844\n",
      "Epoch 9/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.2222 - mean_squared_error: 10.2222 - val_loss: 9.8982 - val_mean_squared_error: 9.8982\n",
      "Epoch 10/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 10.1245 - mean_squared_error: 10.1245 - val_loss: 10.3589 - val_mean_squared_error: 10.3589\n",
      "Epoch 11/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 10.1814 - mean_squared_error: 10.1814 - val_loss: 9.9081 - val_mean_squared_error: 9.9081\n",
      "Epoch 12/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 10.0254 - mean_squared_error: 10.0254 - val_loss: 9.9719 - val_mean_squared_error: 9.9719\n",
      "Epoch 13/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.0848 - mean_squared_error: 10.0848 - val_loss: 9.7923 - val_mean_squared_error: 9.7923\n",
      "Epoch 14/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.1668 - mean_squared_error: 10.1668 - val_loss: 9.6704 - val_mean_squared_error: 9.6704\n",
      "Epoch 15/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 9.9984 - mean_squared_error: 9.9984 - val_loss: 9.5942 - val_mean_squared_error: 9.5942\n",
      "Epoch 16/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.9132 - mean_squared_error: 9.9132 - val_loss: 9.5701 - val_mean_squared_error: 9.5701\n",
      "Epoch 17/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.7862 - mean_squared_error: 9.7862 - val_loss: 9.4941 - val_mean_squared_error: 9.4941\n",
      "Epoch 18/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.9834 - mean_squared_error: 9.9834 - val_loss: 9.5846 - val_mean_squared_error: 9.5846\n",
      "Epoch 19/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.0095 - mean_squared_error: 10.0095 - val_loss: 9.4990 - val_mean_squared_error: 9.4990\n",
      "Epoch 20/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.7128 - mean_squared_error: 9.7128 - val_loss: 9.4568 - val_mean_squared_error: 9.4568\n",
      "Epoch 21/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.6867 - mean_squared_error: 9.6867 - val_loss: 9.4467 - val_mean_squared_error: 9.4467\n",
      "Epoch 22/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.6425 - mean_squared_error: 9.6425 - val_loss: 9.3453 - val_mean_squared_error: 9.3453\n",
      "Epoch 23/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.5829 - mean_squared_error: 9.5829 - val_loss: 9.3036 - val_mean_squared_error: 9.3036\n",
      "Epoch 24/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.5532 - mean_squared_error: 9.5532 - val_loss: 9.5612 - val_mean_squared_error: 9.5612\n",
      "Epoch 25/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.7544 - mean_squared_error: 9.7544 - val_loss: 9.3791 - val_mean_squared_error: 9.3791\n",
      "Epoch 26/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.5418 - mean_squared_error: 9.5418 - val_loss: 9.5865 - val_mean_squared_error: 9.5865\n",
      "Epoch 27/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.5368 - mean_squared_error: 9.5368 - val_loss: 9.3267 - val_mean_squared_error: 9.3267\n",
      "Epoch 28/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.3836 - mean_squared_error: 9.3836 - val_loss: 9.2347 - val_mean_squared_error: 9.2347\n",
      "Epoch 29/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.2723 - mean_squared_error: 9.2723 - val_loss: 9.1219 - val_mean_squared_error: 9.1219\n",
      "Epoch 30/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.3569 - mean_squared_error: 9.3569 - val_loss: 9.6727 - val_mean_squared_error: 9.6727\n",
      "Epoch 31/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.1745 - mean_squared_error: 9.1745 - val_loss: 8.9996 - val_mean_squared_error: 8.9996\n",
      "Epoch 32/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 8.9899 - mean_squared_error: 8.9899 - val_loss: 8.9460 - val_mean_squared_error: 8.9460\n",
      "Epoch 33/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.0063 - mean_squared_error: 9.0063 - val_loss: 9.1140 - val_mean_squared_error: 9.1140\n",
      "Epoch 34/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 8.9476 - mean_squared_error: 8.9476 - val_loss: 9.0671 - val_mean_squared_error: 9.0671\n",
      "Epoch 35/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 8.8566 - mean_squared_error: 8.8566 - val_loss: 8.7128 - val_mean_squared_error: 8.7128\n",
      "Epoch 36/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 8.9206 - mean_squared_error: 8.9206 - val_loss: 10.9865 - val_mean_squared_error: 10.9865\n",
      "Epoch 37/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 8.9113 - mean_squared_error: 8.9113 - val_loss: 8.5995 - val_mean_squared_error: 8.5995\n",
      "Epoch 38/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 8.6381 - mean_squared_error: 8.6381 - val_loss: 8.6781 - val_mean_squared_error: 8.6781\n",
      "Epoch 39/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 8.6820 - mean_squared_error: 8.6820 - val_loss: 8.8278 - val_mean_squared_error: 8.8278\n",
      "Epoch 40/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 8.5225 - mean_squared_error: 8.5225 - val_loss: 8.7273 - val_mean_squared_error: 8.7273\n",
      "Epoch 41/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 8.4217 - mean_squared_error: 8.4217 - val_loss: 8.6312 - val_mean_squared_error: 8.6312\n",
      "Epoch 42/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 8.4622 - mean_squared_error: 8.4622 - val_loss: 8.6013 - val_mean_squared_error: 8.6013\n",
      "Epoch 43/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 8.3291 - mean_squared_error: 8.3291 - val_loss: 8.1906 - val_mean_squared_error: 8.1906\n",
      "Epoch 44/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 8.3071 - mean_squared_error: 8.3071 - val_loss: 8.1986 - val_mean_squared_error: 8.1986\n",
      "Epoch 45/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 8.2837 - mean_squared_error: 8.2837 - val_loss: 8.2797 - val_mean_squared_error: 8.2797\n",
      "Epoch 46/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 8.1861 - mean_squared_error: 8.1861 - val_loss: 8.0900 - val_mean_squared_error: 8.0900\n",
      "Epoch 47/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 8.0825 - mean_squared_error: 8.0825 - val_loss: 7.9407 - val_mean_squared_error: 7.9407\n",
      "Epoch 48/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 8.0844 - mean_squared_error: 8.0844 - val_loss: 7.9686 - val_mean_squared_error: 7.9686\n",
      "Epoch 49/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 7.8840 - mean_squared_error: 7.8840 - val_loss: 7.8904 - val_mean_squared_error: 7.8904\n",
      "Epoch 50/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 7.8295 - mean_squared_error: 7.8295 - val_loss: 7.7456 - val_mean_squared_error: 7.7456\n",
      "Epoch 51/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 7.6741 - mean_squared_error: 7.6741 - val_loss: 7.6860 - val_mean_squared_error: 7.6860\n",
      "Epoch 52/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 7.5684 - mean_squared_error: 7.5684 - val_loss: 7.5518 - val_mean_squared_error: 7.5518\n",
      "Epoch 53/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 7.5160 - mean_squared_error: 7.5160 - val_loss: 7.7653 - val_mean_squared_error: 7.7653\n",
      "Epoch 54/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 7.6505 - mean_squared_error: 7.6505 - val_loss: 8.0495 - val_mean_squared_error: 8.0495\n",
      "Epoch 55/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 7.3370 - mean_squared_error: 7.3370 - val_loss: 7.1617 - val_mean_squared_error: 7.1617\n",
      "Epoch 56/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 7.0892 - mean_squared_error: 7.0892 - val_loss: 6.9871 - val_mean_squared_error: 6.9871\n",
      "Epoch 57/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 7.1212 - mean_squared_error: 7.1212 - val_loss: 7.0019 - val_mean_squared_error: 7.0019\n",
      "Epoch 58/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.8753 - mean_squared_error: 6.8753 - val_loss: 7.1042 - val_mean_squared_error: 7.1042\n",
      "Epoch 59/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.7265 - mean_squared_error: 6.7265 - val_loss: 6.7672 - val_mean_squared_error: 6.7672\n",
      "Epoch 60/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.5109 - mean_squared_error: 6.5109 - val_loss: 6.6185 - val_mean_squared_error: 6.6185\n",
      "Epoch 61/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.4360 - mean_squared_error: 6.4360 - val_loss: 7.1548 - val_mean_squared_error: 7.1548\n",
      "Epoch 62/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.5162 - mean_squared_error: 6.5162 - val_loss: 6.5223 - val_mean_squared_error: 6.5223\n",
      "Epoch 63/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.1883 - mean_squared_error: 6.1883 - val_loss: 6.3917 - val_mean_squared_error: 6.3917\n",
      "Epoch 64/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.9323 - mean_squared_error: 5.9323 - val_loss: 6.0707 - val_mean_squared_error: 6.0707\n",
      "Epoch 65/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.9727 - mean_squared_error: 5.9727 - val_loss: 5.9338 - val_mean_squared_error: 5.9338\n",
      "Epoch 66/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.6853 - mean_squared_error: 5.6853 - val_loss: 6.0350 - val_mean_squared_error: 6.0350\n",
      "Epoch 67/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 5.6326 - mean_squared_error: 5.6326 - val_loss: 5.7612 - val_mean_squared_error: 5.7612\n",
      "Epoch 68/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.5072 - mean_squared_error: 5.5072 - val_loss: 5.6124 - val_mean_squared_error: 5.6124\n",
      "Epoch 69/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.4345 - mean_squared_error: 5.4345 - val_loss: 5.5108 - val_mean_squared_error: 5.5108\n",
      "Epoch 70/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.1562 - mean_squared_error: 5.1562 - val_loss: 5.3051 - val_mean_squared_error: 5.3051\n",
      "Epoch 71/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.0806 - mean_squared_error: 5.0806 - val_loss: 5.3657 - val_mean_squared_error: 5.3657\n",
      "Epoch 72/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.8971 - mean_squared_error: 4.8971 - val_loss: 5.6520 - val_mean_squared_error: 5.6520\n",
      "Epoch 73/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.8732 - mean_squared_error: 4.8732 - val_loss: 5.1581 - val_mean_squared_error: 5.1581\n",
      "Epoch 74/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.6999 - mean_squared_error: 4.6999 - val_loss: 4.9736 - val_mean_squared_error: 4.9736\n",
      "Epoch 75/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.5003 - mean_squared_error: 4.5003 - val_loss: 4.5717 - val_mean_squared_error: 4.5717\n",
      "Epoch 76/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.4029 - mean_squared_error: 4.4029 - val_loss: 4.7697 - val_mean_squared_error: 4.7697\n",
      "Epoch 77/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.3734 - mean_squared_error: 4.3734 - val_loss: 4.5796 - val_mean_squared_error: 4.5796\n",
      "Epoch 78/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.1919 - mean_squared_error: 4.1919 - val_loss: 4.5580 - val_mean_squared_error: 4.5580\n",
      "Epoch 79/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.0408 - mean_squared_error: 4.0408 - val_loss: 4.4496 - val_mean_squared_error: 4.4496\n",
      "Epoch 80/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.9673 - mean_squared_error: 3.9673 - val_loss: 4.2218 - val_mean_squared_error: 4.2218\n",
      "Epoch 81/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.8430 - mean_squared_error: 3.8430 - val_loss: 4.1212 - val_mean_squared_error: 4.1212\n",
      "Epoch 82/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.7334 - mean_squared_error: 3.7334 - val_loss: 4.2660 - val_mean_squared_error: 4.2660\n",
      "Epoch 83/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.7423 - mean_squared_error: 3.7423 - val_loss: 4.0144 - val_mean_squared_error: 4.0144\n",
      "Epoch 84/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.4985 - mean_squared_error: 3.4985 - val_loss: 3.9752 - val_mean_squared_error: 3.9752\n",
      "Epoch 85/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.4885 - mean_squared_error: 3.4885 - val_loss: 3.7682 - val_mean_squared_error: 3.7682\n",
      "Epoch 86/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.3702 - mean_squared_error: 3.3702 - val_loss: 3.8601 - val_mean_squared_error: 3.8601\n",
      "Epoch 87/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: 3.3896 - mean_squared_error: 3.3896 - val_loss: 3.7449 - val_mean_squared_error: 3.7449\n",
      "Epoch 88/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.2916 - mean_squared_error: 3.2916 - val_loss: 3.8506 - val_mean_squared_error: 3.8506\n",
      "Epoch 89/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.0960 - mean_squared_error: 3.0960 - val_loss: 3.6234 - val_mean_squared_error: 3.6234\n",
      "Epoch 90/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.0704 - mean_squared_error: 3.0704 - val_loss: 3.6188 - val_mean_squared_error: 3.6188\n",
      "Epoch 91/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.1607 - mean_squared_error: 3.1607 - val_loss: 3.6750 - val_mean_squared_error: 3.6750\n",
      "Epoch 92/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.9811 - mean_squared_error: 2.9811 - val_loss: 3.9896 - val_mean_squared_error: 3.9896\n",
      "Epoch 93/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.0208 - mean_squared_error: 3.0208 - val_loss: 3.5181 - val_mean_squared_error: 3.5181\n",
      "Epoch 94/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.9839 - mean_squared_error: 2.9839 - val_loss: 3.4113 - val_mean_squared_error: 3.4113\n",
      "Epoch 95/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.8790 - mean_squared_error: 2.8790 - val_loss: 3.8287 - val_mean_squared_error: 3.8287\n",
      "Epoch 96/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.7701 - mean_squared_error: 2.7701 - val_loss: 3.4640 - val_mean_squared_error: 3.4640\n",
      "Epoch 97/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.6419 - mean_squared_error: 2.6419 - val_loss: 3.5877 - val_mean_squared_error: 3.5877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.6083 - mean_squared_error: 2.6083 - val_loss: 3.5914 - val_mean_squared_error: 3.5914\n",
      "Epoch 99/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.6152 - mean_squared_error: 2.6152 - val_loss: 3.5208 - val_mean_squared_error: 3.5208\n",
      "Epoch 100/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.7582 - mean_squared_error: 2.7582 - val_loss: 3.5536 - val_mean_squared_error: 3.5536\n",
      "Epoch 101/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.5843 - mean_squared_error: 2.5843 - val_loss: 3.2613 - val_mean_squared_error: 3.2613\n",
      "Epoch 102/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.4608 - mean_squared_error: 2.4608 - val_loss: 4.2795 - val_mean_squared_error: 4.2795\n",
      "Epoch 103/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.4818 - mean_squared_error: 2.4818 - val_loss: 3.2578 - val_mean_squared_error: 3.2578\n",
      "Epoch 104/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.4592 - mean_squared_error: 2.4592 - val_loss: 3.2959 - val_mean_squared_error: 3.2959\n",
      "Epoch 105/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.4085 - mean_squared_error: 2.4085 - val_loss: 3.2753 - val_mean_squared_error: 3.2753\n",
      "Epoch 106/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.3664 - mean_squared_error: 2.3664 - val_loss: 3.1365 - val_mean_squared_error: 3.1365\n",
      "Epoch 107/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.2459 - mean_squared_error: 2.2459 - val_loss: 3.0718 - val_mean_squared_error: 3.0718\n",
      "Epoch 108/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.2603 - mean_squared_error: 2.2603 - val_loss: 3.2091 - val_mean_squared_error: 3.2091\n",
      "Epoch 109/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: 2.2644 - mean_squared_error: 2.2644 - val_loss: 3.0331 - val_mean_squared_error: 3.0331\n",
      "Epoch 110/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.1015 - mean_squared_error: 2.1015 - val_loss: 3.3697 - val_mean_squared_error: 3.3697\n",
      "Epoch 111/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: 2.0677 - mean_squared_error: 2.0677 - val_loss: 3.0233 - val_mean_squared_error: 3.0233\n",
      "Epoch 112/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.1244 - mean_squared_error: 2.1244 - val_loss: 3.1343 - val_mean_squared_error: 3.1343\n",
      "Epoch 113/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 2.1683 - mean_squared_error: 2.1683 - val_loss: 3.0623 - val_mean_squared_error: 3.0623\n",
      "Epoch 114/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: 2.0618 - mean_squared_error: 2.0618 - val_loss: 3.0246 - val_mean_squared_error: 3.0246\n",
      "Epoch 115/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: 1.9589 - mean_squared_error: 1.9589 - val_loss: 3.0514 - val_mean_squared_error: 3.0514\n",
      "Epoch 116/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.0996 - mean_squared_error: 2.0996 - val_loss: 3.2009 - val_mean_squared_error: 3.2009\n",
      "Epoch 117/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.9056 - mean_squared_error: 1.9056 - val_loss: 3.2018 - val_mean_squared_error: 3.2018\n",
      "Epoch 118/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.9350 - mean_squared_error: 1.9350 - val_loss: 3.3817 - val_mean_squared_error: 3.3817\n",
      "Epoch 119/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.0370 - mean_squared_error: 2.0370 - val_loss: 2.9236 - val_mean_squared_error: 2.9236\n",
      "Epoch 120/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.7998 - mean_squared_error: 1.7998 - val_loss: 3.1755 - val_mean_squared_error: 3.1755\n",
      "Epoch 121/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.7850 - mean_squared_error: 1.7850 - val_loss: 2.8829 - val_mean_squared_error: 2.8829\n",
      "Epoch 122/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.8256 - mean_squared_error: 1.8256 - val_loss: 2.8719 - val_mean_squared_error: 2.8719\n",
      "Epoch 123/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.8779 - mean_squared_error: 1.8779 - val_loss: 2.8538 - val_mean_squared_error: 2.8538\n",
      "Epoch 124/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.7339 - mean_squared_error: 1.7339 - val_loss: 2.9406 - val_mean_squared_error: 2.9406\n",
      "Epoch 125/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.6752 - mean_squared_error: 1.6752 - val_loss: 2.8227 - val_mean_squared_error: 2.8227\n",
      "Epoch 126/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.6643 - mean_squared_error: 1.6643 - val_loss: 2.9688 - val_mean_squared_error: 2.9688\n",
      "Epoch 127/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: 1.6437 - mean_squared_error: 1.6437 - val_loss: 2.7704 - val_mean_squared_error: 2.7704\n",
      "Epoch 128/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.6509 - mean_squared_error: 1.6509 - val_loss: 2.8685 - val_mean_squared_error: 2.8685\n",
      "Epoch 129/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: 1.5835 - mean_squared_error: 1.5835 - val_loss: 2.8303 - val_mean_squared_error: 2.8303\n",
      "Epoch 130/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: 1.5215 - mean_squared_error: 1.5215 - val_loss: 2.8714 - val_mean_squared_error: 2.8714\n",
      "Epoch 131/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.4794 - mean_squared_error: 1.4794 - val_loss: 2.9130 - val_mean_squared_error: 2.9130\n",
      "Epoch 132/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.4620 - mean_squared_error: 1.4620 - val_loss: 2.8817 - val_mean_squared_error: 2.8817\n",
      "Epoch 133/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.5306 - mean_squared_error: 1.5306 - val_loss: 3.1580 - val_mean_squared_error: 3.1580\n",
      "Epoch 134/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.5992 - mean_squared_error: 1.5992 - val_loss: 2.9018 - val_mean_squared_error: 2.9018\n",
      "Epoch 135/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: 1.5361 - mean_squared_error: 1.5361 - val_loss: 2.7482 - val_mean_squared_error: 2.7482\n",
      "Epoch 136/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.4209 - mean_squared_error: 1.4209 - val_loss: 2.8757 - val_mean_squared_error: 2.8757\n",
      "Epoch 137/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.4389 - mean_squared_error: 1.4389 - val_loss: 2.8214 - val_mean_squared_error: 2.8214\n",
      "Epoch 138/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.4691 - mean_squared_error: 1.4691 - val_loss: 2.7640 - val_mean_squared_error: 2.7640\n",
      "Epoch 139/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.4176 - mean_squared_error: 1.4176 - val_loss: 2.7911 - val_mean_squared_error: 2.7911\n",
      "Epoch 140/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: 1.3325 - mean_squared_error: 1.3325 - val_loss: 2.9384 - val_mean_squared_error: 2.9384\n",
      "Epoch 141/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.4125 - mean_squared_error: 1.4125 - val_loss: 2.7539 - val_mean_squared_error: 2.7539\n",
      "Epoch 142/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: 1.2395 - mean_squared_error: 1.2395 - val_loss: 2.6958 - val_mean_squared_error: 2.6958\n",
      "Epoch 143/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.2407 - mean_squared_error: 1.2407 - val_loss: 3.0139 - val_mean_squared_error: 3.0139\n",
      "Epoch 144/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.3572 - mean_squared_error: 1.3572 - val_loss: 2.9050 - val_mean_squared_error: 2.9050\n",
      "Epoch 145/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.1939 - mean_squared_error: 1.1939 - val_loss: 2.7390 - val_mean_squared_error: 2.7390\n",
      "Epoch 146/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.1927 - mean_squared_error: 1.1927 - val_loss: 2.7483 - val_mean_squared_error: 2.7483\n",
      "Epoch 147/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.1946 - mean_squared_error: 1.1946 - val_loss: 2.7192 - val_mean_squared_error: 2.7192\n",
      "Epoch 148/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: 1.1359 - mean_squared_error: 1.1359 - val_loss: 2.6463 - val_mean_squared_error: 2.6463\n",
      "Epoch 149/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.1637 - mean_squared_error: 1.1637 - val_loss: 2.6616 - val_mean_squared_error: 2.6616\n",
      "Epoch 150/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.1376 - mean_squared_error: 1.1376 - val_loss: 2.9152 - val_mean_squared_error: 2.9152\n",
      "Epoch 151/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.2547 - mean_squared_error: 1.2547 - val_loss: 2.6726 - val_mean_squared_error: 2.6726\n",
      "Epoch 152/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: 1.0759 - mean_squared_error: 1.0759 - val_loss: 2.8209 - val_mean_squared_error: 2.8209\n",
      "Epoch 153/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.1045 - mean_squared_error: 1.1045 - val_loss: 2.6809 - val_mean_squared_error: 2.6809\n",
      "Epoch 154/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.0621 - mean_squared_error: 1.0621 - val_loss: 2.9165 - val_mean_squared_error: 2.9165\n",
      "Epoch 155/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.1524 - mean_squared_error: 1.1524 - val_loss: 2.6351 - val_mean_squared_error: 2.6351\n",
      "Epoch 156/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.0327 - mean_squared_error: 1.0327 - val_loss: 2.8052 - val_mean_squared_error: 2.8052\n",
      "Epoch 157/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 1.1328 - mean_squared_error: 1.1328 - val_loss: 2.8888 - val_mean_squared_error: 2.8888\n",
      "Epoch 158/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 0.9767 - mean_squared_error: 0.9767 - val_loss: 2.7098 - val_mean_squared_error: 2.7098\n",
      "Epoch 159/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 0.9680 - mean_squared_error: 0.9680 - val_loss: 2.6466 - val_mean_squared_error: 2.6466\n",
      "Epoch 160/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.1024 - mean_squared_error: 1.1024 - val_loss: 2.6393 - val_mean_squared_error: 2.6393\n",
      "Epoch 161/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.0451 - mean_squared_error: 1.0451 - val_loss: 2.6627 - val_mean_squared_error: 2.6627\n",
      "Epoch 162/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.9020 - mean_squared_error: 0.9020 - val_loss: 2.5996 - val_mean_squared_error: 2.5996\n",
      "Epoch 163/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.8711 - mean_squared_error: 0.8711 - val_loss: 2.6186 - val_mean_squared_error: 2.6186\n",
      "Epoch 164/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.9038 - mean_squared_error: 0.9038 - val_loss: 2.7732 - val_mean_squared_error: 2.7732\n",
      "Epoch 165/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.8560 - mean_squared_error: 0.8560 - val_loss: 2.5851 - val_mean_squared_error: 2.5851\n",
      "Epoch 166/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.8331 - mean_squared_error: 0.8331 - val_loss: 2.6347 - val_mean_squared_error: 2.6347\n",
      "Epoch 167/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.8617 - mean_squared_error: 0.8617 - val_loss: 2.7263 - val_mean_squared_error: 2.7264\n",
      "Epoch 168/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.8369 - mean_squared_error: 0.8369 - val_loss: 2.6381 - val_mean_squared_error: 2.6381\n",
      "Epoch 169/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.8602 - mean_squared_error: 0.8602 - val_loss: 2.7259 - val_mean_squared_error: 2.7259\n",
      "Epoch 170/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.8674 - mean_squared_error: 0.8674 - val_loss: 2.5861 - val_mean_squared_error: 2.5861\n",
      "Epoch 171/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.8277 - mean_squared_error: 0.8277 - val_loss: 2.9893 - val_mean_squared_error: 2.9893\n",
      "Epoch 172/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.8138 - mean_squared_error: 0.8138 - val_loss: 2.7196 - val_mean_squared_error: 2.7196\n",
      "Epoch 173/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 0.8102 - mean_squared_error: 0.8102 - val_loss: 2.8655 - val_mean_squared_error: 2.8655\n",
      "Epoch 174/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 0.8027 - mean_squared_error: 0.8027 - val_loss: 2.6978 - val_mean_squared_error: 2.6978\n",
      "Epoch 175/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.7701 - mean_squared_error: 0.7701 - val_loss: 2.7009 - val_mean_squared_error: 2.7009\n",
      "Epoch 176/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.8224 - mean_squared_error: 0.8224 - val_loss: 2.9328 - val_mean_squared_error: 2.9328\n",
      "Epoch 177/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.7636 - mean_squared_error: 0.7636 - val_loss: 2.6509 - val_mean_squared_error: 2.6509\n",
      "Epoch 178/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.6908 - mean_squared_error: 0.6908 - val_loss: 2.7483 - val_mean_squared_error: 2.7483\n",
      "Epoch 179/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: 0.7651 - mean_squared_error: 0.7651 - val_loss: 2.7467 - val_mean_squared_error: 2.7467\n",
      "Epoch 180/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.7188 - mean_squared_error: 0.7188 - val_loss: 2.6349 - val_mean_squared_error: 2.6349\n",
      "Epoch 181/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.6820 - mean_squared_error: 0.6820 - val_loss: 2.6092 - val_mean_squared_error: 2.6092\n",
      "Epoch 182/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.6502 - mean_squared_error: 0.6502 - val_loss: 2.7112 - val_mean_squared_error: 2.7112\n",
      "Epoch 183/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.6565 - mean_squared_error: 0.6565 - val_loss: 2.6238 - val_mean_squared_error: 2.6238\n",
      "Epoch 184/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.6442 - mean_squared_error: 0.6442 - val_loss: 2.6256 - val_mean_squared_error: 2.6256\n",
      "Epoch 185/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.6084 - mean_squared_error: 0.6084 - val_loss: 2.7037 - val_mean_squared_error: 2.7037\n",
      "Epoch 186/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.6771 - mean_squared_error: 0.6771 - val_loss: 2.8653 - val_mean_squared_error: 2.8653\n",
      "Epoch 187/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.7940 - mean_squared_error: 0.7940 - val_loss: 2.8922 - val_mean_squared_error: 2.8922\n",
      "Epoch 188/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.7178 - mean_squared_error: 0.7178 - val_loss: 2.7904 - val_mean_squared_error: 2.7904\n",
      "Epoch 189/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.6434 - mean_squared_error: 0.6434 - val_loss: 2.6310 - val_mean_squared_error: 2.6310\n",
      "Epoch 190/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.6148 - mean_squared_error: 0.6148 - val_loss: 2.8299 - val_mean_squared_error: 2.8299\n",
      "Epoch 191/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.5871 - mean_squared_error: 0.5871 - val_loss: 2.6380 - val_mean_squared_error: 2.6380\n",
      "Epoch 192/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.6228 - mean_squared_error: 0.6228 - val_loss: 2.7141 - val_mean_squared_error: 2.7141\n",
      "Epoch 193/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.7716 - mean_squared_error: 0.7716 - val_loss: 2.7927 - val_mean_squared_error: 2.7927\n",
      "Epoch 194/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1819/1819 [==============================] - 5s 2ms/sample - loss: 0.6071 - mean_squared_error: 0.6071 - val_loss: 2.8705 - val_mean_squared_error: 2.8705\n",
      "Epoch 195/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.5936 - mean_squared_error: 0.5936 - val_loss: 2.7619 - val_mean_squared_error: 2.7619\n",
      "Epoch 196/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: 0.5539 - mean_squared_error: 0.5539 - val_loss: 2.6498 - val_mean_squared_error: 2.6498\n",
      "Epoch 197/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: 0.5647 - mean_squared_error: 0.5647 - val_loss: 2.6462 - val_mean_squared_error: 2.6462\n",
      "Epoch 198/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.5301 - mean_squared_error: 0.5301 - val_loss: 2.6898 - val_mean_squared_error: 2.6898\n",
      "Epoch 199/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.5554 - mean_squared_error: 0.5554 - val_loss: 2.7156 - val_mean_squared_error: 2.7156\n",
      "Epoch 200/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.6220 - mean_squared_error: 0.6220 - val_loss: 2.7040 - val_mean_squared_error: 2.7040\n",
      "==================================================\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 94, 94, 12)        120       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 47, 47, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 46, 46, 24)        1176      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 23, 23, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 22, 22, 48)        4656      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 11, 11, 48)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 5808)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 500)               2904500   \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 30)                15030     \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 30)                0         \n",
      "=================================================================\n",
      "Total params: 3,175,982\n",
      "Trainable params: 3,175,982\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "==================================================\n",
      "Train on 1819 samples, validate on 321 samples\n",
      "Epoch 1/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 2/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 3/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 4/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 5/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 6/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 7/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 8/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 9/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 10/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 11/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 12/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 13/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 14/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 15/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 16/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 17/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 18/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 19/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 20/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 21/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 22/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 23/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 24/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 25/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 26/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 27/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 28/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 29/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 30/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 31/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 33/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 34/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 35/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 36/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 37/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 38/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 39/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 40/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 41/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 42/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 43/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 44/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 45/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 46/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 47/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 48/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 49/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 50/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 51/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 52/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 53/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 54/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 55/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 56/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 57/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 58/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 59/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 60/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 61/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 62/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 63/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 64/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 65/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 66/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 67/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 68/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 69/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 70/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 71/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 72/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 73/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 74/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 75/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 76/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 77/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 78/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 79/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 80/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 81/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 82/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 83/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 84/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 85/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 86/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 87/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 88/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 89/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 90/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 91/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 92/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 93/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 94/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 95/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 96/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 97/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 98/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 99/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 100/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "==================================================\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 94, 94, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 47, 47, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 46, 46, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 22, 22, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 500)               3872500   \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 30)                15030     \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 30)                0         \n",
      "=================================================================\n",
      "Total params: 4,148,526\n",
      "Trainable params: 4,148,526\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "==================================================\n",
      "Train on 1819 samples, validate on 321 samples\n",
      "Epoch 1/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 252.0565 - mean_squared_error: 252.0565 - val_loss: 15.2699 - val_mean_squared_error: 15.2699\n",
      "Epoch 2/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 12.1196 - mean_squared_error: 12.1196 - val_loss: 11.1855 - val_mean_squared_error: 11.1855\n",
      "Epoch 3/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 11.0151 - mean_squared_error: 11.0151 - val_loss: 10.4708 - val_mean_squared_error: 10.4708\n",
      "Epoch 4/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.4467 - mean_squared_error: 10.4467 - val_loss: 9.8167 - val_mean_squared_error: 9.8167\n",
      "Epoch 5/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.2044 - mean_squared_error: 10.2044 - val_loss: 9.6700 - val_mean_squared_error: 9.6700\n",
      "Epoch 6/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 9.8058 - mean_squared_error: 9.8058 - val_loss: 9.2659 - val_mean_squared_error: 9.2659\n",
      "Epoch 7/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.6144 - mean_squared_error: 9.6144 - val_loss: 9.4279 - val_mean_squared_error: 9.4279\n",
      "Epoch 8/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 9.6254 - mean_squared_error: 9.6254 - val_loss: 9.0192 - val_mean_squared_error: 9.0192\n",
      "Epoch 9/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 9.3435 - mean_squared_error: 9.3435 - val_loss: 8.9465 - val_mean_squared_error: 8.9465\n",
      "Epoch 10/200\n",
      "1819/1819 [==============================] - 7s 4ms/sample - loss: 9.1478 - mean_squared_error: 9.1478 - val_loss: 9.1113 - val_mean_squared_error: 9.1113\n",
      "Epoch 11/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 9.0907 - mean_squared_error: 9.0907 - val_loss: 9.5868 - val_mean_squared_error: 9.5868\n",
      "Epoch 12/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 8.9955 - mean_squared_error: 8.9955 - val_loss: 8.7286 - val_mean_squared_error: 8.7286\n",
      "Epoch 13/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 9.0193 - mean_squared_error: 9.0193 - val_loss: 8.6465 - val_mean_squared_error: 8.6466\n",
      "Epoch 14/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 8.7336 - mean_squared_error: 8.7336 - val_loss: 8.5758 - val_mean_squared_error: 8.5758\n",
      "Epoch 15/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 8.6844 - mean_squared_error: 8.6844 - val_loss: 8.7749 - val_mean_squared_error: 8.7749\n",
      "Epoch 16/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 8.3525 - mean_squared_error: 8.3525 - val_loss: 8.2262 - val_mean_squared_error: 8.2262\n",
      "Epoch 17/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 8.6187 - mean_squared_error: 8.6187 - val_loss: 8.0886 - val_mean_squared_error: 8.0886\n",
      "Epoch 18/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 7.9066 - mean_squared_error: 7.9066 - val_loss: 7.8291 - val_mean_squared_error: 7.8291\n",
      "Epoch 19/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 7.6281 - mean_squared_error: 7.6281 - val_loss: 7.6998 - val_mean_squared_error: 7.6998\n",
      "Epoch 20/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 7.4238 - mean_squared_error: 7.4238 - val_loss: 7.2636 - val_mean_squared_error: 7.2636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 7.1991 - mean_squared_error: 7.1991 - val_loss: 7.7417 - val_mean_squared_error: 7.7417\n",
      "Epoch 22/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 7.1250 - mean_squared_error: 7.1250 - val_loss: 6.8032 - val_mean_squared_error: 6.8032\n",
      "Epoch 23/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 6.8125 - mean_squared_error: 6.8125 - val_loss: 6.4791 - val_mean_squared_error: 6.4791\n",
      "Epoch 24/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 6.3531 - mean_squared_error: 6.3531 - val_loss: 6.3926 - val_mean_squared_error: 6.3926\n",
      "Epoch 25/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 6.1989 - mean_squared_error: 6.1989 - val_loss: 6.6286 - val_mean_squared_error: 6.6286\n",
      "Epoch 26/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 6.1448 - mean_squared_error: 6.1448 - val_loss: 5.9808 - val_mean_squared_error: 5.9808\n",
      "Epoch 27/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 5.8366 - mean_squared_error: 5.8366 - val_loss: 5.7003 - val_mean_squared_error: 5.7003\n",
      "Epoch 28/200\n",
      "1819/1819 [==============================] - 6s 4ms/sample - loss: 5.6717 - mean_squared_error: 5.6717 - val_loss: 5.5950 - val_mean_squared_error: 5.5950\n",
      "Epoch 29/200\n",
      "1819/1819 [==============================] - 7s 4ms/sample - loss: 5.6834 - mean_squared_error: 5.6834 - val_loss: 5.6423 - val_mean_squared_error: 5.6423\n",
      "Epoch 30/200\n",
      "1819/1819 [==============================] - 6s 4ms/sample - loss: 5.5261 - mean_squared_error: 5.5261 - val_loss: 5.6101 - val_mean_squared_error: 5.6101\n",
      "Epoch 31/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 5.4223 - mean_squared_error: 5.4223 - val_loss: 5.7249 - val_mean_squared_error: 5.7249\n",
      "Epoch 32/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 5.5487 - mean_squared_error: 5.5487 - val_loss: 5.8074 - val_mean_squared_error: 5.8074\n",
      "Epoch 33/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 5.1836 - mean_squared_error: 5.1836 - val_loss: 5.1782 - val_mean_squared_error: 5.1782\n",
      "Epoch 34/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 5.0190 - mean_squared_error: 5.0190 - val_loss: 4.9410 - val_mean_squared_error: 4.9410\n",
      "Epoch 35/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 4.8423 - mean_squared_error: 4.8423 - val_loss: 5.0170 - val_mean_squared_error: 5.0170\n",
      "Epoch 36/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 4.7831 - mean_squared_error: 4.7831 - val_loss: 5.2009 - val_mean_squared_error: 5.2009\n",
      "Epoch 37/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 4.8045 - mean_squared_error: 4.8045 - val_loss: 4.7984 - val_mean_squared_error: 4.7984\n",
      "Epoch 38/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 4.6430 - mean_squared_error: 4.6430 - val_loss: 4.7805 - val_mean_squared_error: 4.7805\n",
      "Epoch 39/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 4.5995 - mean_squared_error: 4.5995 - val_loss: 4.6080 - val_mean_squared_error: 4.6080\n",
      "Epoch 40/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 4.9333 - mean_squared_error: 4.9333 - val_loss: 5.1529 - val_mean_squared_error: 5.1529\n",
      "Epoch 41/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 4.6062 - mean_squared_error: 4.6062 - val_loss: 4.3276 - val_mean_squared_error: 4.3276\n",
      "Epoch 42/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 4.8076 - mean_squared_error: 4.8076 - val_loss: 5.6215 - val_mean_squared_error: 5.6215\n",
      "Epoch 43/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 4.5643 - mean_squared_error: 4.5643 - val_loss: 4.7302 - val_mean_squared_error: 4.7302\n",
      "Epoch 44/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 4.2686 - mean_squared_error: 4.2686 - val_loss: 4.1615 - val_mean_squared_error: 4.1615\n",
      "Epoch 45/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 4.2468 - mean_squared_error: 4.2468 - val_loss: 4.9173 - val_mean_squared_error: 4.9173\n",
      "Epoch 46/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 4.1555 - mean_squared_error: 4.1555 - val_loss: 4.1963 - val_mean_squared_error: 4.1963\n",
      "Epoch 47/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 4.0399 - mean_squared_error: 4.0399 - val_loss: 5.1157 - val_mean_squared_error: 5.1157\n",
      "Epoch 48/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.2816 - mean_squared_error: 4.2816 - val_loss: 5.5481 - val_mean_squared_error: 5.5481\n",
      "Epoch 49/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.4878 - mean_squared_error: 4.4878 - val_loss: 4.5126 - val_mean_squared_error: 4.5126\n",
      "Epoch 50/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 3.9117 - mean_squared_error: 3.9117 - val_loss: 4.1004 - val_mean_squared_error: 4.1004\n",
      "Epoch 51/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.7959 - mean_squared_error: 3.7959 - val_loss: 4.0409 - val_mean_squared_error: 4.0409\n",
      "Epoch 52/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.8394 - mean_squared_error: 3.8394 - val_loss: 3.9658 - val_mean_squared_error: 3.9658\n",
      "Epoch 53/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.7575 - mean_squared_error: 3.7575 - val_loss: 4.2551 - val_mean_squared_error: 4.2551\n",
      "Epoch 54/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 3.7403 - mean_squared_error: 3.7403 - val_loss: 3.9757 - val_mean_squared_error: 3.9757\n",
      "Epoch 55/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 3.6209 - mean_squared_error: 3.6209 - val_loss: 4.1782 - val_mean_squared_error: 4.1782\n",
      "Epoch 56/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 3.5332 - mean_squared_error: 3.5332 - val_loss: 3.8509 - val_mean_squared_error: 3.8509\n",
      "Epoch 57/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 3.5998 - mean_squared_error: 3.5998 - val_loss: 3.6980 - val_mean_squared_error: 3.6980\n",
      "Epoch 58/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 3.8505 - mean_squared_error: 3.8505 - val_loss: 4.8875 - val_mean_squared_error: 4.8875\n",
      "Epoch 59/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 3.5879 - mean_squared_error: 3.5879 - val_loss: 3.8492 - val_mean_squared_error: 3.8492\n",
      "Epoch 60/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 3.3830 - mean_squared_error: 3.3830 - val_loss: 3.6246 - val_mean_squared_error: 3.6246\n",
      "Epoch 61/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 3.3647 - mean_squared_error: 3.3647 - val_loss: 3.5983 - val_mean_squared_error: 3.5983\n",
      "Epoch 62/200\n",
      "1819/1819 [==============================] - 7s 4ms/sample - loss: 3.6007 - mean_squared_error: 3.6007 - val_loss: 3.6455 - val_mean_squared_error: 3.6455\n",
      "Epoch 63/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 3.2843 - mean_squared_error: 3.2843 - val_loss: 3.6360 - val_mean_squared_error: 3.6360\n",
      "Epoch 64/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 3.3866 - mean_squared_error: 3.3866 - val_loss: 3.6520 - val_mean_squared_error: 3.6520\n",
      "Epoch 65/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 3.1802 - mean_squared_error: 3.1802 - val_loss: 3.6452 - val_mean_squared_error: 3.6452\n",
      "Epoch 66/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 3.2166 - mean_squared_error: 3.2166 - val_loss: 3.5181 - val_mean_squared_error: 3.5181\n",
      "Epoch 67/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 3.2945 - mean_squared_error: 3.2945 - val_loss: 3.8380 - val_mean_squared_error: 3.8380\n",
      "Epoch 68/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 3.1207 - mean_squared_error: 3.1207 - val_loss: 3.7009 - val_mean_squared_error: 3.7009\n",
      "Epoch 69/200\n",
      "1819/1819 [==============================] - 7s 4ms/sample - loss: 3.2574 - mean_squared_error: 3.2574 - val_loss: 4.4788 - val_mean_squared_error: 4.4788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 3.1239 - mean_squared_error: 3.1239 - val_loss: 3.4856 - val_mean_squared_error: 3.4856\n",
      "Epoch 71/200\n",
      "1819/1819 [==============================] - 6s 4ms/sample - loss: 3.1113 - mean_squared_error: 3.1113 - val_loss: 3.5177 - val_mean_squared_error: 3.5177\n",
      "Epoch 72/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 2.9668 - mean_squared_error: 2.9668 - val_loss: 3.2920 - val_mean_squared_error: 3.2920\n",
      "Epoch 73/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 3.0499 - mean_squared_error: 3.0499 - val_loss: 3.7272 - val_mean_squared_error: 3.7272\n",
      "Epoch 74/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.9194 - mean_squared_error: 2.9194 - val_loss: 3.3763 - val_mean_squared_error: 3.3763\n",
      "Epoch 75/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 2.8721 - mean_squared_error: 2.8721 - val_loss: 4.6338 - val_mean_squared_error: 4.6338\n",
      "Epoch 76/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.9724 - mean_squared_error: 2.9724 - val_loss: 3.2447 - val_mean_squared_error: 3.2447\n",
      "Epoch 77/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 2.9455 - mean_squared_error: 2.9455 - val_loss: 3.5394 - val_mean_squared_error: 3.5394\n",
      "Epoch 78/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 2.9811 - mean_squared_error: 2.9811 - val_loss: 3.1405 - val_mean_squared_error: 3.1405\n",
      "Epoch 79/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 2.6973 - mean_squared_error: 2.6973 - val_loss: 3.0677 - val_mean_squared_error: 3.0677\n",
      "Epoch 80/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 2.6920 - mean_squared_error: 2.6920 - val_loss: 3.1885 - val_mean_squared_error: 3.1885\n",
      "Epoch 81/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 2.6593 - mean_squared_error: 2.6593 - val_loss: 3.0736 - val_mean_squared_error: 3.0736\n",
      "Epoch 82/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 2.7092 - mean_squared_error: 2.7092 - val_loss: 3.6129 - val_mean_squared_error: 3.6129\n",
      "Epoch 83/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 2.7281 - mean_squared_error: 2.7281 - val_loss: 3.0782 - val_mean_squared_error: 3.0782\n",
      "Epoch 84/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 2.6925 - mean_squared_error: 2.6925 - val_loss: 3.2361 - val_mean_squared_error: 3.2361\n",
      "Epoch 85/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.6216 - mean_squared_error: 2.6216 - val_loss: 3.2552 - val_mean_squared_error: 3.2552\n",
      "Epoch 86/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.4734 - mean_squared_error: 2.4734 - val_loss: 2.9450 - val_mean_squared_error: 2.9450\n",
      "Epoch 87/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 2.5558 - mean_squared_error: 2.5558 - val_loss: 3.3770 - val_mean_squared_error: 3.3770\n",
      "Epoch 88/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 2.4390 - mean_squared_error: 2.4390 - val_loss: 2.9052 - val_mean_squared_error: 2.9052\n",
      "Epoch 89/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 2.3395 - mean_squared_error: 2.3395 - val_loss: 3.3589 - val_mean_squared_error: 3.3589\n",
      "Epoch 90/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.4463 - mean_squared_error: 2.4463 - val_loss: 3.0505 - val_mean_squared_error: 3.0505\n",
      "Epoch 91/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 2.7928 - mean_squared_error: 2.7928 - val_loss: 3.0891 - val_mean_squared_error: 3.0891\n",
      "Epoch 92/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 2.2879 - mean_squared_error: 2.2879 - val_loss: 3.2092 - val_mean_squared_error: 3.2092\n",
      "Epoch 93/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 2.4503 - mean_squared_error: 2.4503 - val_loss: 2.7533 - val_mean_squared_error: 2.7533\n",
      "Epoch 94/200\n",
      "1819/1819 [==============================] - 6s 4ms/sample - loss: 2.1740 - mean_squared_error: 2.1740 - val_loss: 2.8775 - val_mean_squared_error: 2.8775\n",
      "Epoch 95/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 2.1424 - mean_squared_error: 2.1424 - val_loss: 2.8033 - val_mean_squared_error: 2.8033\n",
      "Epoch 96/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 2.0971 - mean_squared_error: 2.0971 - val_loss: 2.8672 - val_mean_squared_error: 2.8672\n",
      "Epoch 97/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 2.0982 - mean_squared_error: 2.0982 - val_loss: 2.7448 - val_mean_squared_error: 2.7448\n",
      "Epoch 98/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 2.0951 - mean_squared_error: 2.0951 - val_loss: 2.7973 - val_mean_squared_error: 2.7973\n",
      "Epoch 99/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.9629 - mean_squared_error: 1.9629 - val_loss: 2.6988 - val_mean_squared_error: 2.6988\n",
      "Epoch 100/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.0154 - mean_squared_error: 2.0154 - val_loss: 2.8550 - val_mean_squared_error: 2.8550\n",
      "Epoch 101/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.9157 - mean_squared_error: 1.9157 - val_loss: 3.1779 - val_mean_squared_error: 3.1779\n",
      "Epoch 102/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.9721 - mean_squared_error: 1.9721 - val_loss: 2.7942 - val_mean_squared_error: 2.7942\n",
      "Epoch 103/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.9491 - mean_squared_error: 1.9491 - val_loss: 2.8122 - val_mean_squared_error: 2.8122\n",
      "Epoch 104/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.7626 - mean_squared_error: 1.7626 - val_loss: 2.6518 - val_mean_squared_error: 2.6518\n",
      "Epoch 105/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.7562 - mean_squared_error: 1.7562 - val_loss: 3.0484 - val_mean_squared_error: 3.0484\n",
      "Epoch 106/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.1020 - mean_squared_error: 2.1020 - val_loss: 3.3334 - val_mean_squared_error: 3.3334\n",
      "Epoch 107/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.7690 - mean_squared_error: 1.7690 - val_loss: 2.6739 - val_mean_squared_error: 2.6739\n",
      "Epoch 108/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.7054 - mean_squared_error: 1.7054 - val_loss: 2.6259 - val_mean_squared_error: 2.6259\n",
      "Epoch 109/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.7223 - mean_squared_error: 1.7223 - val_loss: 2.8013 - val_mean_squared_error: 2.8013\n",
      "Epoch 110/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.7381 - mean_squared_error: 1.7381 - val_loss: 2.6113 - val_mean_squared_error: 2.6113\n",
      "Epoch 111/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.6614 - mean_squared_error: 1.6614 - val_loss: 2.6251 - val_mean_squared_error: 2.6251\n",
      "Epoch 112/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.6827 - mean_squared_error: 1.6827 - val_loss: 2.9037 - val_mean_squared_error: 2.9037\n",
      "Epoch 113/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.6606 - mean_squared_error: 1.6606 - val_loss: 2.6304 - val_mean_squared_error: 2.6304\n",
      "Epoch 114/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.6512 - mean_squared_error: 1.6512 - val_loss: 4.0013 - val_mean_squared_error: 4.0013\n",
      "Epoch 115/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.9279 - mean_squared_error: 1.9279 - val_loss: 2.5806 - val_mean_squared_error: 2.5806\n",
      "Epoch 116/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.5276 - mean_squared_error: 1.5276 - val_loss: 2.5520 - val_mean_squared_error: 2.5520\n",
      "Epoch 117/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.5304 - mean_squared_error: 1.5304 - val_loss: 2.5080 - val_mean_squared_error: 2.5080\n",
      "Epoch 118/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.5406 - mean_squared_error: 1.5406 - val_loss: 2.5188 - val_mean_squared_error: 2.5188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.5151 - mean_squared_error: 1.5151 - val_loss: 2.5230 - val_mean_squared_error: 2.5230\n",
      "Epoch 120/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.3978 - mean_squared_error: 1.3978 - val_loss: 2.6307 - val_mean_squared_error: 2.6307\n",
      "Epoch 121/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.3630 - mean_squared_error: 1.3630 - val_loss: 2.4958 - val_mean_squared_error: 2.4958\n",
      "Epoch 122/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.4443 - mean_squared_error: 1.4443 - val_loss: 2.4569 - val_mean_squared_error: 2.4569\n",
      "Epoch 123/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.3647 - mean_squared_error: 1.3647 - val_loss: 2.5227 - val_mean_squared_error: 2.5227\n",
      "Epoch 124/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.3005 - mean_squared_error: 1.3005 - val_loss: 2.4919 - val_mean_squared_error: 2.4919\n",
      "Epoch 125/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.3740 - mean_squared_error: 1.3740 - val_loss: 2.5039 - val_mean_squared_error: 2.5039\n",
      "Epoch 126/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.3162 - mean_squared_error: 1.3162 - val_loss: 2.5163 - val_mean_squared_error: 2.5163\n",
      "Epoch 127/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.3319 - mean_squared_error: 1.3319 - val_loss: 2.4615 - val_mean_squared_error: 2.4615\n",
      "Epoch 128/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.2504 - mean_squared_error: 1.2504 - val_loss: 2.5079 - val_mean_squared_error: 2.5079\n",
      "Epoch 129/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.3241 - mean_squared_error: 1.3241 - val_loss: 2.8679 - val_mean_squared_error: 2.8679\n",
      "Epoch 130/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.2596 - mean_squared_error: 1.2596 - val_loss: 2.7281 - val_mean_squared_error: 2.7281\n",
      "Epoch 131/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.1756 - mean_squared_error: 1.1756 - val_loss: 2.5281 - val_mean_squared_error: 2.5281\n",
      "Epoch 132/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.1745 - mean_squared_error: 1.1745 - val_loss: 2.5314 - val_mean_squared_error: 2.5314\n",
      "Epoch 133/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.1299 - mean_squared_error: 1.1299 - val_loss: 2.5438 - val_mean_squared_error: 2.5438\n",
      "Epoch 134/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.2145 - mean_squared_error: 1.2145 - val_loss: 2.6334 - val_mean_squared_error: 2.6334\n",
      "Epoch 135/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.1849 - mean_squared_error: 1.1849 - val_loss: 2.9221 - val_mean_squared_error: 2.9221\n",
      "Epoch 136/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.1816 - mean_squared_error: 1.1816 - val_loss: 2.5164 - val_mean_squared_error: 2.5164\n",
      "Epoch 137/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.2281 - mean_squared_error: 1.2281 - val_loss: 2.6132 - val_mean_squared_error: 2.6132\n",
      "Epoch 138/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.4925 - mean_squared_error: 1.4925 - val_loss: 2.8916 - val_mean_squared_error: 2.8916\n",
      "Epoch 139/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.0727 - mean_squared_error: 1.0727 - val_loss: 2.5444 - val_mean_squared_error: 2.5444\n",
      "Epoch 140/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.0397 - mean_squared_error: 1.0397 - val_loss: 2.8298 - val_mean_squared_error: 2.8298\n",
      "Epoch 141/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.9659 - mean_squared_error: 0.9659 - val_loss: 2.4564 - val_mean_squared_error: 2.4564\n",
      "Epoch 142/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.9909 - mean_squared_error: 0.9909 - val_loss: 2.4788 - val_mean_squared_error: 2.4788\n",
      "Epoch 143/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.9642 - mean_squared_error: 0.9642 - val_loss: 2.5492 - val_mean_squared_error: 2.5492\n",
      "Epoch 144/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.2146 - mean_squared_error: 1.2146 - val_loss: 2.6006 - val_mean_squared_error: 2.6006\n",
      "Epoch 145/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.0673 - mean_squared_error: 1.0673 - val_loss: 2.5045 - val_mean_squared_error: 2.5045\n",
      "Epoch 146/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.9377 - mean_squared_error: 0.9377 - val_loss: 2.4410 - val_mean_squared_error: 2.4410\n",
      "Epoch 147/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.8636 - mean_squared_error: 0.8636 - val_loss: 2.6029 - val_mean_squared_error: 2.6029\n",
      "Epoch 148/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.9240 - mean_squared_error: 0.9240 - val_loss: 2.4475 - val_mean_squared_error: 2.4475\n",
      "Epoch 149/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.9676 - mean_squared_error: 0.9676 - val_loss: 2.4682 - val_mean_squared_error: 2.4683\n",
      "Epoch 150/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.9541 - mean_squared_error: 0.9541 - val_loss: 2.4152 - val_mean_squared_error: 2.4152\n",
      "Epoch 151/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.9500 - mean_squared_error: 0.9500 - val_loss: 2.6720 - val_mean_squared_error: 2.6720\n",
      "Epoch 152/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.8904 - mean_squared_error: 0.8904 - val_loss: 2.4391 - val_mean_squared_error: 2.4391\n",
      "Epoch 153/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.9027 - mean_squared_error: 0.9027 - val_loss: 2.5114 - val_mean_squared_error: 2.5114\n",
      "Epoch 154/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.8687 - mean_squared_error: 0.8687 - val_loss: 2.4310 - val_mean_squared_error: 2.4310\n",
      "Epoch 155/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.8500 - mean_squared_error: 0.8500 - val_loss: 2.4725 - val_mean_squared_error: 2.4725\n",
      "Epoch 156/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.8599 - mean_squared_error: 0.8599 - val_loss: 2.5484 - val_mean_squared_error: 2.5484\n",
      "Epoch 157/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 1.0031 - mean_squared_error: 1.0031 - val_loss: 2.4722 - val_mean_squared_error: 2.4722\n",
      "Epoch 158/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.9097 - mean_squared_error: 0.9097 - val_loss: 2.4625 - val_mean_squared_error: 2.4625\n",
      "Epoch 159/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.7380 - mean_squared_error: 0.7380 - val_loss: 2.4553 - val_mean_squared_error: 2.4553\n",
      "Epoch 160/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.9195 - mean_squared_error: 0.9195 - val_loss: 2.5266 - val_mean_squared_error: 2.5266\n",
      "Epoch 161/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.8124 - mean_squared_error: 0.8124 - val_loss: 2.5134 - val_mean_squared_error: 2.5134\n",
      "Epoch 162/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.7923 - mean_squared_error: 0.7923 - val_loss: 2.4791 - val_mean_squared_error: 2.4791\n",
      "Epoch 163/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.9327 - mean_squared_error: 0.9327 - val_loss: 2.9199 - val_mean_squared_error: 2.9199\n",
      "Epoch 164/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.7270 - mean_squared_error: 0.7270 - val_loss: 2.4433 - val_mean_squared_error: 2.4433\n",
      "Epoch 165/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.7064 - mean_squared_error: 0.7064 - val_loss: 2.4326 - val_mean_squared_error: 2.4326\n",
      "Epoch 166/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.7311 - mean_squared_error: 0.7311 - val_loss: 2.8488 - val_mean_squared_error: 2.8488\n",
      "Epoch 167/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.6783 - mean_squared_error: 0.6783 - val_loss: 2.5596 - val_mean_squared_error: 2.5596\n",
      "Epoch 168/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.6794 - mean_squared_error: 0.6794 - val_loss: 2.4918 - val_mean_squared_error: 2.4918\n",
      "Epoch 169/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.6505 - mean_squared_error: 0.6505 - val_loss: 2.5206 - val_mean_squared_error: 2.5206\n",
      "Epoch 170/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.6456 - mean_squared_error: 0.6456 - val_loss: 2.4658 - val_mean_squared_error: 2.4658\n",
      "Epoch 171/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.6263 - mean_squared_error: 0.6263 - val_loss: 2.4816 - val_mean_squared_error: 2.4816\n",
      "Epoch 172/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.6353 - mean_squared_error: 0.6353 - val_loss: 2.5778 - val_mean_squared_error: 2.5778\n",
      "Epoch 173/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.6141 - mean_squared_error: 0.6141 - val_loss: 2.4902 - val_mean_squared_error: 2.4902\n",
      "Epoch 174/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.7166 - mean_squared_error: 0.7166 - val_loss: 2.6428 - val_mean_squared_error: 2.6428\n",
      "Epoch 175/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.7495 - mean_squared_error: 0.7495 - val_loss: 2.5242 - val_mean_squared_error: 2.5242\n",
      "Epoch 176/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.6697 - mean_squared_error: 0.6697 - val_loss: 2.4598 - val_mean_squared_error: 2.4598\n",
      "Epoch 177/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.6074 - mean_squared_error: 0.6074 - val_loss: 2.5007 - val_mean_squared_error: 2.5007\n",
      "Epoch 178/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.6388 - mean_squared_error: 0.6388 - val_loss: 2.4788 - val_mean_squared_error: 2.4788\n",
      "Epoch 179/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.7502 - mean_squared_error: 0.7502 - val_loss: 2.4912 - val_mean_squared_error: 2.4912\n",
      "Epoch 180/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.7070 - mean_squared_error: 0.7070 - val_loss: 2.5461 - val_mean_squared_error: 2.5461\n",
      "Epoch 181/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.6532 - mean_squared_error: 0.6532 - val_loss: 2.4987 - val_mean_squared_error: 2.4987\n",
      "Epoch 182/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.6069 - mean_squared_error: 0.6069 - val_loss: 2.4723 - val_mean_squared_error: 2.4723\n",
      "Epoch 183/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.5623 - mean_squared_error: 0.5623 - val_loss: 2.8009 - val_mean_squared_error: 2.8009\n",
      "Epoch 184/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.5297 - mean_squared_error: 0.5297 - val_loss: 2.5522 - val_mean_squared_error: 2.5522\n",
      "Epoch 185/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.5595 - mean_squared_error: 0.5595 - val_loss: 2.5136 - val_mean_squared_error: 2.5136\n",
      "Epoch 186/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.5263 - mean_squared_error: 0.5263 - val_loss: 2.5362 - val_mean_squared_error: 2.5362\n",
      "Epoch 187/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.6039 - mean_squared_error: 0.6039 - val_loss: 2.9215 - val_mean_squared_error: 2.9215\n",
      "Epoch 188/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.5564 - mean_squared_error: 0.5564 - val_loss: 2.4887 - val_mean_squared_error: 2.4887\n",
      "Epoch 189/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.5203 - mean_squared_error: 0.5203 - val_loss: 2.4965 - val_mean_squared_error: 2.4965\n",
      "Epoch 190/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.5661 - mean_squared_error: 0.5661 - val_loss: 2.5604 - val_mean_squared_error: 2.5604\n",
      "Epoch 191/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.5523 - mean_squared_error: 0.5523 - val_loss: 2.5992 - val_mean_squared_error: 2.5992\n",
      "Epoch 192/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.6421 - mean_squared_error: 0.6421 - val_loss: 2.5243 - val_mean_squared_error: 2.5243\n",
      "Epoch 193/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.6610 - mean_squared_error: 0.6610 - val_loss: 2.4697 - val_mean_squared_error: 2.4697\n",
      "Epoch 194/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.4957 - mean_squared_error: 0.4957 - val_loss: 2.5248 - val_mean_squared_error: 2.5248\n",
      "Epoch 195/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.4579 - mean_squared_error: 0.4579 - val_loss: 2.5021 - val_mean_squared_error: 2.5021\n",
      "Epoch 196/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.4893 - mean_squared_error: 0.4893 - val_loss: 2.5069 - val_mean_squared_error: 2.5069\n",
      "Epoch 197/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.5042 - mean_squared_error: 0.5042 - val_loss: 2.5487 - val_mean_squared_error: 2.5487\n",
      "Epoch 198/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.4937 - mean_squared_error: 0.4937 - val_loss: 2.5245 - val_mean_squared_error: 2.5245\n",
      "Epoch 199/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.4689 - mean_squared_error: 0.4689 - val_loss: 2.6130 - val_mean_squared_error: 2.6130\n",
      "Epoch 200/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 0.4435 - mean_squared_error: 0.4435 - val_loss: 2.4725 - val_mean_squared_error: 2.4725\n",
      "==================================================\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_27 (Conv2D)           (None, 94, 94, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 47, 47, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 46, 46, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 22, 22, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 500)               3872500   \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 30)                15030     \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 30)                0         \n",
      "=================================================================\n",
      "Total params: 4,148,526\n",
      "Trainable params: 4,148,526\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "==================================================\n",
      "Train on 1819 samples, validate on 321 samples\n",
      "Epoch 1/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 3/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 4/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 5/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 6/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 7/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 8/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 9/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 10/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 11/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 12/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 13/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 14/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 15/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 16/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 17/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 18/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 19/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 20/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 21/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 22/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 23/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 24/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 25/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 26/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 27/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 28/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 29/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 30/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 31/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 32/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 33/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 34/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 35/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 36/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 37/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 38/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 39/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 40/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 41/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 42/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 43/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 44/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 45/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 46/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 47/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 48/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 49/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 50/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 51/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 52/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 53/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 54/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 55/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 56/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 57/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 58/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 59/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 60/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 61/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 62/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 63/200\n",
      "1819/1819 [==============================] - 4s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 64/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 65/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 66/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 67/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 68/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 69/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 70/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 71/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 72/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 73/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 74/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 75/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 76/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 77/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 78/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 79/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 80/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 81/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 82/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 83/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 84/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 85/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 86/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 87/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 88/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 89/200\n",
      "1819/1819 [==============================] - 5s 2ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 90/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 91/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 92/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 93/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 94/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 95/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 96/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 97/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 98/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 99/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 100/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n"
     ]
    }
   ],
   "source": [
    "# Redefine optimizer list to just focus on adam and sgd\n",
    "opt_list = {'adam':adam,'sgd':sgd}\n",
    "\n",
    "# Use an early stopping callback and our timing callback\n",
    "early_stop = callbacks.EarlyStopping(monitor='val_loss', min_delta=0.1,\n",
    "                              patience=100, mode='auto')\n",
    "time_callback = TimeHistory()\n",
    "\n",
    "# Initialize a new data frame to hold our output data\n",
    "cnn_filter_df = pd.DataFrame()\n",
    "\n",
    "# Let's try a range of starting filter sizes from 3 to 16 (our baseline had 32)\n",
    "n_filters = [3, 5, 12, 16]\n",
    "for n in n_filters:\n",
    "    for opt_name, opt in opt_list.items():\n",
    "        model = create_filter_cnn_model(start_filters=n)\n",
    "        model.compile(\n",
    "              optimizer=opt,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mean_squared_error'])\n",
    "        history = model.fit(\n",
    "            X.astype(np.float32), y.astype(np.float32),\n",
    "            epochs=200,\n",
    "            validation_split=0.15, callbacks=[time_callback, early_stop])\n",
    "        times = time_callback.times\n",
    "\n",
    "        # Convert to dataframe\n",
    "        hist = pd.DataFrame(history.history)\n",
    "        hist['epoch'] = history.epoch\n",
    "        hist['RMSE'] = np.sqrt(hist.mean_squared_error)\n",
    "        hist['val_RMSE'] = np.sqrt(hist.val_mean_squared_error)\n",
    "        hist['times'] = times\n",
    "        hist['starting_filter'] = n\n",
    "        hist['layers'] = 3\n",
    "        hist['pooling'] = 'yes'\n",
    "        hist['fc_layer'] = 500\n",
    "        hist['activation'] = 'relu'\n",
    "        hist['optimizer'] = opt_name\n",
    "        hist['lrate'] = opt.get_config()['learning_rate']\n",
    "\n",
    "        # Keep concatenating to dataframe\n",
    "        cnn_filter_df = pd.concat([cnn_filter_df,hist])\n",
    "\n",
    "        # Re-pickle after every model to retain progress\n",
    "        cnn_filter_df.to_pickle(\"OutputData/cnn_filter_df.pkl\")\n",
    "\n",
    "        # Save models.\n",
    "        filename = \"filter_cnn_model_{}_{}filters\".format(opt_name, n)\n",
    "        model.save(\"Models/\"+filename+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dropout_cnn_model(d, step):\n",
    "    '''\n",
    "    Simple function that retruns a keras cnn model \n",
    "    '''\n",
    "    cnn_model = tf.keras.models.Sequential()\n",
    "    cnn_model.add(tf.keras.layers.InputLayer(input_shape=(96, 96, 1)))\n",
    "    cnn_model.add(tf.keras.layers.Conv2D(16, (3, 3), padding='valid', activation='relu'))\n",
    "    cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    cnn_model.add(tf.keras.layers.Dropout(d))\n",
    "    cnn_model.add(tf.keras.layers.Conv2D(32, (2, 2), padding='valid', activation='relu'))\n",
    "    cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    cnn_model.add(tf.keras.layers.Dropout(d+step))\n",
    "    cnn_model.add(tf.keras.layers.Conv2D(64, (2, 2), padding='valid', activation='relu'))\n",
    "    cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    cnn_model.add(tf.keras.layers.Dropout(d+2*step))\n",
    "    cnn_model.add(tf.keras.layers.Flatten())\n",
    "    cnn_model.add(tf.keras.layers.Dense(500))\n",
    "    cnn_model.add(tf.keras.layers.Dropout(d+3*step))\n",
    "    cnn_model.add(tf.keras.layers.Activation('relu'))\n",
    "    cnn_model.add(tf.keras.layers.Dense(500))\n",
    "    cnn_model.add(tf.keras.layers.Activation('relu'))\n",
    "    cnn_model.add(tf.keras.layers.Dense(30))\n",
    "    cnn_model.add(tf.keras.layers.Activation('linear'))\n",
    "\n",
    "    print(50*\"=\")\n",
    "    print(cnn_model.summary())\n",
    "    print(50*\"=\")\n",
    "    \n",
    "    return cnn_model\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_42 (Conv2D)           (None, 94, 94, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 47, 47, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 47, 47, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 46, 46, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 22, 22, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 500)               3872500   \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 30)                15030     \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 30)                0         \n",
      "=================================================================\n",
      "Total params: 4,148,526\n",
      "Trainable params: 4,148,526\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "==================================================\n",
      "Train on 1819 samples, validate on 321 samples\n",
      "Epoch 1/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 275.6915 - mean_squared_error: 275.6915 - val_loss: 21.5820 - val_mean_squared_error: 21.5820\n",
      "Epoch 2/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 16.3052 - mean_squared_error: 16.3052 - val_loss: 20.6774 - val_mean_squared_error: 20.6774\n",
      "Epoch 3/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 15.5849 - mean_squared_error: 15.5849 - val_loss: 34.5814 - val_mean_squared_error: 34.5814\n",
      "Epoch 4/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 14.4037 - mean_squared_error: 14.4037 - val_loss: 17.3761 - val_mean_squared_error: 17.3761\n",
      "Epoch 5/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 14.8755 - mean_squared_error: 14.8755 - val_loss: 48.3651 - val_mean_squared_error: 48.3651\n",
      "Epoch 6/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 15.3427 - mean_squared_error: 15.3427 - val_loss: 41.4454 - val_mean_squared_error: 41.4454\n",
      "Epoch 7/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 14.3845 - mean_squared_error: 14.3845 - val_loss: 27.1338 - val_mean_squared_error: 27.1338\n",
      "Epoch 8/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 14.0533 - mean_squared_error: 14.0533 - val_loss: 31.8529 - val_mean_squared_error: 31.8529\n",
      "Epoch 9/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 15.0090 - mean_squared_error: 15.0090 - val_loss: 21.5396 - val_mean_squared_error: 21.5396\n",
      "Epoch 10/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 14.2471 - mean_squared_error: 14.2471 - val_loss: 16.2000 - val_mean_squared_error: 16.2000\n",
      "Epoch 11/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 13.2440 - mean_squared_error: 13.2439 - val_loss: 17.5776 - val_mean_squared_error: 17.5776\n",
      "Epoch 12/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 13.3908 - mean_squared_error: 13.3908 - val_loss: 22.1920 - val_mean_squared_error: 22.1920\n",
      "Epoch 13/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 12.8590 - mean_squared_error: 12.8590 - val_loss: 23.6324 - val_mean_squared_error: 23.6324\n",
      "Epoch 14/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 13.3664 - mean_squared_error: 13.3664 - val_loss: 35.7211 - val_mean_squared_error: 35.7211\n",
      "Epoch 15/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 13.3051 - mean_squared_error: 13.3051 - val_loss: 18.7958 - val_mean_squared_error: 18.7958\n",
      "Epoch 16/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 13.4431 - mean_squared_error: 13.4431 - val_loss: 24.7465 - val_mean_squared_error: 24.7465\n",
      "Epoch 17/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 12.8333 - mean_squared_error: 12.8333 - val_loss: 19.3980 - val_mean_squared_error: 19.3980\n",
      "Epoch 18/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 12.6567 - mean_squared_error: 12.6567 - val_loss: 21.2733 - val_mean_squared_error: 21.2733\n",
      "Epoch 19/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 12.8277 - mean_squared_error: 12.8277 - val_loss: 16.9464 - val_mean_squared_error: 16.9464\n",
      "Epoch 20/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 12.7044 - mean_squared_error: 12.7044 - val_loss: 16.4040 - val_mean_squared_error: 16.4040\n",
      "Epoch 21/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 13.3697 - mean_squared_error: 13.3697 - val_loss: 31.2388 - val_mean_squared_error: 31.2388\n",
      "Epoch 22/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 12.8117 - mean_squared_error: 12.8117 - val_loss: 22.5016 - val_mean_squared_error: 22.5016\n",
      "Epoch 23/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 12.7987 - mean_squared_error: 12.7988 - val_loss: 19.5996 - val_mean_squared_error: 19.5996\n",
      "Epoch 24/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 12.6353 - mean_squared_error: 12.6353 - val_loss: 21.3052 - val_mean_squared_error: 21.3052\n",
      "Epoch 25/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 12.7254 - mean_squared_error: 12.7254 - val_loss: 13.0339 - val_mean_squared_error: 13.0339\n",
      "Epoch 26/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.3333 - mean_squared_error: 12.3333 - val_loss: 15.6599 - val_mean_squared_error: 15.6599\n",
      "Epoch 27/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 12.4044 - mean_squared_error: 12.4044 - val_loss: 11.0152 - val_mean_squared_error: 11.0152\n",
      "Epoch 28/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.3376 - mean_squared_error: 12.3376 - val_loss: 17.1278 - val_mean_squared_error: 17.1278\n",
      "Epoch 29/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 13.4668 - mean_squared_error: 13.4668 - val_loss: 10.3276 - val_mean_squared_error: 10.3276\n",
      "Epoch 30/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 12.8438 - mean_squared_error: 12.8438 - val_loss: 16.0542 - val_mean_squared_error: 16.0542\n",
      "Epoch 31/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 11.8210 - mean_squared_error: 11.8210 - val_loss: 18.1101 - val_mean_squared_error: 18.1101\n",
      "Epoch 32/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 11.7920 - mean_squared_error: 11.7920 - val_loss: 16.1971 - val_mean_squared_error: 16.1971\n",
      "Epoch 33/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 11.7662 - mean_squared_error: 11.7662 - val_loss: 15.5905 - val_mean_squared_error: 15.5905\n",
      "Epoch 34/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 11.4776 - mean_squared_error: 11.4776 - val_loss: 13.1037 - val_mean_squared_error: 13.1037\n",
      "Epoch 35/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 11.3230 - mean_squared_error: 11.3230 - val_loss: 19.6061 - val_mean_squared_error: 19.6061\n",
      "Epoch 36/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 11.1426 - mean_squared_error: 11.1426 - val_loss: 20.4805 - val_mean_squared_error: 20.4805\n",
      "Epoch 37/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 11.4000 - mean_squared_error: 11.4000 - val_loss: 10.8982 - val_mean_squared_error: 10.8982\n",
      "Epoch 38/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 11.2731 - mean_squared_error: 11.2731 - val_loss: 21.3285 - val_mean_squared_error: 21.3285\n",
      "Epoch 39/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 13.1546 - mean_squared_error: 13.1546 - val_loss: 9.4961 - val_mean_squared_error: 9.4961\n",
      "Epoch 40/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.9302 - mean_squared_error: 10.9302 - val_loss: 11.0660 - val_mean_squared_error: 11.0660\n",
      "Epoch 41/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.2516 - mean_squared_error: 10.2516 - val_loss: 11.5018 - val_mean_squared_error: 11.5018\n",
      "Epoch 42/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.6358 - mean_squared_error: 10.6358 - val_loss: 9.4160 - val_mean_squared_error: 9.4160\n",
      "Epoch 43/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.8612 - mean_squared_error: 9.8612 - val_loss: 15.7825 - val_mean_squared_error: 15.7825\n",
      "Epoch 44/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.3883 - mean_squared_error: 10.3883 - val_loss: 9.6917 - val_mean_squared_error: 9.6917\n",
      "Epoch 45/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.7438 - mean_squared_error: 9.7438 - val_loss: 17.2863 - val_mean_squared_error: 17.2863\n",
      "Epoch 46/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.3242 - mean_squared_error: 10.3242 - val_loss: 9.6977 - val_mean_squared_error: 9.6977\n",
      "Epoch 47/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.1202 - mean_squared_error: 10.1202 - val_loss: 8.5620 - val_mean_squared_error: 8.5620\n",
      "Epoch 48/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.4127 - mean_squared_error: 9.4127 - val_loss: 10.1593 - val_mean_squared_error: 10.1593\n",
      "Epoch 49/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.1250 - mean_squared_error: 9.1250 - val_loss: 14.4882 - val_mean_squared_error: 14.4882\n",
      "Epoch 50/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.7945 - mean_squared_error: 9.7945 - val_loss: 9.3548 - val_mean_squared_error: 9.3548\n",
      "Epoch 51/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 8.9088 - mean_squared_error: 8.9088 - val_loss: 11.6609 - val_mean_squared_error: 11.6609\n",
      "Epoch 52/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.6954 - mean_squared_error: 9.6954 - val_loss: 8.1071 - val_mean_squared_error: 8.1071\n",
      "Epoch 53/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.0756 - mean_squared_error: 9.0756 - val_loss: 14.7670 - val_mean_squared_error: 14.7670\n",
      "Epoch 54/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.0546 - mean_squared_error: 9.0546 - val_loss: 17.3251 - val_mean_squared_error: 17.3251\n",
      "Epoch 55/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 8.3316 - mean_squared_error: 8.3316 - val_loss: 7.5474 - val_mean_squared_error: 7.5474\n",
      "Epoch 56/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 8.7967 - mean_squared_error: 8.7967 - val_loss: 8.4358 - val_mean_squared_error: 8.4358\n",
      "Epoch 57/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 8.5926 - mean_squared_error: 8.5926 - val_loss: 12.2032 - val_mean_squared_error: 12.2032\n",
      "Epoch 58/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 8.8638 - mean_squared_error: 8.8638 - val_loss: 10.1002 - val_mean_squared_error: 10.1002\n",
      "Epoch 59/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 8.3587 - mean_squared_error: 8.3587 - val_loss: 7.1273 - val_mean_squared_error: 7.1273\n",
      "Epoch 60/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 8.9929 - mean_squared_error: 8.9929 - val_loss: 7.0903 - val_mean_squared_error: 7.0903\n",
      "Epoch 61/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.0511 - mean_squared_error: 9.0511 - val_loss: 7.0166 - val_mean_squared_error: 7.0166\n",
      "Epoch 62/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 8.4515 - mean_squared_error: 8.4515 - val_loss: 7.9707 - val_mean_squared_error: 7.9707\n",
      "Epoch 63/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 8.5220 - mean_squared_error: 8.5220 - val_loss: 6.5742 - val_mean_squared_error: 6.5742\n",
      "Epoch 64/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 8.0225 - mean_squared_error: 8.0225 - val_loss: 7.7922 - val_mean_squared_error: 7.7922\n",
      "Epoch 65/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 7.9038 - mean_squared_error: 7.9038 - val_loss: 8.9909 - val_mean_squared_error: 8.9909\n",
      "Epoch 66/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 8.3436 - mean_squared_error: 8.3436 - val_loss: 9.1074 - val_mean_squared_error: 9.1074\n",
      "Epoch 67/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 7.9596 - mean_squared_error: 7.9596 - val_loss: 5.5665 - val_mean_squared_error: 5.5665\n",
      "Epoch 68/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 7.5712 - mean_squared_error: 7.5712 - val_loss: 11.2887 - val_mean_squared_error: 11.2887\n",
      "Epoch 69/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 8.0984 - mean_squared_error: 8.0984 - val_loss: 5.9793 - val_mean_squared_error: 5.9793\n",
      "Epoch 70/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 7.4820 - mean_squared_error: 7.4820 - val_loss: 5.3430 - val_mean_squared_error: 5.3430\n",
      "Epoch 71/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 7.6185 - mean_squared_error: 7.6185 - val_loss: 12.8246 - val_mean_squared_error: 12.8246\n",
      "Epoch 72/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 7.4794 - mean_squared_error: 7.4794 - val_loss: 4.4151 - val_mean_squared_error: 4.4151\n",
      "Epoch 73/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 7.3809 - mean_squared_error: 7.3809 - val_loss: 5.4549 - val_mean_squared_error: 5.4549\n",
      "Epoch 74/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 7.2139 - mean_squared_error: 7.2139 - val_loss: 5.2703 - val_mean_squared_error: 5.2703\n",
      "Epoch 75/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 8.0066 - mean_squared_error: 8.0066 - val_loss: 7.0254 - val_mean_squared_error: 7.0254\n",
      "Epoch 76/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 7.3026 - mean_squared_error: 7.3026 - val_loss: 4.4788 - val_mean_squared_error: 4.4788\n",
      "Epoch 77/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 8.2985 - mean_squared_error: 8.2985 - val_loss: 7.4461 - val_mean_squared_error: 7.4461\n",
      "Epoch 78/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 7.1787 - mean_squared_error: 7.1787 - val_loss: 6.7539 - val_mean_squared_error: 6.7539\n",
      "Epoch 79/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 7.2783 - mean_squared_error: 7.2783 - val_loss: 6.8591 - val_mean_squared_error: 6.8591\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 7.2107 - mean_squared_error: 7.2107 - val_loss: 6.2597 - val_mean_squared_error: 6.2597\n",
      "Epoch 81/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 7.0343 - mean_squared_error: 7.0343 - val_loss: 4.2983 - val_mean_squared_error: 4.2983\n",
      "Epoch 82/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 7.7750 - mean_squared_error: 7.7750 - val_loss: 5.7280 - val_mean_squared_error: 5.7280\n",
      "Epoch 83/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 7.5477 - mean_squared_error: 7.5477 - val_loss: 9.3448 - val_mean_squared_error: 9.3448\n",
      "Epoch 84/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.9841 - mean_squared_error: 6.9841 - val_loss: 6.9367 - val_mean_squared_error: 6.9367\n",
      "Epoch 85/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 7.0895 - mean_squared_error: 7.0895 - val_loss: 4.7552 - val_mean_squared_error: 4.7552\n",
      "Epoch 86/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 7.0011 - mean_squared_error: 7.0011 - val_loss: 8.7096 - val_mean_squared_error: 8.7096\n",
      "Epoch 87/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.7919 - mean_squared_error: 6.7919 - val_loss: 5.2968 - val_mean_squared_error: 5.2968\n",
      "Epoch 88/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 7.0456 - mean_squared_error: 7.0456 - val_loss: 9.9574 - val_mean_squared_error: 9.9574\n",
      "Epoch 89/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 7.2457 - mean_squared_error: 7.2457 - val_loss: 8.0359 - val_mean_squared_error: 8.0359\n",
      "Epoch 90/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.7630 - mean_squared_error: 6.7630 - val_loss: 6.5869 - val_mean_squared_error: 6.5869\n",
      "Epoch 91/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 6.6770 - mean_squared_error: 6.6770 - val_loss: 5.4409 - val_mean_squared_error: 5.4409\n",
      "Epoch 92/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 7.0665 - mean_squared_error: 7.0665 - val_loss: 5.8644 - val_mean_squared_error: 5.8644\n",
      "Epoch 93/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.7665 - mean_squared_error: 6.7665 - val_loss: 9.5936 - val_mean_squared_error: 9.5936\n",
      "Epoch 94/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.6074 - mean_squared_error: 6.6074 - val_loss: 6.6476 - val_mean_squared_error: 6.6476\n",
      "Epoch 95/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.5833 - mean_squared_error: 6.5833 - val_loss: 9.4991 - val_mean_squared_error: 9.4991\n",
      "Epoch 96/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.7140 - mean_squared_error: 6.7140 - val_loss: 4.3848 - val_mean_squared_error: 4.3848\n",
      "Epoch 97/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.7070 - mean_squared_error: 6.7070 - val_loss: 5.1623 - val_mean_squared_error: 5.1623\n",
      "Epoch 98/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.7559 - mean_squared_error: 6.7559 - val_loss: 10.4147 - val_mean_squared_error: 10.4147\n",
      "Epoch 99/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.7880 - mean_squared_error: 6.7880 - val_loss: 3.6753 - val_mean_squared_error: 3.6753\n",
      "Epoch 100/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 7.1936 - mean_squared_error: 7.1936 - val_loss: 9.4726 - val_mean_squared_error: 9.4726\n",
      "Epoch 101/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 7.2475 - mean_squared_error: 7.2475 - val_loss: 6.0284 - val_mean_squared_error: 6.0284\n",
      "Epoch 102/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 6.3278 - mean_squared_error: 6.3278 - val_loss: 8.8175 - val_mean_squared_error: 8.8175\n",
      "Epoch 103/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 7.6286 - mean_squared_error: 7.6286 - val_loss: 3.8291 - val_mean_squared_error: 3.8291\n",
      "Epoch 104/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 6.8023 - mean_squared_error: 6.8023 - val_loss: 7.4284 - val_mean_squared_error: 7.4284\n",
      "Epoch 105/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.5866 - mean_squared_error: 6.5866 - val_loss: 6.8182 - val_mean_squared_error: 6.8182\n",
      "Epoch 106/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 6.4136 - mean_squared_error: 6.4136 - val_loss: 6.7754 - val_mean_squared_error: 6.7754\n",
      "Epoch 107/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 6.4548 - mean_squared_error: 6.4548 - val_loss: 4.5972 - val_mean_squared_error: 4.5972\n",
      "Epoch 108/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.4292 - mean_squared_error: 6.4292 - val_loss: 4.4868 - val_mean_squared_error: 4.4868\n",
      "Epoch 109/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.9926 - mean_squared_error: 6.9926 - val_loss: 3.6225 - val_mean_squared_error: 3.6225\n",
      "Epoch 110/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 7.3622 - mean_squared_error: 7.3622 - val_loss: 7.7185 - val_mean_squared_error: 7.7185\n",
      "Epoch 111/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.1929 - mean_squared_error: 6.1929 - val_loss: 6.5691 - val_mean_squared_error: 6.5691\n",
      "Epoch 112/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 6.2680 - mean_squared_error: 6.2680 - val_loss: 5.1296 - val_mean_squared_error: 5.1296\n",
      "Epoch 113/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.8877 - mean_squared_error: 6.8877 - val_loss: 4.3182 - val_mean_squared_error: 4.3182\n",
      "Epoch 114/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 6.6276 - mean_squared_error: 6.6276 - val_loss: 4.4109 - val_mean_squared_error: 4.4109\n",
      "Epoch 115/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 6.0163 - mean_squared_error: 6.0163 - val_loss: 4.8921 - val_mean_squared_error: 4.8921\n",
      "Epoch 116/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.0272 - mean_squared_error: 6.0272 - val_loss: 7.4689 - val_mean_squared_error: 7.4689\n",
      "Epoch 117/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.6435 - mean_squared_error: 6.6435 - val_loss: 14.9032 - val_mean_squared_error: 14.9032\n",
      "Epoch 118/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 6.4441 - mean_squared_error: 6.4441 - val_loss: 3.5760 - val_mean_squared_error: 3.5760\n",
      "Epoch 119/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.2742 - mean_squared_error: 6.2742 - val_loss: 6.9848 - val_mean_squared_error: 6.9848\n",
      "Epoch 120/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.9627 - mean_squared_error: 5.9627 - val_loss: 5.9607 - val_mean_squared_error: 5.9607\n",
      "Epoch 121/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.0436 - mean_squared_error: 6.0436 - val_loss: 7.1838 - val_mean_squared_error: 7.1838\n",
      "Epoch 122/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.2740 - mean_squared_error: 6.2740 - val_loss: 7.2334 - val_mean_squared_error: 7.2334\n",
      "Epoch 123/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.7529 - mean_squared_error: 6.7529 - val_loss: 6.9204 - val_mean_squared_error: 6.9204\n",
      "Epoch 124/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.1744 - mean_squared_error: 6.1744 - val_loss: 3.4490 - val_mean_squared_error: 3.4490\n",
      "Epoch 125/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.9343 - mean_squared_error: 5.9343 - val_loss: 8.1362 - val_mean_squared_error: 8.1362\n",
      "Epoch 126/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.8293 - mean_squared_error: 5.8293 - val_loss: 5.2653 - val_mean_squared_error: 5.2653\n",
      "Epoch 127/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.7315 - mean_squared_error: 5.7315 - val_loss: 6.4166 - val_mean_squared_error: 6.4166\n",
      "Epoch 128/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.8552 - mean_squared_error: 5.8552 - val_loss: 4.4803 - val_mean_squared_error: 4.4803\n",
      "Epoch 129/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.1538 - mean_squared_error: 6.1538 - val_loss: 3.5491 - val_mean_squared_error: 3.5491\n",
      "Epoch 130/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.9021 - mean_squared_error: 5.9021 - val_loss: 3.4627 - val_mean_squared_error: 3.4627\n",
      "Epoch 131/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.7423 - mean_squared_error: 6.7423 - val_loss: 5.3555 - val_mean_squared_error: 5.3555\n",
      "Epoch 132/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.8698 - mean_squared_error: 5.8698 - val_loss: 5.4521 - val_mean_squared_error: 5.4521\n",
      "Epoch 133/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.7023 - mean_squared_error: 5.7023 - val_loss: 8.4158 - val_mean_squared_error: 8.4158\n",
      "Epoch 134/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.8440 - mean_squared_error: 5.8440 - val_loss: 13.4891 - val_mean_squared_error: 13.4891\n",
      "Epoch 135/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.8185 - mean_squared_error: 5.8185 - val_loss: 5.5265 - val_mean_squared_error: 5.5265\n",
      "Epoch 136/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 6.2208 - mean_squared_error: 6.2208 - val_loss: 5.2358 - val_mean_squared_error: 5.2358\n",
      "Epoch 137/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.4556 - mean_squared_error: 5.4556 - val_loss: 6.3408 - val_mean_squared_error: 6.3408\n",
      "Epoch 138/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.7988 - mean_squared_error: 5.7988 - val_loss: 4.0979 - val_mean_squared_error: 4.0979\n",
      "Epoch 139/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.7685 - mean_squared_error: 5.7685 - val_loss: 6.1837 - val_mean_squared_error: 6.1837\n",
      "Epoch 140/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 5.4498 - mean_squared_error: 5.4498 - val_loss: 6.2619 - val_mean_squared_error: 6.2619\n",
      "Epoch 141/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.3725 - mean_squared_error: 5.3725 - val_loss: 7.1919 - val_mean_squared_error: 7.1919\n",
      "Epoch 142/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.3599 - mean_squared_error: 5.3599 - val_loss: 12.5698 - val_mean_squared_error: 12.5698\n",
      "Epoch 143/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.5622 - mean_squared_error: 5.5622 - val_loss: 6.3175 - val_mean_squared_error: 6.3175\n",
      "Epoch 144/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.3780 - mean_squared_error: 5.3780 - val_loss: 9.9478 - val_mean_squared_error: 9.9478\n",
      "Epoch 145/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.8469 - mean_squared_error: 5.8469 - val_loss: 4.0112 - val_mean_squared_error: 4.0112\n",
      "Epoch 146/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.3866 - mean_squared_error: 5.3866 - val_loss: 4.9632 - val_mean_squared_error: 4.9632\n",
      "Epoch 147/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.7204 - mean_squared_error: 5.7204 - val_loss: 4.1656 - val_mean_squared_error: 4.1656\n",
      "Epoch 148/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.0740 - mean_squared_error: 5.0740 - val_loss: 4.9241 - val_mean_squared_error: 4.9241\n",
      "Epoch 149/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.2961 - mean_squared_error: 5.2961 - val_loss: 10.6058 - val_mean_squared_error: 10.6058\n",
      "Epoch 150/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.3222 - mean_squared_error: 5.3222 - val_loss: 11.4384 - val_mean_squared_error: 11.4384\n",
      "Epoch 151/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.5143 - mean_squared_error: 5.5143 - val_loss: 7.0022 - val_mean_squared_error: 7.0022\n",
      "Epoch 152/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.2347 - mean_squared_error: 6.2347 - val_loss: 9.0998 - val_mean_squared_error: 9.0998\n",
      "Epoch 153/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.8964 - mean_squared_error: 4.8964 - val_loss: 13.8027 - val_mean_squared_error: 13.8027\n",
      "Epoch 154/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.4771 - mean_squared_error: 5.4771 - val_loss: 7.3038 - val_mean_squared_error: 7.3038\n",
      "Epoch 155/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.9610 - mean_squared_error: 4.9610 - val_loss: 8.2594 - val_mean_squared_error: 8.2594\n",
      "Epoch 156/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.2236 - mean_squared_error: 5.2236 - val_loss: 6.7265 - val_mean_squared_error: 6.7265\n",
      "Epoch 157/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.9563 - mean_squared_error: 4.9563 - val_loss: 7.0627 - val_mean_squared_error: 7.0627\n",
      "Epoch 158/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.8564 - mean_squared_error: 4.8564 - val_loss: 10.0367 - val_mean_squared_error: 10.0367\n",
      "Epoch 159/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.0730 - mean_squared_error: 6.0730 - val_loss: 8.4936 - val_mean_squared_error: 8.4936\n",
      "Epoch 160/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.6222 - mean_squared_error: 4.6222 - val_loss: 8.0277 - val_mean_squared_error: 8.0277\n",
      "Epoch 161/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.5034 - mean_squared_error: 4.5034 - val_loss: 5.5474 - val_mean_squared_error: 5.5474\n",
      "Epoch 162/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 4.3660 - mean_squared_error: 4.3660 - val_loss: 9.4944 - val_mean_squared_error: 9.4944\n",
      "Epoch 163/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.3877 - mean_squared_error: 4.3877 - val_loss: 14.2879 - val_mean_squared_error: 14.2879\n",
      "Epoch 164/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.3492 - mean_squared_error: 4.3492 - val_loss: 14.0435 - val_mean_squared_error: 14.0435\n",
      "Epoch 165/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.5179 - mean_squared_error: 4.5179 - val_loss: 14.5391 - val_mean_squared_error: 14.5391\n",
      "Epoch 166/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.5291 - mean_squared_error: 4.5291 - val_loss: 15.3103 - val_mean_squared_error: 15.3103\n",
      "Epoch 167/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.3219 - mean_squared_error: 4.3219 - val_loss: 17.1368 - val_mean_squared_error: 17.1368\n",
      "Epoch 168/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.7249 - mean_squared_error: 4.7249 - val_loss: 12.6102 - val_mean_squared_error: 12.6102\n",
      "Epoch 169/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.2556 - mean_squared_error: 4.2556 - val_loss: 16.8104 - val_mean_squared_error: 16.8104\n",
      "Epoch 170/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 4.1097 - mean_squared_error: 4.1097 - val_loss: 29.6208 - val_mean_squared_error: 29.6208\n",
      "Epoch 171/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 4.2302 - mean_squared_error: 4.2302 - val_loss: 20.8549 - val_mean_squared_error: 20.8549\n",
      "Epoch 172/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.1894 - mean_squared_error: 4.1894 - val_loss: 9.4984 - val_mean_squared_error: 9.4984\n",
      "Epoch 173/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.8527 - mean_squared_error: 3.8527 - val_loss: 23.3529 - val_mean_squared_error: 23.3529\n",
      "Epoch 174/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.7356 - mean_squared_error: 3.7356 - val_loss: 21.4071 - val_mean_squared_error: 21.4071\n",
      "Epoch 175/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.4886 - mean_squared_error: 3.4886 - val_loss: 16.0755 - val_mean_squared_error: 16.0755\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.7648 - mean_squared_error: 3.7648 - val_loss: 17.8024 - val_mean_squared_error: 17.8024\n",
      "Epoch 177/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.3802 - mean_squared_error: 3.3802 - val_loss: 21.5238 - val_mean_squared_error: 21.5238\n",
      "Epoch 178/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.2918 - mean_squared_error: 3.2918 - val_loss: 26.4062 - val_mean_squared_error: 26.4062\n",
      "Epoch 179/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.4780 - mean_squared_error: 3.4780 - val_loss: 26.5462 - val_mean_squared_error: 26.5462\n",
      "Epoch 180/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.4175 - mean_squared_error: 3.4175 - val_loss: 33.5745 - val_mean_squared_error: 33.5745\n",
      "Epoch 181/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.5943 - mean_squared_error: 3.5943 - val_loss: 18.6511 - val_mean_squared_error: 18.6511\n",
      "Epoch 182/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.2358 - mean_squared_error: 3.2358 - val_loss: 28.0317 - val_mean_squared_error: 28.0317\n",
      "Epoch 183/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 3.3469 - mean_squared_error: 3.3469 - val_loss: 31.1191 - val_mean_squared_error: 31.1191\n",
      "Epoch 184/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 3.0816 - mean_squared_error: 3.0816 - val_loss: 24.2448 - val_mean_squared_error: 24.2448\n",
      "Epoch 185/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.1096 - mean_squared_error: 3.1096 - val_loss: 28.6262 - val_mean_squared_error: 28.6262\n",
      "Epoch 186/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.0745 - mean_squared_error: 3.0745 - val_loss: 31.9789 - val_mean_squared_error: 31.9789\n",
      "Epoch 187/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.2559 - mean_squared_error: 3.2559 - val_loss: 33.1006 - val_mean_squared_error: 33.1006\n",
      "Epoch 188/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.2122 - mean_squared_error: 3.2122 - val_loss: 34.3214 - val_mean_squared_error: 34.3214\n",
      "Epoch 189/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.0589 - mean_squared_error: 3.0589 - val_loss: 35.4544 - val_mean_squared_error: 35.4544\n",
      "Epoch 190/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.9506 - mean_squared_error: 2.9506 - val_loss: 34.1252 - val_mean_squared_error: 34.1252\n",
      "Epoch 191/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.9949 - mean_squared_error: 2.9949 - val_loss: 26.1507 - val_mean_squared_error: 26.1507\n",
      "Epoch 192/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.9423 - mean_squared_error: 2.9423 - val_loss: 35.9207 - val_mean_squared_error: 35.9207\n",
      "Epoch 193/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.1284 - mean_squared_error: 3.1284 - val_loss: 28.8991 - val_mean_squared_error: 28.8991\n",
      "Epoch 194/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 3.0875 - mean_squared_error: 3.0875 - val_loss: 38.1613 - val_mean_squared_error: 38.1613\n",
      "Epoch 195/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.8097 - mean_squared_error: 2.8097 - val_loss: 39.0360 - val_mean_squared_error: 39.0360\n",
      "Epoch 196/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.8193 - mean_squared_error: 2.8193 - val_loss: 41.7380 - val_mean_squared_error: 41.7380\n",
      "Epoch 197/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 3.0735 - mean_squared_error: 3.0735 - val_loss: 40.2402 - val_mean_squared_error: 40.2402\n",
      "Epoch 198/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.8853 - mean_squared_error: 2.8853 - val_loss: 43.7143 - val_mean_squared_error: 43.7143\n",
      "Epoch 199/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 3.2719 - mean_squared_error: 3.2719 - val_loss: 41.6459 - val_mean_squared_error: 41.6459\n",
      "Epoch 200/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 2.7222 - mean_squared_error: 2.7222 - val_loss: 32.7523 - val_mean_squared_error: 32.7523\n",
      "==================================================\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_45 (Conv2D)           (None, 94, 94, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 47, 47, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 47, 47, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 46, 46, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 22, 22, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 500)               3872500   \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 30)                15030     \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 30)                0         \n",
      "=================================================================\n",
      "Total params: 4,148,526\n",
      "Trainable params: 4,148,526\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "==================================================\n",
      "Train on 1819 samples, validate on 321 samples\n",
      "Epoch 1/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 1124.2485 - mean_squared_error: 1124.2487 - val_loss: 33.9910 - val_mean_squared_error: 33.9910\n",
      "Epoch 2/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 34.1683 - mean_squared_error: 34.1683 - val_loss: 11.2822 - val_mean_squared_error: 11.2822\n",
      "Epoch 3/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 23.8070 - mean_squared_error: 23.8070 - val_loss: 12.2172 - val_mean_squared_error: 12.2172\n",
      "Epoch 4/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 22.2713 - mean_squared_error: 22.2713 - val_loss: 16.4675 - val_mean_squared_error: 16.4675\n",
      "Epoch 5/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 22.1206 - mean_squared_error: 22.1206 - val_loss: 15.3532 - val_mean_squared_error: 15.3532\n",
      "Epoch 6/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 22.1624 - mean_squared_error: 22.1624 - val_loss: 11.1586 - val_mean_squared_error: 11.1586\n",
      "Epoch 7/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 22.0316 - mean_squared_error: 22.0316 - val_loss: 14.0613 - val_mean_squared_error: 14.0613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 21.0265 - mean_squared_error: 21.0265 - val_loss: 10.8983 - val_mean_squared_error: 10.8983\n",
      "Epoch 9/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 21.7446 - mean_squared_error: 21.7446 - val_loss: 16.3793 - val_mean_squared_error: 16.3793\n",
      "Epoch 10/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 20.8288 - mean_squared_error: 20.8288 - val_loss: 11.1855 - val_mean_squared_error: 11.1855\n",
      "Epoch 11/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 20.5463 - mean_squared_error: 20.5463 - val_loss: 10.3606 - val_mean_squared_error: 10.3606\n",
      "Epoch 12/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 19.8110 - mean_squared_error: 19.8110 - val_loss: 13.9932 - val_mean_squared_error: 13.9932\n",
      "Epoch 13/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 20.7683 - mean_squared_error: 20.7683 - val_loss: 13.1759 - val_mean_squared_error: 13.1759\n",
      "Epoch 14/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 20.1643 - mean_squared_error: 20.1643 - val_loss: 14.9845 - val_mean_squared_error: 14.9845\n",
      "Epoch 15/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 20.5482 - mean_squared_error: 20.5482 - val_loss: 11.3512 - val_mean_squared_error: 11.3512\n",
      "Epoch 16/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 19.7362 - mean_squared_error: 19.7362 - val_loss: 14.0896 - val_mean_squared_error: 14.0896\n",
      "Epoch 17/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 19.9948 - mean_squared_error: 19.9948 - val_loss: 16.9741 - val_mean_squared_error: 16.9741\n",
      "Epoch 18/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 20.0518 - mean_squared_error: 20.0518 - val_loss: 10.4839 - val_mean_squared_error: 10.4839\n",
      "Epoch 19/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 20.4546 - mean_squared_error: 20.4546 - val_loss: 15.2287 - val_mean_squared_error: 15.2287\n",
      "Epoch 20/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 19.9063 - mean_squared_error: 19.9063 - val_loss: 11.8613 - val_mean_squared_error: 11.8613\n",
      "Epoch 21/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 19.8187 - mean_squared_error: 19.8187 - val_loss: 13.0131 - val_mean_squared_error: 13.0131\n",
      "Epoch 22/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 19.7863 - mean_squared_error: 19.7863 - val_loss: 10.4428 - val_mean_squared_error: 10.4428\n",
      "Epoch 23/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 20.2175 - mean_squared_error: 20.2175 - val_loss: 11.3054 - val_mean_squared_error: 11.3054\n",
      "Epoch 24/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 19.6742 - mean_squared_error: 19.6742 - val_loss: 13.5293 - val_mean_squared_error: 13.5293\n",
      "Epoch 25/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 19.6895 - mean_squared_error: 19.6895 - val_loss: 12.0100 - val_mean_squared_error: 12.0100\n",
      "Epoch 26/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 19.2420 - mean_squared_error: 19.2420 - val_loss: 10.1871 - val_mean_squared_error: 10.1871\n",
      "Epoch 27/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 19.1387 - mean_squared_error: 19.1387 - val_loss: 12.3640 - val_mean_squared_error: 12.3640\n",
      "Epoch 28/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 18.4691 - mean_squared_error: 18.4691 - val_loss: 13.6236 - val_mean_squared_error: 13.6236\n",
      "Epoch 29/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 19.3304 - mean_squared_error: 19.3304 - val_loss: 10.7757 - val_mean_squared_error: 10.7757\n",
      "Epoch 30/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 19.3912 - mean_squared_error: 19.3912 - val_loss: 10.5549 - val_mean_squared_error: 10.5549\n",
      "Epoch 31/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 19.4864 - mean_squared_error: 19.4864 - val_loss: 10.1805 - val_mean_squared_error: 10.1805\n",
      "Epoch 32/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 19.2940 - mean_squared_error: 19.2940 - val_loss: 12.6565 - val_mean_squared_error: 12.6565\n",
      "Epoch 33/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 19.3164 - mean_squared_error: 19.3164 - val_loss: 12.8275 - val_mean_squared_error: 12.8275\n",
      "Epoch 34/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 18.7415 - mean_squared_error: 18.7415 - val_loss: 12.9582 - val_mean_squared_error: 12.9582\n",
      "Epoch 35/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 18.9367 - mean_squared_error: 18.9367 - val_loss: 10.5768 - val_mean_squared_error: 10.5768\n",
      "Epoch 36/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 18.8059 - mean_squared_error: 18.8059 - val_loss: 13.3029 - val_mean_squared_error: 13.3029\n",
      "Epoch 37/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 18.3834 - mean_squared_error: 18.3834 - val_loss: 10.3666 - val_mean_squared_error: 10.3666\n",
      "Epoch 38/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 19.5124 - mean_squared_error: 19.5124 - val_loss: 11.1210 - val_mean_squared_error: 11.1210\n",
      "Epoch 39/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 18.6683 - mean_squared_error: 18.6683 - val_loss: 10.4818 - val_mean_squared_error: 10.4818\n",
      "Epoch 40/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 18.4778 - mean_squared_error: 18.4778 - val_loss: 12.8944 - val_mean_squared_error: 12.8944\n",
      "Epoch 41/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 18.1234 - mean_squared_error: 18.1234 - val_loss: 11.6258 - val_mean_squared_error: 11.6258\n",
      "Epoch 42/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 18.3922 - mean_squared_error: 18.3922 - val_loss: 9.9537 - val_mean_squared_error: 9.9537\n",
      "Epoch 43/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 19.3490 - mean_squared_error: 19.3490 - val_loss: 11.2218 - val_mean_squared_error: 11.2218\n",
      "Epoch 44/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 17.8657 - mean_squared_error: 17.8657 - val_loss: 13.1861 - val_mean_squared_error: 13.1861\n",
      "Epoch 45/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 18.3670 - mean_squared_error: 18.3670 - val_loss: 10.0654 - val_mean_squared_error: 10.0654\n",
      "Epoch 46/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 18.3433 - mean_squared_error: 18.3433 - val_loss: 10.6859 - val_mean_squared_error: 10.6859\n",
      "Epoch 47/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 18.8143 - mean_squared_error: 18.8143 - val_loss: 10.9340 - val_mean_squared_error: 10.9340\n",
      "Epoch 48/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 18.3762 - mean_squared_error: 18.3762 - val_loss: 11.3906 - val_mean_squared_error: 11.3906\n",
      "Epoch 49/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 18.4600 - mean_squared_error: 18.4600 - val_loss: 11.6941 - val_mean_squared_error: 11.6941\n",
      "Epoch 50/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 17.8139 - mean_squared_error: 17.8139 - val_loss: 11.9492 - val_mean_squared_error: 11.9492\n",
      "Epoch 51/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 17.7336 - mean_squared_error: 17.7336 - val_loss: 14.3502 - val_mean_squared_error: 14.3502\n",
      "Epoch 52/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 17.6904 - mean_squared_error: 17.6904 - val_loss: 10.0897 - val_mean_squared_error: 10.0897\n",
      "Epoch 53/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 17.7025 - mean_squared_error: 17.7025 - val_loss: 10.3972 - val_mean_squared_error: 10.3972\n",
      "Epoch 54/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 18.1126 - mean_squared_error: 18.1126 - val_loss: 11.8837 - val_mean_squared_error: 11.8837\n",
      "Epoch 55/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 18.0137 - mean_squared_error: 18.0137 - val_loss: 11.2158 - val_mean_squared_error: 11.2158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 17.6904 - mean_squared_error: 17.6904 - val_loss: 10.3918 - val_mean_squared_error: 10.3918\n",
      "Epoch 57/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 17.7413 - mean_squared_error: 17.7413 - val_loss: 10.5143 - val_mean_squared_error: 10.5143\n",
      "Epoch 58/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 17.9191 - mean_squared_error: 17.9191 - val_loss: 9.3911 - val_mean_squared_error: 9.3911\n",
      "Epoch 59/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 17.3133 - mean_squared_error: 17.3133 - val_loss: 16.0972 - val_mean_squared_error: 16.0972\n",
      "Epoch 60/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 17.6327 - mean_squared_error: 17.6327 - val_loss: 9.6229 - val_mean_squared_error: 9.6229\n",
      "Epoch 61/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 17.3062 - mean_squared_error: 17.3062 - val_loss: 12.3377 - val_mean_squared_error: 12.3377\n",
      "Epoch 62/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 17.2588 - mean_squared_error: 17.2588 - val_loss: 11.5008 - val_mean_squared_error: 11.5008\n",
      "Epoch 63/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 16.2806 - mean_squared_error: 16.2806 - val_loss: 11.0617 - val_mean_squared_error: 11.0617\n",
      "Epoch 64/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 17.0382 - mean_squared_error: 17.0382 - val_loss: 9.5477 - val_mean_squared_error: 9.5477\n",
      "Epoch 65/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 17.1800 - mean_squared_error: 17.1800 - val_loss: 9.0853 - val_mean_squared_error: 9.0853\n",
      "Epoch 66/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 17.1823 - mean_squared_error: 17.1823 - val_loss: 10.6672 - val_mean_squared_error: 10.6672\n",
      "Epoch 67/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 17.3708 - mean_squared_error: 17.3708 - val_loss: 9.3885 - val_mean_squared_error: 9.3885\n",
      "Epoch 68/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 16.9397 - mean_squared_error: 16.9397 - val_loss: 9.8503 - val_mean_squared_error: 9.8503\n",
      "Epoch 69/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 16.9051 - mean_squared_error: 16.9052 - val_loss: 10.3555 - val_mean_squared_error: 10.3555\n",
      "Epoch 70/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 17.0257 - mean_squared_error: 17.0257 - val_loss: 12.8745 - val_mean_squared_error: 12.8745\n",
      "Epoch 71/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 16.7400 - mean_squared_error: 16.7400 - val_loss: 12.7684 - val_mean_squared_error: 12.7684\n",
      "Epoch 72/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 16.5361 - mean_squared_error: 16.5361 - val_loss: 8.8203 - val_mean_squared_error: 8.8203\n",
      "Epoch 73/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 17.6528 - mean_squared_error: 17.6528 - val_loss: 9.0479 - val_mean_squared_error: 9.0479\n",
      "Epoch 74/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 16.9044 - mean_squared_error: 16.9044 - val_loss: 11.7392 - val_mean_squared_error: 11.7392\n",
      "Epoch 75/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 16.0736 - mean_squared_error: 16.0736 - val_loss: 10.5519 - val_mean_squared_error: 10.5519\n",
      "Epoch 76/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 15.7305 - mean_squared_error: 15.7305 - val_loss: 10.6954 - val_mean_squared_error: 10.6954\n",
      "Epoch 77/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 16.2831 - mean_squared_error: 16.2831 - val_loss: 8.6059 - val_mean_squared_error: 8.6059\n",
      "Epoch 78/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 16.2842 - mean_squared_error: 16.2842 - val_loss: 8.8580 - val_mean_squared_error: 8.8580\n",
      "Epoch 79/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 16.4197 - mean_squared_error: 16.4197 - val_loss: 8.7931 - val_mean_squared_error: 8.7931\n",
      "Epoch 80/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 16.1480 - mean_squared_error: 16.1480 - val_loss: 8.7071 - val_mean_squared_error: 8.7071\n",
      "Epoch 81/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 16.2869 - mean_squared_error: 16.2869 - val_loss: 13.6910 - val_mean_squared_error: 13.6910\n",
      "Epoch 82/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 15.4887 - mean_squared_error: 15.4887 - val_loss: 11.7012 - val_mean_squared_error: 11.7012\n",
      "Epoch 83/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 16.1273 - mean_squared_error: 16.1273 - val_loss: 12.2764 - val_mean_squared_error: 12.2764\n",
      "Epoch 84/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 15.6344 - mean_squared_error: 15.6344 - val_loss: 12.5747 - val_mean_squared_error: 12.5747\n",
      "Epoch 85/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 15.4200 - mean_squared_error: 15.4200 - val_loss: 8.7685 - val_mean_squared_error: 8.7685\n",
      "Epoch 86/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 14.9502 - mean_squared_error: 14.9502 - val_loss: 9.6273 - val_mean_squared_error: 9.6273\n",
      "Epoch 87/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 15.7546 - mean_squared_error: 15.7546 - val_loss: 13.4608 - val_mean_squared_error: 13.4608\n",
      "Epoch 88/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 15.5852 - mean_squared_error: 15.5852 - val_loss: 12.4221 - val_mean_squared_error: 12.4221\n",
      "Epoch 89/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 15.8072 - mean_squared_error: 15.8072 - val_loss: 10.0949 - val_mean_squared_error: 10.0949\n",
      "Epoch 90/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 15.4354 - mean_squared_error: 15.4354 - val_loss: 9.8101 - val_mean_squared_error: 9.8102\n",
      "Epoch 91/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 15.5464 - mean_squared_error: 15.5464 - val_loss: 9.4537 - val_mean_squared_error: 9.4537\n",
      "Epoch 92/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 14.9450 - mean_squared_error: 14.9450 - val_loss: 13.3149 - val_mean_squared_error: 13.3149\n",
      "Epoch 93/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 14.9721 - mean_squared_error: 14.9721 - val_loss: 11.2710 - val_mean_squared_error: 11.2710\n",
      "Epoch 94/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 15.3580 - mean_squared_error: 15.3580 - val_loss: 8.3116 - val_mean_squared_error: 8.3116\n",
      "Epoch 95/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 15.3070 - mean_squared_error: 15.3070 - val_loss: 11.3280 - val_mean_squared_error: 11.3280\n",
      "Epoch 96/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 15.2825 - mean_squared_error: 15.2825 - val_loss: 8.4903 - val_mean_squared_error: 8.4903\n",
      "Epoch 97/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 14.7195 - mean_squared_error: 14.7195 - val_loss: 9.7893 - val_mean_squared_error: 9.7893\n",
      "Epoch 98/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 14.9212 - mean_squared_error: 14.9212 - val_loss: 11.2706 - val_mean_squared_error: 11.2706\n",
      "Epoch 99/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 14.8264 - mean_squared_error: 14.8265 - val_loss: 15.2572 - val_mean_squared_error: 15.2572\n",
      "Epoch 100/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 15.4823 - mean_squared_error: 15.4823 - val_loss: 11.9742 - val_mean_squared_error: 11.9742\n",
      "Epoch 101/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 14.6821 - mean_squared_error: 14.6821 - val_loss: 13.7804 - val_mean_squared_error: 13.7804\n",
      "Epoch 102/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 14.9498 - mean_squared_error: 14.9498 - val_loss: 12.1793 - val_mean_squared_error: 12.1793\n",
      "Epoch 103/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 14.8507 - mean_squared_error: 14.8507 - val_loss: 12.3490 - val_mean_squared_error: 12.3490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 15.0813 - mean_squared_error: 15.0813 - val_loss: 9.3593 - val_mean_squared_error: 9.3593\n",
      "Epoch 105/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 14.9172 - mean_squared_error: 14.9172 - val_loss: 9.5766 - val_mean_squared_error: 9.5766\n",
      "Epoch 106/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 15.2143 - mean_squared_error: 15.2143 - val_loss: 9.5227 - val_mean_squared_error: 9.5227\n",
      "Epoch 107/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 14.0636 - mean_squared_error: 14.0636 - val_loss: 16.3083 - val_mean_squared_error: 16.3083\n",
      "Epoch 108/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 14.6634 - mean_squared_error: 14.6634 - val_loss: 11.3650 - val_mean_squared_error: 11.3650\n",
      "Epoch 109/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 15.4797 - mean_squared_error: 15.4797 - val_loss: 12.4420 - val_mean_squared_error: 12.4420\n",
      "Epoch 110/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 14.2475 - mean_squared_error: 14.2475 - val_loss: 13.2279 - val_mean_squared_error: 13.2279\n",
      "Epoch 111/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 14.7108 - mean_squared_error: 14.7108 - val_loss: 11.6141 - val_mean_squared_error: 11.6141\n",
      "Epoch 112/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 14.5557 - mean_squared_error: 14.5557 - val_loss: 20.2479 - val_mean_squared_error: 20.2479\n",
      "Epoch 113/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 13.7780 - mean_squared_error: 13.7780 - val_loss: 17.0587 - val_mean_squared_error: 17.0587\n",
      "Epoch 114/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 14.4488 - mean_squared_error: 14.4488 - val_loss: 18.0858 - val_mean_squared_error: 18.0858\n",
      "Epoch 115/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 13.9144 - mean_squared_error: 13.9144 - val_loss: 11.2866 - val_mean_squared_error: 11.2866\n",
      "Epoch 116/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 15.0621 - mean_squared_error: 15.0621 - val_loss: 9.6569 - val_mean_squared_error: 9.6569\n",
      "Epoch 117/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 14.1767 - mean_squared_error: 14.1767 - val_loss: 15.2673 - val_mean_squared_error: 15.2673\n",
      "Epoch 118/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 13.7666 - mean_squared_error: 13.7666 - val_loss: 12.6654 - val_mean_squared_error: 12.6654\n",
      "Epoch 119/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 13.7823 - mean_squared_error: 13.7823 - val_loss: 13.5505 - val_mean_squared_error: 13.5505\n",
      "Epoch 120/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 13.4019 - mean_squared_error: 13.4019 - val_loss: 15.6821 - val_mean_squared_error: 15.6821\n",
      "Epoch 121/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 13.5737 - mean_squared_error: 13.5737 - val_loss: 16.0364 - val_mean_squared_error: 16.0364\n",
      "Epoch 122/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 13.9891 - mean_squared_error: 13.9891 - val_loss: 23.9011 - val_mean_squared_error: 23.9011\n",
      "Epoch 123/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 13.1912 - mean_squared_error: 13.1912 - val_loss: 24.1549 - val_mean_squared_error: 24.1549\n",
      "Epoch 124/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 13.8357 - mean_squared_error: 13.8357 - val_loss: 13.4430 - val_mean_squared_error: 13.4430\n",
      "Epoch 125/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 13.2934 - mean_squared_error: 13.2934 - val_loss: 13.3540 - val_mean_squared_error: 13.3540\n",
      "Epoch 126/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 13.5458 - mean_squared_error: 13.5458 - val_loss: 20.7713 - val_mean_squared_error: 20.7713\n",
      "Epoch 127/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 13.3614 - mean_squared_error: 13.3614 - val_loss: 14.0448 - val_mean_squared_error: 14.0448\n",
      "Epoch 128/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 13.3111 - mean_squared_error: 13.3111 - val_loss: 27.8140 - val_mean_squared_error: 27.8140\n",
      "Epoch 129/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 13.3981 - mean_squared_error: 13.3981 - val_loss: 32.2817 - val_mean_squared_error: 32.2817\n",
      "Epoch 130/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 13.6271 - mean_squared_error: 13.6271 - val_loss: 29.3544 - val_mean_squared_error: 29.3544\n",
      "Epoch 131/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 13.8360 - mean_squared_error: 13.8360 - val_loss: 20.6518 - val_mean_squared_error: 20.6518\n",
      "Epoch 132/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 13.0165 - mean_squared_error: 13.0165 - val_loss: 20.8628 - val_mean_squared_error: 20.8628\n",
      "Epoch 133/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 12.4114 - mean_squared_error: 12.4114 - val_loss: 21.7661 - val_mean_squared_error: 21.7661\n",
      "Epoch 134/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 12.5682 - mean_squared_error: 12.5682 - val_loss: 25.9427 - val_mean_squared_error: 25.9427\n",
      "Epoch 135/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 12.3946 - mean_squared_error: 12.3946 - val_loss: 33.4246 - val_mean_squared_error: 33.4246\n",
      "Epoch 136/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 12.8461 - mean_squared_error: 12.8461 - val_loss: 29.0600 - val_mean_squared_error: 29.0600\n",
      "Epoch 137/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 12.0028 - mean_squared_error: 12.0028 - val_loss: 25.7247 - val_mean_squared_error: 25.7247\n",
      "Epoch 138/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 12.5940 - mean_squared_error: 12.5940 - val_loss: 33.7813 - val_mean_squared_error: 33.7813\n",
      "Epoch 139/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 12.0005 - mean_squared_error: 12.0005 - val_loss: 41.1469 - val_mean_squared_error: 41.1469\n",
      "Epoch 140/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 11.7422 - mean_squared_error: 11.7422 - val_loss: 32.6786 - val_mean_squared_error: 32.6786\n",
      "Epoch 141/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 12.0007 - mean_squared_error: 12.0007 - val_loss: 45.9116 - val_mean_squared_error: 45.9116\n",
      "Epoch 142/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 11.6877 - mean_squared_error: 11.6877 - val_loss: 41.8634 - val_mean_squared_error: 41.8634\n",
      "Epoch 143/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 11.2464 - mean_squared_error: 11.2464 - val_loss: 51.4301 - val_mean_squared_error: 51.4301\n",
      "Epoch 144/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 11.3795 - mean_squared_error: 11.3795 - val_loss: 88.1769 - val_mean_squared_error: 88.1769\n",
      "Epoch 145/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 11.6714 - mean_squared_error: 11.6714 - val_loss: 74.2913 - val_mean_squared_error: 74.2914\n",
      "Epoch 146/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.8152 - mean_squared_error: 10.8152 - val_loss: 57.6760 - val_mean_squared_error: 57.6760\n",
      "Epoch 147/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.7796 - mean_squared_error: 10.7796 - val_loss: 91.0238 - val_mean_squared_error: 91.0238\n",
      "Epoch 148/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.4510 - mean_squared_error: 10.4510 - val_loss: 77.3664 - val_mean_squared_error: 77.3664\n",
      "Epoch 149/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.6656 - mean_squared_error: 9.6656 - val_loss: 89.9455 - val_mean_squared_error: 89.9455\n",
      "Epoch 150/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.9204 - mean_squared_error: 9.9204 - val_loss: 92.4167 - val_mean_squared_error: 92.4167\n",
      "Epoch 151/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 9.0957 - mean_squared_error: 9.0957 - val_loss: 137.2391 - val_mean_squared_error: 137.2391\n",
      "Epoch 152/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 9.6209 - mean_squared_error: 9.6209 - val_loss: 82.2614 - val_mean_squared_error: 82.2614\n",
      "Epoch 153/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.0839 - mean_squared_error: 9.0839 - val_loss: 120.2753 - val_mean_squared_error: 120.2753\n",
      "Epoch 154/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 8.2273 - mean_squared_error: 8.2273 - val_loss: 119.0812 - val_mean_squared_error: 119.0812\n",
      "Epoch 155/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 8.1268 - mean_squared_error: 8.1268 - val_loss: 103.3669 - val_mean_squared_error: 103.3669\n",
      "Epoch 156/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 8.1961 - mean_squared_error: 8.1961 - val_loss: 123.2084 - val_mean_squared_error: 123.2084\n",
      "Epoch 157/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 8.0368 - mean_squared_error: 8.0368 - val_loss: 120.7640 - val_mean_squared_error: 120.7640\n",
      "Epoch 158/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 7.5707 - mean_squared_error: 7.5707 - val_loss: 147.1703 - val_mean_squared_error: 147.1703\n",
      "Epoch 159/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 7.8779 - mean_squared_error: 7.8779 - val_loss: 149.1782 - val_mean_squared_error: 149.1782\n",
      "Epoch 160/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 7.2632 - mean_squared_error: 7.2632 - val_loss: 148.0111 - val_mean_squared_error: 148.0111\n",
      "Epoch 161/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 7.2185 - mean_squared_error: 7.2185 - val_loss: 114.5997 - val_mean_squared_error: 114.5997\n",
      "Epoch 162/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 7.3200 - mean_squared_error: 7.3200 - val_loss: 146.0075 - val_mean_squared_error: 146.0075\n",
      "Epoch 163/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 6.7939 - mean_squared_error: 6.7939 - val_loss: 141.6410 - val_mean_squared_error: 141.6410\n",
      "Epoch 164/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 6.5898 - mean_squared_error: 6.5898 - val_loss: 142.4616 - val_mean_squared_error: 142.4616\n",
      "Epoch 165/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.4582 - mean_squared_error: 6.4582 - val_loss: 133.5611 - val_mean_squared_error: 133.5610\n",
      "Epoch 166/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.2748 - mean_squared_error: 6.2748 - val_loss: 146.4280 - val_mean_squared_error: 146.4280\n",
      "Epoch 167/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.3291 - mean_squared_error: 6.3291 - val_loss: 171.6629 - val_mean_squared_error: 171.6629\n",
      "Epoch 168/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.2114 - mean_squared_error: 6.2114 - val_loss: 126.7071 - val_mean_squared_error: 126.7071\n",
      "Epoch 169/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.3053 - mean_squared_error: 6.3053 - val_loss: 134.6917 - val_mean_squared_error: 134.6917\n",
      "Epoch 170/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.8821 - mean_squared_error: 5.8821 - val_loss: 143.8568 - val_mean_squared_error: 143.8568\n",
      "Epoch 171/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 6.0094 - mean_squared_error: 6.0094 - val_loss: 145.2077 - val_mean_squared_error: 145.2077\n",
      "Epoch 172/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 6.2354 - mean_squared_error: 6.2354 - val_loss: 150.1117 - val_mean_squared_error: 150.1117\n",
      "Epoch 173/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.8292 - mean_squared_error: 5.8292 - val_loss: 150.0661 - val_mean_squared_error: 150.0661\n",
      "Epoch 174/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.5493 - mean_squared_error: 5.5493 - val_loss: 141.5231 - val_mean_squared_error: 141.5231\n",
      "Epoch 175/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.4634 - mean_squared_error: 5.4634 - val_loss: 157.6386 - val_mean_squared_error: 157.6386\n",
      "Epoch 176/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.2550 - mean_squared_error: 5.2550 - val_loss: 169.5637 - val_mean_squared_error: 169.5637\n",
      "Epoch 177/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.1900 - mean_squared_error: 5.1900 - val_loss: 161.3957 - val_mean_squared_error: 161.3957\n",
      "Epoch 178/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.2150 - mean_squared_error: 5.2150 - val_loss: 150.3644 - val_mean_squared_error: 150.3644\n",
      "Epoch 179/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 5.3736 - mean_squared_error: 5.3736 - val_loss: 163.9146 - val_mean_squared_error: 163.9146\n",
      "Epoch 180/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.9876 - mean_squared_error: 4.9876 - val_loss: 155.8453 - val_mean_squared_error: 155.8453\n",
      "Epoch 181/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.8849 - mean_squared_error: 4.8849 - val_loss: 161.3191 - val_mean_squared_error: 161.3191\n",
      "Epoch 182/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.9064 - mean_squared_error: 4.9064 - val_loss: 171.9450 - val_mean_squared_error: 171.9449\n",
      "Epoch 183/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.7864 - mean_squared_error: 4.7864 - val_loss: 170.5997 - val_mean_squared_error: 170.5996\n",
      "Epoch 184/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.8463 - mean_squared_error: 4.8463 - val_loss: 183.3167 - val_mean_squared_error: 183.3167\n",
      "Epoch 185/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.7433 - mean_squared_error: 4.7433 - val_loss: 181.2130 - val_mean_squared_error: 181.2130\n",
      "Epoch 186/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.8405 - mean_squared_error: 4.8405 - val_loss: 187.2496 - val_mean_squared_error: 187.2496\n",
      "Epoch 187/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.4802 - mean_squared_error: 4.4802 - val_loss: 164.8533 - val_mean_squared_error: 164.8533\n",
      "Epoch 188/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 4.4740 - mean_squared_error: 4.4740 - val_loss: 172.5605 - val_mean_squared_error: 172.5605\n",
      "Epoch 189/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.6126 - mean_squared_error: 4.6126 - val_loss: 167.1144 - val_mean_squared_error: 167.1144\n",
      "Epoch 190/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.6488 - mean_squared_error: 4.6488 - val_loss: 194.5325 - val_mean_squared_error: 194.5325\n",
      "Epoch 191/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.5827 - mean_squared_error: 4.5827 - val_loss: 172.1188 - val_mean_squared_error: 172.1188\n",
      "Epoch 192/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 4.2932 - mean_squared_error: 4.2932 - val_loss: 180.4253 - val_mean_squared_error: 180.4253\n",
      "Epoch 193/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 4.1750 - mean_squared_error: 4.1750 - val_loss: 195.4188 - val_mean_squared_error: 195.4187\n",
      "Epoch 194/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 4.3711 - mean_squared_error: 4.3711 - val_loss: 193.2594 - val_mean_squared_error: 193.2593\n",
      "==================================================\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_48 (Conv2D)           (None, 94, 94, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 47, 47, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 47, 47, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 46, 46, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 22, 22, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 500)               3872500   \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 30)                15030     \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 30)                0         \n",
      "=================================================================\n",
      "Total params: 4,148,526\n",
      "Trainable params: 4,148,526\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1819 samples, validate on 321 samples\n",
      "Epoch 1/200\n",
      "1819/1819 [==============================] - 7s 4ms/sample - loss: 1234.3343 - mean_squared_error: 1234.3341 - val_loss: 99.8063 - val_mean_squared_error: 99.8063\n",
      "Epoch 2/200\n",
      "1819/1819 [==============================] - 7s 4ms/sample - loss: 64.1862 - mean_squared_error: 64.1862 - val_loss: 39.5086 - val_mean_squared_error: 39.5086\n",
      "Epoch 3/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 52.2504 - mean_squared_error: 52.2504 - val_loss: 30.9345 - val_mean_squared_error: 30.9345\n",
      "Epoch 4/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 52.3424 - mean_squared_error: 52.3424 - val_loss: 32.5343 - val_mean_squared_error: 32.5343\n",
      "Epoch 5/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 46.0698 - mean_squared_error: 46.0698 - val_loss: 19.0579 - val_mean_squared_error: 19.0579\n",
      "Epoch 6/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 39.8059 - mean_squared_error: 39.8059 - val_loss: 47.0223 - val_mean_squared_error: 47.0223\n",
      "Epoch 7/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 38.6247 - mean_squared_error: 38.6247 - val_loss: 42.9404 - val_mean_squared_error: 42.9404\n",
      "Epoch 8/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 32.7457 - mean_squared_error: 32.7457 - val_loss: 55.6067 - val_mean_squared_error: 55.6067\n",
      "Epoch 9/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 28.0735 - mean_squared_error: 28.0735 - val_loss: 59.1116 - val_mean_squared_error: 59.1116\n",
      "Epoch 10/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 24.6283 - mean_squared_error: 24.6283 - val_loss: 88.5378 - val_mean_squared_error: 88.5378\n",
      "Epoch 11/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 21.6170 - mean_squared_error: 21.6170 - val_loss: 90.0335 - val_mean_squared_error: 90.0335\n",
      "Epoch 12/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 19.3201 - mean_squared_error: 19.3201 - val_loss: 96.5640 - val_mean_squared_error: 96.5640\n",
      "Epoch 13/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 17.7420 - mean_squared_error: 17.7420 - val_loss: 98.6090 - val_mean_squared_error: 98.6090\n",
      "Epoch 14/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 15.7024 - mean_squared_error: 15.7024 - val_loss: 117.3599 - val_mean_squared_error: 117.3599\n",
      "Epoch 15/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 16.3360 - mean_squared_error: 16.3360 - val_loss: 101.3401 - val_mean_squared_error: 101.3401\n",
      "Epoch 16/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 14.0337 - mean_squared_error: 14.0337 - val_loss: 115.9136 - val_mean_squared_error: 115.9136\n",
      "Epoch 17/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 13.8429 - mean_squared_error: 13.8429 - val_loss: 107.4595 - val_mean_squared_error: 107.4595\n",
      "Epoch 18/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 13.3969 - mean_squared_error: 13.3969 - val_loss: 111.1149 - val_mean_squared_error: 111.1149\n",
      "Epoch 19/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.6959 - mean_squared_error: 12.6959 - val_loss: 118.9022 - val_mean_squared_error: 118.9022\n",
      "Epoch 20/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 13.2655 - mean_squared_error: 13.2655 - val_loss: 126.9958 - val_mean_squared_error: 126.9958\n",
      "Epoch 21/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 13.2802 - mean_squared_error: 13.2802 - val_loss: 121.2438 - val_mean_squared_error: 121.2438\n",
      "Epoch 22/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.7904 - mean_squared_error: 12.7904 - val_loss: 116.3412 - val_mean_squared_error: 116.3412\n",
      "Epoch 23/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.7879 - mean_squared_error: 12.7879 - val_loss: 102.6565 - val_mean_squared_error: 102.6565\n",
      "Epoch 24/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.6336 - mean_squared_error: 12.6336 - val_loss: 116.2033 - val_mean_squared_error: 116.2033\n",
      "Epoch 25/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.4693 - mean_squared_error: 12.4693 - val_loss: 116.8562 - val_mean_squared_error: 116.8562\n",
      "Epoch 26/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.1299 - mean_squared_error: 12.1299 - val_loss: 116.3869 - val_mean_squared_error: 116.3869\n",
      "Epoch 27/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.3820 - mean_squared_error: 12.3820 - val_loss: 109.6354 - val_mean_squared_error: 109.6354\n",
      "Epoch 28/200\n",
      "1819/1819 [==============================] - 6s 4ms/sample - loss: 12.0861 - mean_squared_error: 12.0861 - val_loss: 112.2501 - val_mean_squared_error: 112.2501\n",
      "Epoch 29/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.1710 - mean_squared_error: 12.1710 - val_loss: 118.2779 - val_mean_squared_error: 118.2779\n",
      "Epoch 30/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.2368 - mean_squared_error: 12.2368 - val_loss: 115.8051 - val_mean_squared_error: 115.8051\n",
      "Epoch 31/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.6522 - mean_squared_error: 11.6522 - val_loss: 108.1648 - val_mean_squared_error: 108.1648\n",
      "Epoch 32/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.7944 - mean_squared_error: 11.7944 - val_loss: 120.4517 - val_mean_squared_error: 120.4517\n",
      "Epoch 33/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 11.9920 - mean_squared_error: 11.9920 - val_loss: 104.1618 - val_mean_squared_error: 104.1618\n",
      "Epoch 34/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.6616 - mean_squared_error: 11.6616 - val_loss: 99.0910 - val_mean_squared_error: 99.0910\n",
      "Epoch 35/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.7146 - mean_squared_error: 11.7146 - val_loss: 101.9286 - val_mean_squared_error: 101.9286\n",
      "Epoch 36/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.4132 - mean_squared_error: 11.4132 - val_loss: 122.4034 - val_mean_squared_error: 122.4034\n",
      "Epoch 37/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.9632 - mean_squared_error: 11.9632 - val_loss: 96.4452 - val_mean_squared_error: 96.4452\n",
      "Epoch 38/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.5545 - mean_squared_error: 11.5545 - val_loss: 92.6983 - val_mean_squared_error: 92.6983\n",
      "Epoch 39/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.6982 - mean_squared_error: 11.6982 - val_loss: 115.5452 - val_mean_squared_error: 115.5452\n",
      "Epoch 40/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.7313 - mean_squared_error: 11.7313 - val_loss: 114.3479 - val_mean_squared_error: 114.3479\n",
      "Epoch 41/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.9598 - mean_squared_error: 11.9598 - val_loss: 100.4618 - val_mean_squared_error: 100.4618\n",
      "Epoch 42/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.6133 - mean_squared_error: 11.6133 - val_loss: 108.7256 - val_mean_squared_error: 108.7256\n",
      "Epoch 43/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.3388 - mean_squared_error: 11.3388 - val_loss: 103.2622 - val_mean_squared_error: 103.2622\n",
      "Epoch 44/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.2699 - mean_squared_error: 11.2699 - val_loss: 97.7309 - val_mean_squared_error: 97.7309\n",
      "Epoch 45/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.3688 - mean_squared_error: 11.3688 - val_loss: 94.5363 - val_mean_squared_error: 94.5363\n",
      "Epoch 46/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.2775 - mean_squared_error: 11.2775 - val_loss: 111.4872 - val_mean_squared_error: 111.4872\n",
      "Epoch 47/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.3522 - mean_squared_error: 11.3522 - val_loss: 85.3372 - val_mean_squared_error: 85.3372\n",
      "Epoch 48/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.1395 - mean_squared_error: 11.1395 - val_loss: 103.3128 - val_mean_squared_error: 103.3128\n",
      "Epoch 49/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.1041 - mean_squared_error: 11.1041 - val_loss: 98.2215 - val_mean_squared_error: 98.2215\n",
      "Epoch 50/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.3228 - mean_squared_error: 11.3228 - val_loss: 104.9566 - val_mean_squared_error: 104.9566\n",
      "Epoch 51/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.9725 - mean_squared_error: 10.9725 - val_loss: 99.8255 - val_mean_squared_error: 99.8255\n",
      "Epoch 52/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.2079 - mean_squared_error: 11.2079 - val_loss: 102.1517 - val_mean_squared_error: 102.1517\n",
      "Epoch 53/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.1021 - mean_squared_error: 11.1021 - val_loss: 99.9542 - val_mean_squared_error: 99.9542\n",
      "Epoch 54/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.1004 - mean_squared_error: 11.1004 - val_loss: 94.8551 - val_mean_squared_error: 94.8551\n",
      "Epoch 55/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.0084 - mean_squared_error: 11.0084 - val_loss: 93.7406 - val_mean_squared_error: 93.7406\n",
      "Epoch 56/200\n",
      "1819/1819 [==============================] - 7s 4ms/sample - loss: 11.1191 - mean_squared_error: 11.1191 - val_loss: 102.6296 - val_mean_squared_error: 102.6296\n",
      "Epoch 57/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.9751 - mean_squared_error: 10.9751 - val_loss: 112.4722 - val_mean_squared_error: 112.4722\n",
      "Epoch 58/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.2463 - mean_squared_error: 11.2463 - val_loss: 103.3901 - val_mean_squared_error: 103.3901\n",
      "Epoch 59/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.0844 - mean_squared_error: 11.0844 - val_loss: 102.1533 - val_mean_squared_error: 102.1533\n",
      "Epoch 60/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.2948 - mean_squared_error: 11.2948 - val_loss: 110.9547 - val_mean_squared_error: 110.9547\n",
      "Epoch 61/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.1365 - mean_squared_error: 11.1365 - val_loss: 107.7755 - val_mean_squared_error: 107.7755\n",
      "Epoch 62/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.8466 - mean_squared_error: 10.8466 - val_loss: 105.2583 - val_mean_squared_error: 105.2583\n",
      "Epoch 63/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.9545 - mean_squared_error: 10.9545 - val_loss: 90.5464 - val_mean_squared_error: 90.5464\n",
      "Epoch 64/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.2103 - mean_squared_error: 11.2103 - val_loss: 93.5573 - val_mean_squared_error: 93.5573\n",
      "Epoch 65/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.9213 - mean_squared_error: 10.9213 - val_loss: 103.5173 - val_mean_squared_error: 103.5173\n",
      "Epoch 66/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.8297 - mean_squared_error: 10.8297 - val_loss: 100.1088 - val_mean_squared_error: 100.1088\n",
      "Epoch 67/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.9600 - mean_squared_error: 10.9600 - val_loss: 94.8884 - val_mean_squared_error: 94.8885\n",
      "Epoch 68/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.1044 - mean_squared_error: 11.1044 - val_loss: 94.9294 - val_mean_squared_error: 94.9294\n",
      "Epoch 69/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.9470 - mean_squared_error: 10.9470 - val_loss: 97.2788 - val_mean_squared_error: 97.2788\n",
      "Epoch 70/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 11.0290 - mean_squared_error: 11.0290 - val_loss: 101.2412 - val_mean_squared_error: 101.2412\n",
      "Epoch 71/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.8536 - mean_squared_error: 10.8536 - val_loss: 101.4665 - val_mean_squared_error: 101.4665\n",
      "Epoch 72/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 11.0122 - mean_squared_error: 11.0122 - val_loss: 95.6521 - val_mean_squared_error: 95.6521\n",
      "Epoch 73/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.7786 - mean_squared_error: 10.7786 - val_loss: 104.4734 - val_mean_squared_error: 104.4734\n",
      "Epoch 74/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.7854 - mean_squared_error: 10.7854 - val_loss: 89.3424 - val_mean_squared_error: 89.3424\n",
      "Epoch 75/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 11.0745 - mean_squared_error: 11.0745 - val_loss: 103.5841 - val_mean_squared_error: 103.5841\n",
      "Epoch 76/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.9605 - mean_squared_error: 10.9605 - val_loss: 79.2635 - val_mean_squared_error: 79.2635\n",
      "Epoch 77/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.8557 - mean_squared_error: 10.8557 - val_loss: 113.8566 - val_mean_squared_error: 113.8566\n",
      "Epoch 78/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.8620 - mean_squared_error: 10.8620 - val_loss: 114.3336 - val_mean_squared_error: 114.3336\n",
      "Epoch 79/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.6504 - mean_squared_error: 10.6504 - val_loss: 99.6567 - val_mean_squared_error: 99.6567\n",
      "Epoch 80/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.6141 - mean_squared_error: 10.6141 - val_loss: 89.7864 - val_mean_squared_error: 89.7864\n",
      "Epoch 81/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.6300 - mean_squared_error: 10.6300 - val_loss: 97.2265 - val_mean_squared_error: 97.2265\n",
      "Epoch 82/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.8357 - mean_squared_error: 10.8357 - val_loss: 101.5411 - val_mean_squared_error: 101.5411\n",
      "Epoch 83/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.7005 - mean_squared_error: 10.7005 - val_loss: 92.3816 - val_mean_squared_error: 92.3816\n",
      "Epoch 84/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.7695 - mean_squared_error: 10.7695 - val_loss: 104.6073 - val_mean_squared_error: 104.6073\n",
      "Epoch 85/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.7552 - mean_squared_error: 10.7552 - val_loss: 88.4319 - val_mean_squared_error: 88.4319\n",
      "Epoch 86/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.5159 - mean_squared_error: 10.5159 - val_loss: 97.5333 - val_mean_squared_error: 97.5333\n",
      "Epoch 87/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.5848 - mean_squared_error: 10.5848 - val_loss: 100.3228 - val_mean_squared_error: 100.3228\n",
      "Epoch 88/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.7320 - mean_squared_error: 10.7320 - val_loss: 86.7268 - val_mean_squared_error: 86.7268\n",
      "Epoch 89/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.5979 - mean_squared_error: 10.5979 - val_loss: 104.2323 - val_mean_squared_error: 104.2323\n",
      "Epoch 90/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.6701 - mean_squared_error: 10.6701 - val_loss: 92.6250 - val_mean_squared_error: 92.6250\n",
      "Epoch 91/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.5316 - mean_squared_error: 10.5316 - val_loss: 91.6540 - val_mean_squared_error: 91.6540\n",
      "Epoch 92/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.4745 - mean_squared_error: 10.4745 - val_loss: 89.0209 - val_mean_squared_error: 89.0209\n",
      "Epoch 93/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.6450 - mean_squared_error: 10.6450 - val_loss: 92.8753 - val_mean_squared_error: 92.8753\n",
      "Epoch 94/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.0947 - mean_squared_error: 10.0947 - val_loss: 97.4413 - val_mean_squared_error: 97.4412\n",
      "Epoch 95/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.2778 - mean_squared_error: 10.2778 - val_loss: 84.6906 - val_mean_squared_error: 84.6906\n",
      "Epoch 96/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.1192 - mean_squared_error: 10.1192 - val_loss: 91.1931 - val_mean_squared_error: 91.1931\n",
      "Epoch 97/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.0435 - mean_squared_error: 10.0435 - val_loss: 81.5423 - val_mean_squared_error: 81.5423\n",
      "Epoch 98/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.9830 - mean_squared_error: 9.9830 - val_loss: 74.9105 - val_mean_squared_error: 74.9105\n",
      "Epoch 99/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.1402 - mean_squared_error: 10.1402 - val_loss: 81.5095 - val_mean_squared_error: 81.5095\n",
      "Epoch 100/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.8297 - mean_squared_error: 9.8297 - val_loss: 92.3764 - val_mean_squared_error: 92.3764\n",
      "Epoch 101/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.9835 - mean_squared_error: 9.9835 - val_loss: 69.2707 - val_mean_squared_error: 69.2707\n",
      "Epoch 102/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.2973 - mean_squared_error: 10.2973 - val_loss: 82.1490 - val_mean_squared_error: 82.1490\n",
      "Epoch 103/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.9272 - mean_squared_error: 9.9272 - val_loss: 88.2182 - val_mean_squared_error: 88.2182\n",
      "Epoch 104/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.7943 - mean_squared_error: 9.7943 - val_loss: 79.6153 - val_mean_squared_error: 79.6153\n",
      "Epoch 105/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.6024 - mean_squared_error: 9.6024 - val_loss: 80.6257 - val_mean_squared_error: 80.6257\n",
      "==================================================\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_51 (Conv2D)           (None, 94, 94, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 47, 47, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 47, 47, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 46, 46, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 22, 22, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_53 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 500)               3872500   \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 30)                15030     \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 30)                0         \n",
      "=================================================================\n",
      "Total params: 4,148,526\n",
      "Trainable params: 4,148,526\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "==================================================\n",
      "Train on 1819 samples, validate on 321 samples\n",
      "Epoch 1/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 964.3423 - mean_squared_error: 964.3426 - val_loss: 40.5782 - val_mean_squared_error: 40.5782\n",
      "Epoch 2/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 64.8648 - mean_squared_error: 64.8648 - val_loss: 21.0936 - val_mean_squared_error: 21.0936\n",
      "Epoch 3/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 59.1575 - mean_squared_error: 59.1575 - val_loss: 38.3426 - val_mean_squared_error: 38.3426\n",
      "Epoch 4/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 56.1689 - mean_squared_error: 56.1689 - val_loss: 40.7060 - val_mean_squared_error: 40.7060\n",
      "Epoch 5/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 52.0882 - mean_squared_error: 52.0882 - val_loss: 51.3745 - val_mean_squared_error: 51.3745\n",
      "Epoch 6/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 50.3310 - mean_squared_error: 50.3310 - val_loss: 69.4606 - val_mean_squared_error: 69.4606\n",
      "Epoch 7/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 43.7913 - mean_squared_error: 43.7913 - val_loss: 100.5183 - val_mean_squared_error: 100.5183\n",
      "Epoch 8/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 37.7086 - mean_squared_error: 37.7086 - val_loss: 112.6344 - val_mean_squared_error: 112.6344\n",
      "Epoch 9/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 30.5521 - mean_squared_error: 30.5521 - val_loss: 132.6453 - val_mean_squared_error: 132.6452\n",
      "Epoch 10/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 23.8818 - mean_squared_error: 23.8818 - val_loss: 190.2257 - val_mean_squared_error: 190.2257\n",
      "Epoch 11/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 20.2245 - mean_squared_error: 20.2245 - val_loss: 229.3170 - val_mean_squared_error: 229.3170\n",
      "Epoch 12/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 18.3683 - mean_squared_error: 18.3683 - val_loss: 223.9247 - val_mean_squared_error: 223.9247\n",
      "Epoch 13/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 16.9690 - mean_squared_error: 16.9690 - val_loss: 226.4628 - val_mean_squared_error: 226.4628\n",
      "Epoch 14/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 17.1081 - mean_squared_error: 17.1081 - val_loss: 238.8004 - val_mean_squared_error: 238.8004\n",
      "Epoch 15/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 16.8798 - mean_squared_error: 16.8798 - val_loss: 228.4458 - val_mean_squared_error: 228.4458\n",
      "Epoch 16/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 15.5220 - mean_squared_error: 15.5220 - val_loss: 273.7209 - val_mean_squared_error: 273.7209\n",
      "Epoch 17/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 15.8524 - mean_squared_error: 15.8524 - val_loss: 259.9703 - val_mean_squared_error: 259.9702\n",
      "Epoch 18/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 14.5576 - mean_squared_error: 14.5576 - val_loss: 258.6461 - val_mean_squared_error: 258.6461\n",
      "Epoch 19/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 14.5947 - mean_squared_error: 14.5947 - val_loss: 263.4930 - val_mean_squared_error: 263.4930\n",
      "Epoch 20/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 14.8153 - mean_squared_error: 14.8153 - val_loss: 280.9608 - val_mean_squared_error: 280.9608\n",
      "Epoch 21/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 13.9802 - mean_squared_error: 13.9802 - val_loss: 238.8670 - val_mean_squared_error: 238.8670\n",
      "Epoch 22/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 14.2416 - mean_squared_error: 14.2416 - val_loss: 276.3833 - val_mean_squared_error: 276.3833\n",
      "Epoch 23/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 13.3609 - mean_squared_error: 13.3609 - val_loss: 269.1395 - val_mean_squared_error: 269.1395\n",
      "Epoch 24/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 14.3913 - mean_squared_error: 14.3913 - val_loss: 292.7937 - val_mean_squared_error: 292.7937\n",
      "Epoch 25/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 13.7099 - mean_squared_error: 13.7099 - val_loss: 319.2131 - val_mean_squared_error: 319.2132\n",
      "Epoch 26/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 13.3504 - mean_squared_error: 13.3504 - val_loss: 282.6713 - val_mean_squared_error: 282.6713\n",
      "Epoch 27/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 13.5771 - mean_squared_error: 13.5771 - val_loss: 296.7126 - val_mean_squared_error: 296.7126\n",
      "Epoch 28/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 13.2689 - mean_squared_error: 13.2689 - val_loss: 302.3365 - val_mean_squared_error: 302.3365\n",
      "Epoch 29/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.9932 - mean_squared_error: 12.9932 - val_loss: 305.3925 - val_mean_squared_error: 305.3925\n",
      "Epoch 30/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.8901 - mean_squared_error: 12.8901 - val_loss: 316.5780 - val_mean_squared_error: 316.5780\n",
      "Epoch 31/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.6845 - mean_squared_error: 12.6845 - val_loss: 335.6688 - val_mean_squared_error: 335.6688\n",
      "Epoch 32/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.5322 - mean_squared_error: 12.5322 - val_loss: 336.8676 - val_mean_squared_error: 336.8676\n",
      "Epoch 33/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.8185 - mean_squared_error: 12.8185 - val_loss: 333.7490 - val_mean_squared_error: 333.7491\n",
      "Epoch 34/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.4549 - mean_squared_error: 12.4549 - val_loss: 343.3708 - val_mean_squared_error: 343.3708\n",
      "Epoch 35/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.3172 - mean_squared_error: 12.3172 - val_loss: 323.2799 - val_mean_squared_error: 323.2799\n",
      "Epoch 36/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.3009 - mean_squared_error: 12.3009 - val_loss: 325.2734 - val_mean_squared_error: 325.2734\n",
      "Epoch 37/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.3547 - mean_squared_error: 12.3547 - val_loss: 346.0103 - val_mean_squared_error: 346.0103\n",
      "Epoch 38/200\n",
      "1819/1819 [==============================] - 6s 4ms/sample - loss: 12.4317 - mean_squared_error: 12.4317 - val_loss: 324.7989 - val_mean_squared_error: 324.7989\n",
      "Epoch 39/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.0736 - mean_squared_error: 12.0736 - val_loss: 340.4264 - val_mean_squared_error: 340.4264\n",
      "Epoch 40/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.2260 - mean_squared_error: 12.2260 - val_loss: 353.3555 - val_mean_squared_error: 353.3555\n",
      "Epoch 41/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.3908 - mean_squared_error: 12.3908 - val_loss: 313.0869 - val_mean_squared_error: 313.0869\n",
      "Epoch 42/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.3642 - mean_squared_error: 12.3642 - val_loss: 333.5182 - val_mean_squared_error: 333.5182\n",
      "Epoch 43/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.0438 - mean_squared_error: 12.0438 - val_loss: 330.8522 - val_mean_squared_error: 330.8521\n",
      "Epoch 44/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.1083 - mean_squared_error: 12.1083 - val_loss: 329.9666 - val_mean_squared_error: 329.9666\n",
      "Epoch 45/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.6994 - mean_squared_error: 11.6994 - val_loss: 335.3484 - val_mean_squared_error: 335.3484\n",
      "Epoch 46/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.8532 - mean_squared_error: 11.8532 - val_loss: 334.1356 - val_mean_squared_error: 334.1357\n",
      "Epoch 47/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.0599 - mean_squared_error: 12.0599 - val_loss: 325.6327 - val_mean_squared_error: 325.6328\n",
      "Epoch 48/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.2027 - mean_squared_error: 12.2027 - val_loss: 344.3033 - val_mean_squared_error: 344.3033\n",
      "Epoch 49/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.1741 - mean_squared_error: 12.1741 - val_loss: 338.5534 - val_mean_squared_error: 338.5534\n",
      "Epoch 50/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.0180 - mean_squared_error: 12.0180 - val_loss: 326.0640 - val_mean_squared_error: 326.0640\n",
      "Epoch 51/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.0285 - mean_squared_error: 12.0285 - val_loss: 348.7240 - val_mean_squared_error: 348.7240\n",
      "Epoch 52/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.6833 - mean_squared_error: 11.6833 - val_loss: 330.3307 - val_mean_squared_error: 330.3307\n",
      "Epoch 53/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.2499 - mean_squared_error: 12.2499 - val_loss: 358.9603 - val_mean_squared_error: 358.9603\n",
      "Epoch 54/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.9478 - mean_squared_error: 11.9478 - val_loss: 311.3031 - val_mean_squared_error: 311.3032\n",
      "Epoch 55/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.5388 - mean_squared_error: 11.5388 - val_loss: 310.0674 - val_mean_squared_error: 310.0674\n",
      "Epoch 56/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.8303 - mean_squared_error: 11.8303 - val_loss: 310.9727 - val_mean_squared_error: 310.9727\n",
      "Epoch 57/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.5090 - mean_squared_error: 11.5090 - val_loss: 301.9566 - val_mean_squared_error: 301.9565\n",
      "Epoch 58/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.7251 - mean_squared_error: 11.7251 - val_loss: 304.2231 - val_mean_squared_error: 304.2231\n",
      "Epoch 59/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.4192 - mean_squared_error: 11.4192 - val_loss: 306.5224 - val_mean_squared_error: 306.5224\n",
      "Epoch 60/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.3923 - mean_squared_error: 11.3923 - val_loss: 312.7504 - val_mean_squared_error: 312.7504\n",
      "Epoch 61/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.5030 - mean_squared_error: 11.5030 - val_loss: 331.2251 - val_mean_squared_error: 331.2252\n",
      "Epoch 62/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.5601 - mean_squared_error: 11.5601 - val_loss: 337.8901 - val_mean_squared_error: 337.8901\n",
      "Epoch 63/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.4159 - mean_squared_error: 11.4159 - val_loss: 302.8084 - val_mean_squared_error: 302.8084\n",
      "Epoch 64/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.6962 - mean_squared_error: 11.6962 - val_loss: 317.3163 - val_mean_squared_error: 317.3163\n",
      "Epoch 65/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.6966 - mean_squared_error: 11.6966 - val_loss: 326.8377 - val_mean_squared_error: 326.8377\n",
      "Epoch 66/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.3989 - mean_squared_error: 11.3989 - val_loss: 323.4350 - val_mean_squared_error: 323.4350\n",
      "Epoch 67/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.9378 - mean_squared_error: 10.9378 - val_loss: 313.1328 - val_mean_squared_error: 313.1328\n",
      "Epoch 68/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.3755 - mean_squared_error: 11.3755 - val_loss: 322.0500 - val_mean_squared_error: 322.0500\n",
      "Epoch 69/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.2340 - mean_squared_error: 11.2340 - val_loss: 347.7704 - val_mean_squared_error: 347.7704\n",
      "Epoch 70/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.1600 - mean_squared_error: 11.1600 - val_loss: 320.8706 - val_mean_squared_error: 320.8706\n",
      "Epoch 71/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.0421 - mean_squared_error: 11.0421 - val_loss: 329.5272 - val_mean_squared_error: 329.5273\n",
      "Epoch 72/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.1313 - mean_squared_error: 11.1313 - val_loss: 319.7370 - val_mean_squared_error: 319.7370\n",
      "Epoch 73/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.7138 - mean_squared_error: 10.7138 - val_loss: 344.9837 - val_mean_squared_error: 344.9837\n",
      "Epoch 74/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.6146 - mean_squared_error: 10.6146 - val_loss: 312.8380 - val_mean_squared_error: 312.8381\n",
      "Epoch 75/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.7128 - mean_squared_error: 10.7128 - val_loss: 305.1277 - val_mean_squared_error: 305.1277\n",
      "Epoch 76/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.4773 - mean_squared_error: 10.4773 - val_loss: 328.5310 - val_mean_squared_error: 328.5310\n",
      "Epoch 77/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.5352 - mean_squared_error: 10.5352 - val_loss: 305.2562 - val_mean_squared_error: 305.2562\n",
      "Epoch 78/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.5935 - mean_squared_error: 10.5935 - val_loss: 313.2719 - val_mean_squared_error: 313.2719\n",
      "Epoch 79/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.7029 - mean_squared_error: 10.7029 - val_loss: 300.6526 - val_mean_squared_error: 300.6526\n",
      "Epoch 80/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.5679 - mean_squared_error: 10.5679 - val_loss: 313.6116 - val_mean_squared_error: 313.6116\n",
      "Epoch 81/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.3924 - mean_squared_error: 10.3924 - val_loss: 329.7857 - val_mean_squared_error: 329.7857\n",
      "Epoch 82/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.7968 - mean_squared_error: 10.7968 - val_loss: 334.3165 - val_mean_squared_error: 334.3165\n",
      "Epoch 83/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.2912 - mean_squared_error: 10.2912 - val_loss: 308.7452 - val_mean_squared_error: 308.7452\n",
      "Epoch 84/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.1420 - mean_squared_error: 10.1420 - val_loss: 304.6729 - val_mean_squared_error: 304.6729\n",
      "Epoch 85/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.1512 - mean_squared_error: 10.1512 - val_loss: 307.7348 - val_mean_squared_error: 307.7348\n",
      "Epoch 86/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.1110 - mean_squared_error: 10.1110 - val_loss: 309.9999 - val_mean_squared_error: 309.9999\n",
      "Epoch 87/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.1802 - mean_squared_error: 10.1802 - val_loss: 296.8604 - val_mean_squared_error: 296.8604\n",
      "Epoch 88/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.2447 - mean_squared_error: 10.2447 - val_loss: 314.4409 - val_mean_squared_error: 314.4409\n",
      "Epoch 89/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.0448 - mean_squared_error: 10.0448 - val_loss: 303.7633 - val_mean_squared_error: 303.7633\n",
      "Epoch 90/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.0002 - mean_squared_error: 10.0002 - val_loss: 308.9717 - val_mean_squared_error: 308.9717\n",
      "Epoch 91/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.0658 - mean_squared_error: 10.0658 - val_loss: 288.6614 - val_mean_squared_error: 288.6614\n",
      "Epoch 92/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.1255 - mean_squared_error: 10.1255 - val_loss: 308.6828 - val_mean_squared_error: 308.6827\n",
      "Epoch 93/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.0374 - mean_squared_error: 10.0374 - val_loss: 285.3173 - val_mean_squared_error: 285.3173\n",
      "Epoch 94/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.0224 - mean_squared_error: 10.0224 - val_loss: 281.9203 - val_mean_squared_error: 281.9203\n",
      "Epoch 95/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.6868 - mean_squared_error: 9.6868 - val_loss: 311.2937 - val_mean_squared_error: 311.2937\n",
      "Epoch 96/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.3518 - mean_squared_error: 9.3518 - val_loss: 296.4253 - val_mean_squared_error: 296.4253\n",
      "Epoch 97/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.3092 - mean_squared_error: 9.3092 - val_loss: 300.8291 - val_mean_squared_error: 300.8291\n",
      "Epoch 98/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.7321 - mean_squared_error: 9.7321 - val_loss: 274.1238 - val_mean_squared_error: 274.1238\n",
      "Epoch 99/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.0004 - mean_squared_error: 9.0004 - val_loss: 304.2608 - val_mean_squared_error: 304.2607\n",
      "Epoch 100/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.0231 - mean_squared_error: 9.0231 - val_loss: 290.1969 - val_mean_squared_error: 290.1968\n",
      "Epoch 101/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 8.6556 - mean_squared_error: 8.6556 - val_loss: 308.3715 - val_mean_squared_error: 308.3715\n",
      "Epoch 102/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 8.8004 - mean_squared_error: 8.8004 - val_loss: 280.4015 - val_mean_squared_error: 280.4015\n",
      "==================================================\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_54 (Conv2D)           (None, 94, 94, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling (None, 47, 47, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 47, 47, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 46, 46, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_55 (MaxPooling (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 22, 22, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_56 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 500)               3872500   \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 30)                15030     \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 30)                0         \n",
      "=================================================================\n",
      "Total params: 4,148,526\n",
      "Trainable params: 4,148,526\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1819 samples, validate on 321 samples\n",
      "Epoch 1/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 1213.6387 - mean_squared_error: 1213.6383 - val_loss: 206.2957 - val_mean_squared_error: 206.2957\n",
      "Epoch 2/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 96.5470 - mean_squared_error: 96.5470 - val_loss: 112.2823 - val_mean_squared_error: 112.2823\n",
      "Epoch 3/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 69.5351 - mean_squared_error: 69.5351 - val_loss: 150.3280 - val_mean_squared_error: 150.3280\n",
      "Epoch 4/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 49.5376 - mean_squared_error: 49.5376 - val_loss: 236.8414 - val_mean_squared_error: 236.8414\n",
      "Epoch 5/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 33.2029 - mean_squared_error: 33.2029 - val_loss: 258.5341 - val_mean_squared_error: 258.5341\n",
      "Epoch 6/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 23.1441 - mean_squared_error: 23.1441 - val_loss: 263.6681 - val_mean_squared_error: 263.6680\n",
      "Epoch 7/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 18.7845 - mean_squared_error: 18.7845 - val_loss: 248.3965 - val_mean_squared_error: 248.3966\n",
      "Epoch 8/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 16.8092 - mean_squared_error: 16.8092 - val_loss: 252.9156 - val_mean_squared_error: 252.9156\n",
      "Epoch 9/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 15.6506 - mean_squared_error: 15.6506 - val_loss: 267.9832 - val_mean_squared_error: 267.9831\n",
      "Epoch 10/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 14.0066 - mean_squared_error: 14.0066 - val_loss: 262.7282 - val_mean_squared_error: 262.7281\n",
      "Epoch 11/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 14.8794 - mean_squared_error: 14.8794 - val_loss: 269.1393 - val_mean_squared_error: 269.1393\n",
      "Epoch 12/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 14.5301 - mean_squared_error: 14.5301 - val_loss: 230.0419 - val_mean_squared_error: 230.0419\n",
      "Epoch 13/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 13.1319 - mean_squared_error: 13.1319 - val_loss: 258.4485 - val_mean_squared_error: 258.4485\n",
      "Epoch 14/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.9699 - mean_squared_error: 12.9699 - val_loss: 282.8369 - val_mean_squared_error: 282.8369\n",
      "Epoch 15/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.0985 - mean_squared_error: 12.0985 - val_loss: 249.8710 - val_mean_squared_error: 249.8710\n",
      "Epoch 16/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.1261 - mean_squared_error: 12.1261 - val_loss: 259.7280 - val_mean_squared_error: 259.7280\n",
      "Epoch 17/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.4808 - mean_squared_error: 12.4808 - val_loss: 253.1752 - val_mean_squared_error: 253.1752\n",
      "Epoch 18/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.1260 - mean_squared_error: 12.1259 - val_loss: 253.4228 - val_mean_squared_error: 253.4228\n",
      "Epoch 19/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.8688 - mean_squared_error: 11.8688 - val_loss: 243.4792 - val_mean_squared_error: 243.4792\n",
      "Epoch 20/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.9127 - mean_squared_error: 11.9127 - val_loss: 248.2571 - val_mean_squared_error: 248.2571\n",
      "Epoch 21/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.1450 - mean_squared_error: 12.1450 - val_loss: 260.8353 - val_mean_squared_error: 260.8353\n",
      "Epoch 22/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.7588 - mean_squared_error: 11.7588 - val_loss: 256.2012 - val_mean_squared_error: 256.2012\n",
      "Epoch 23/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.9209 - mean_squared_error: 11.9209 - val_loss: 248.6010 - val_mean_squared_error: 248.6010\n",
      "Epoch 24/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.9635 - mean_squared_error: 11.9635 - val_loss: 268.5045 - val_mean_squared_error: 268.5045\n",
      "Epoch 25/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.6298 - mean_squared_error: 11.6298 - val_loss: 234.2709 - val_mean_squared_error: 234.2709\n",
      "Epoch 26/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.4564 - mean_squared_error: 11.4564 - val_loss: 234.1030 - val_mean_squared_error: 234.1030\n",
      "Epoch 27/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.8936 - mean_squared_error: 11.8936 - val_loss: 244.6324 - val_mean_squared_error: 244.6324\n",
      "Epoch 28/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.3494 - mean_squared_error: 11.3494 - val_loss: 256.5461 - val_mean_squared_error: 256.5461\n",
      "Epoch 29/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.3594 - mean_squared_error: 11.3594 - val_loss: 236.6651 - val_mean_squared_error: 236.6651\n",
      "Epoch 30/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.2131 - mean_squared_error: 11.2130 - val_loss: 221.7211 - val_mean_squared_error: 221.7211\n",
      "Epoch 31/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.2260 - mean_squared_error: 11.2260 - val_loss: 227.0807 - val_mean_squared_error: 227.0807\n",
      "Epoch 32/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.1386 - mean_squared_error: 11.1386 - val_loss: 230.6966 - val_mean_squared_error: 230.6967\n",
      "Epoch 33/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.2290 - mean_squared_error: 11.2290 - val_loss: 248.7862 - val_mean_squared_error: 248.7862\n",
      "Epoch 34/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.7415 - mean_squared_error: 11.7415 - val_loss: 234.0194 - val_mean_squared_error: 234.0194\n",
      "Epoch 35/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.1978 - mean_squared_error: 11.1978 - val_loss: 214.8012 - val_mean_squared_error: 214.8012\n",
      "Epoch 36/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.2596 - mean_squared_error: 11.2596 - val_loss: 234.0771 - val_mean_squared_error: 234.0771\n",
      "Epoch 37/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.3914 - mean_squared_error: 11.3914 - val_loss: 243.3728 - val_mean_squared_error: 243.3728\n",
      "Epoch 38/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.5001 - mean_squared_error: 11.5001 - val_loss: 221.4407 - val_mean_squared_error: 221.4407\n",
      "Epoch 39/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.3621 - mean_squared_error: 11.3621 - val_loss: 251.5739 - val_mean_squared_error: 251.5739\n",
      "Epoch 40/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.0661 - mean_squared_error: 11.0661 - val_loss: 202.8021 - val_mean_squared_error: 202.8021\n",
      "Epoch 41/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.8195 - mean_squared_error: 10.8195 - val_loss: 243.4063 - val_mean_squared_error: 243.4063\n",
      "Epoch 42/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.3537 - mean_squared_error: 11.3537 - val_loss: 213.4118 - val_mean_squared_error: 213.4118\n",
      "Epoch 43/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.2723 - mean_squared_error: 11.2723 - val_loss: 194.9518 - val_mean_squared_error: 194.9518\n",
      "Epoch 44/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.1079 - mean_squared_error: 11.1079 - val_loss: 217.7814 - val_mean_squared_error: 217.7814\n",
      "Epoch 45/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.8810 - mean_squared_error: 10.8810 - val_loss: 200.7901 - val_mean_squared_error: 200.7901\n",
      "Epoch 46/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.2587 - mean_squared_error: 11.2587 - val_loss: 217.9943 - val_mean_squared_error: 217.9943\n",
      "Epoch 47/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.8639 - mean_squared_error: 10.8639 - val_loss: 219.1893 - val_mean_squared_error: 219.1893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.0523 - mean_squared_error: 11.0523 - val_loss: 205.6615 - val_mean_squared_error: 205.6615\n",
      "Epoch 49/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.1156 - mean_squared_error: 11.1156 - val_loss: 203.3401 - val_mean_squared_error: 203.3401\n",
      "Epoch 50/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.2134 - mean_squared_error: 11.2134 - val_loss: 196.2203 - val_mean_squared_error: 196.2202\n",
      "Epoch 51/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.8915 - mean_squared_error: 10.8915 - val_loss: 213.3526 - val_mean_squared_error: 213.3526\n",
      "Epoch 52/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.7330 - mean_squared_error: 10.7330 - val_loss: 223.5492 - val_mean_squared_error: 223.5492\n",
      "Epoch 53/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.9006 - mean_squared_error: 10.9006 - val_loss: 201.3059 - val_mean_squared_error: 201.3059\n",
      "Epoch 54/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.8366 - mean_squared_error: 10.8366 - val_loss: 197.8196 - val_mean_squared_error: 197.8196\n",
      "Epoch 55/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.9418 - mean_squared_error: 10.9418 - val_loss: 216.9256 - val_mean_squared_error: 216.9256\n",
      "Epoch 56/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.0012 - mean_squared_error: 11.0012 - val_loss: 218.4670 - val_mean_squared_error: 218.4670\n",
      "Epoch 57/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.8817 - mean_squared_error: 10.8817 - val_loss: 207.7925 - val_mean_squared_error: 207.7925\n",
      "Epoch 58/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.0258 - mean_squared_error: 11.0258 - val_loss: 217.3657 - val_mean_squared_error: 217.3657\n",
      "Epoch 59/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.9010 - mean_squared_error: 10.9010 - val_loss: 210.1688 - val_mean_squared_error: 210.1688\n",
      "Epoch 60/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.8868 - mean_squared_error: 10.8868 - val_loss: 193.6703 - val_mean_squared_error: 193.6703\n",
      "Epoch 61/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.9111 - mean_squared_error: 10.9111 - val_loss: 179.0882 - val_mean_squared_error: 179.0882\n",
      "Epoch 62/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.5788 - mean_squared_error: 10.5788 - val_loss: 209.3376 - val_mean_squared_error: 209.3376\n",
      "Epoch 63/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.0915 - mean_squared_error: 11.0915 - val_loss: 186.4561 - val_mean_squared_error: 186.4561\n",
      "Epoch 64/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.8072 - mean_squared_error: 10.8072 - val_loss: 198.6140 - val_mean_squared_error: 198.6140\n",
      "Epoch 65/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.9023 - mean_squared_error: 10.9023 - val_loss: 212.5174 - val_mean_squared_error: 212.5174\n",
      "Epoch 66/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.1673 - mean_squared_error: 11.1673 - val_loss: 191.6479 - val_mean_squared_error: 191.6479\n",
      "Epoch 67/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.7498 - mean_squared_error: 10.7498 - val_loss: 179.4242 - val_mean_squared_error: 179.4242\n",
      "Epoch 68/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.5367 - mean_squared_error: 10.5367 - val_loss: 181.9347 - val_mean_squared_error: 181.9348\n",
      "Epoch 69/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.9227 - mean_squared_error: 10.9227 - val_loss: 182.0824 - val_mean_squared_error: 182.0824\n",
      "Epoch 70/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.5379 - mean_squared_error: 10.5379 - val_loss: 184.6335 - val_mean_squared_error: 184.6335\n",
      "Epoch 71/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.6681 - mean_squared_error: 10.6681 - val_loss: 192.1764 - val_mean_squared_error: 192.1765\n",
      "Epoch 72/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.5771 - mean_squared_error: 10.5771 - val_loss: 187.2424 - val_mean_squared_error: 187.2424\n",
      "Epoch 73/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.6628 - mean_squared_error: 10.6628 - val_loss: 189.4692 - val_mean_squared_error: 189.4692\n",
      "Epoch 74/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.6850 - mean_squared_error: 10.6850 - val_loss: 181.7683 - val_mean_squared_error: 181.7684\n",
      "Epoch 75/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.7022 - mean_squared_error: 10.7022 - val_loss: 179.6964 - val_mean_squared_error: 179.6964\n",
      "Epoch 76/200\n",
      "1819/1819 [==============================] - 6s 4ms/sample - loss: 10.4264 - mean_squared_error: 10.4265 - val_loss: 201.6037 - val_mean_squared_error: 201.6038\n",
      "Epoch 77/200\n",
      "1819/1819 [==============================] - 6s 4ms/sample - loss: 10.4846 - mean_squared_error: 10.4846 - val_loss: 179.5195 - val_mean_squared_error: 179.5195\n",
      "Epoch 78/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.8105 - mean_squared_error: 10.8105 - val_loss: 204.5199 - val_mean_squared_error: 204.5199\n",
      "Epoch 79/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.5630 - mean_squared_error: 10.5630 - val_loss: 203.9741 - val_mean_squared_error: 203.9741\n",
      "Epoch 80/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.7368 - mean_squared_error: 10.7368 - val_loss: 190.4387 - val_mean_squared_error: 190.4387\n",
      "Epoch 81/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.4110 - mean_squared_error: 10.4110 - val_loss: 191.2225 - val_mean_squared_error: 191.2224\n",
      "Epoch 82/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.4531 - mean_squared_error: 10.4531 - val_loss: 162.9655 - val_mean_squared_error: 162.9655\n",
      "Epoch 83/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.6235 - mean_squared_error: 10.6235 - val_loss: 174.9776 - val_mean_squared_error: 174.9776\n",
      "Epoch 84/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.2941 - mean_squared_error: 10.2941 - val_loss: 163.7435 - val_mean_squared_error: 163.7435\n",
      "Epoch 85/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.3845 - mean_squared_error: 10.3845 - val_loss: 148.8786 - val_mean_squared_error: 148.8786\n",
      "Epoch 86/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.5703 - mean_squared_error: 10.5703 - val_loss: 164.7631 - val_mean_squared_error: 164.7631\n",
      "Epoch 87/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.3682 - mean_squared_error: 10.3682 - val_loss: 172.0636 - val_mean_squared_error: 172.0636\n",
      "Epoch 88/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.0903 - mean_squared_error: 10.0903 - val_loss: 162.0902 - val_mean_squared_error: 162.0902\n",
      "Epoch 89/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.1145 - mean_squared_error: 10.1145 - val_loss: 175.9558 - val_mean_squared_error: 175.9558\n",
      "Epoch 90/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.2578 - mean_squared_error: 10.2578 - val_loss: 154.4800 - val_mean_squared_error: 154.4800\n",
      "Epoch 91/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.2720 - mean_squared_error: 10.2720 - val_loss: 178.4111 - val_mean_squared_error: 178.4111\n",
      "Epoch 92/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.0898 - mean_squared_error: 10.0898 - val_loss: 168.5560 - val_mean_squared_error: 168.5560\n",
      "Epoch 93/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.0100 - mean_squared_error: 10.0100 - val_loss: 151.5909 - val_mean_squared_error: 151.5909\n",
      "Epoch 94/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.0509 - mean_squared_error: 10.0509 - val_loss: 163.7762 - val_mean_squared_error: 163.7762\n",
      "Epoch 95/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.5191 - mean_squared_error: 10.5191 - val_loss: 156.8011 - val_mean_squared_error: 156.8011\n",
      "Epoch 96/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.0609 - mean_squared_error: 10.0609 - val_loss: 150.2643 - val_mean_squared_error: 150.2643\n",
      "Epoch 97/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.0963 - mean_squared_error: 10.0963 - val_loss: 158.0233 - val_mean_squared_error: 158.0233\n",
      "Epoch 98/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 9.9903 - mean_squared_error: 9.9903 - val_loss: 165.6025 - val_mean_squared_error: 165.6025\n",
      "Epoch 99/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.0406 - mean_squared_error: 10.0406 - val_loss: 157.7974 - val_mean_squared_error: 157.7974\n",
      "Epoch 100/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.0707 - mean_squared_error: 10.0707 - val_loss: 151.6074 - val_mean_squared_error: 151.6074\n",
      "Epoch 101/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 10.0644 - mean_squared_error: 10.0644 - val_loss: 169.8956 - val_mean_squared_error: 169.8956\n",
      "Epoch 102/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 9.9113 - mean_squared_error: 9.9113 - val_loss: 161.0284 - val_mean_squared_error: 161.0284\n",
      "==================================================\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_57 (Conv2D)           (None, 94, 94, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_57 (MaxPooling (None, 47, 47, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 47, 47, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 46, 46, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_58 (MaxPooling (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 22, 22, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_59 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 500)               3872500   \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 30)                15030     \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 30)                0         \n",
      "=================================================================\n",
      "Total params: 4,148,526\n",
      "Trainable params: 4,148,526\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "==================================================\n",
      "Train on 1819 samples, validate on 321 samples\n",
      "Epoch 1/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 513.8238 - mean_squared_error: 513.8239 - val_loss: 170.3667 - val_mean_squared_error: 170.3667\n",
      "Epoch 2/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 28.6813 - mean_squared_error: 28.6813 - val_loss: 154.7543 - val_mean_squared_error: 154.7543\n",
      "Epoch 3/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 26.0416 - mean_squared_error: 26.0416 - val_loss: 151.7058 - val_mean_squared_error: 151.7058\n",
      "Epoch 4/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 24.1658 - mean_squared_error: 24.1658 - val_loss: 146.0184 - val_mean_squared_error: 146.0184\n",
      "Epoch 5/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 24.1779 - mean_squared_error: 24.1779 - val_loss: 155.9259 - val_mean_squared_error: 155.9259\n",
      "Epoch 6/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 24.6079 - mean_squared_error: 24.6079 - val_loss: 140.5455 - val_mean_squared_error: 140.5455\n",
      "Epoch 7/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 24.5894 - mean_squared_error: 24.5894 - val_loss: 127.2660 - val_mean_squared_error: 127.2660\n",
      "Epoch 8/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 23.5065 - mean_squared_error: 23.5065 - val_loss: 127.8543 - val_mean_squared_error: 127.8543\n",
      "Epoch 9/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 22.0006 - mean_squared_error: 22.0006 - val_loss: 101.4885 - val_mean_squared_error: 101.4885\n",
      "Epoch 10/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 23.4811 - mean_squared_error: 23.4811 - val_loss: 136.4173 - val_mean_squared_error: 136.4173\n",
      "Epoch 11/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 23.9096 - mean_squared_error: 23.9096 - val_loss: 110.9136 - val_mean_squared_error: 110.9136\n",
      "Epoch 12/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 22.5499 - mean_squared_error: 22.5499 - val_loss: 121.6930 - val_mean_squared_error: 121.6930\n",
      "Epoch 13/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 22.5629 - mean_squared_error: 22.5629 - val_loss: 129.6108 - val_mean_squared_error: 129.6108\n",
      "Epoch 14/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 22.0564 - mean_squared_error: 22.0564 - val_loss: 75.1486 - val_mean_squared_error: 75.1486\n",
      "Epoch 15/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 23.9810 - mean_squared_error: 23.9810 - val_loss: 87.7962 - val_mean_squared_error: 87.7962\n",
      "Epoch 16/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 22.3696 - mean_squared_error: 22.3696 - val_loss: 133.5095 - val_mean_squared_error: 133.5096\n",
      "Epoch 17/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 23.4710 - mean_squared_error: 23.4710 - val_loss: 83.9330 - val_mean_squared_error: 83.9330\n",
      "Epoch 18/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 22.7304 - mean_squared_error: 22.7304 - val_loss: 72.8270 - val_mean_squared_error: 72.8270\n",
      "Epoch 19/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 23.6387 - mean_squared_error: 23.6387 - val_loss: 105.6188 - val_mean_squared_error: 105.6188\n",
      "Epoch 20/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 22.2490 - mean_squared_error: 22.2491 - val_loss: 93.1823 - val_mean_squared_error: 93.1823\n",
      "Epoch 21/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 21.9975 - mean_squared_error: 21.9975 - val_loss: 77.5753 - val_mean_squared_error: 77.5753\n",
      "Epoch 22/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 21.9582 - mean_squared_error: 21.9582 - val_loss: 60.0140 - val_mean_squared_error: 60.0140\n",
      "Epoch 23/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 22.3155 - mean_squared_error: 22.3155 - val_loss: 62.8241 - val_mean_squared_error: 62.8241\n",
      "Epoch 24/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 21.7687 - mean_squared_error: 21.7687 - val_loss: 71.7499 - val_mean_squared_error: 71.7499\n",
      "Epoch 25/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 22.3479 - mean_squared_error: 22.3479 - val_loss: 64.8150 - val_mean_squared_error: 64.8149\n",
      "Epoch 26/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 22.8922 - mean_squared_error: 22.8922 - val_loss: 87.5067 - val_mean_squared_error: 87.5067\n",
      "Epoch 27/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 21.7052 - mean_squared_error: 21.7052 - val_loss: 78.9649 - val_mean_squared_error: 78.9649\n",
      "Epoch 28/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 22.7683 - mean_squared_error: 22.7683 - val_loss: 50.7494 - val_mean_squared_error: 50.7494\n",
      "Epoch 29/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 22.5405 - mean_squared_error: 22.5405 - val_loss: 47.2132 - val_mean_squared_error: 47.2132\n",
      "Epoch 30/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 21.7774 - mean_squared_error: 21.7774 - val_loss: 45.9971 - val_mean_squared_error: 45.9971\n",
      "Epoch 31/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 22.6117 - mean_squared_error: 22.6117 - val_loss: 41.3389 - val_mean_squared_error: 41.3389\n",
      "Epoch 32/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 21.5402 - mean_squared_error: 21.5403 - val_loss: 42.3505 - val_mean_squared_error: 42.3505\n",
      "Epoch 33/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 24.0920 - mean_squared_error: 24.0921 - val_loss: 38.9574 - val_mean_squared_error: 38.9574\n",
      "Epoch 34/200\n",
      "1819/1819 [==============================] - 5s 3ms/sample - loss: 22.2329 - mean_squared_error: 22.2329 - val_loss: 37.1163 - val_mean_squared_error: 37.1162\n",
      "Epoch 35/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 22.7360 - mean_squared_error: 22.7360 - val_loss: 48.4085 - val_mean_squared_error: 48.4085\n",
      "Epoch 36/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 21.1300 - mean_squared_error: 21.1300 - val_loss: 47.2145 - val_mean_squared_error: 47.2145\n",
      "Epoch 37/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 21.0883 - mean_squared_error: 21.0883 - val_loss: 39.6430 - val_mean_squared_error: 39.6430\n",
      "Epoch 38/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 20.6626 - mean_squared_error: 20.6626 - val_loss: 35.7524 - val_mean_squared_error: 35.7524\n",
      "Epoch 39/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 22.8936 - mean_squared_error: 22.8936 - val_loss: 24.1264 - val_mean_squared_error: 24.1264\n",
      "Epoch 40/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 20.7093 - mean_squared_error: 20.7093 - val_loss: 36.8670 - val_mean_squared_error: 36.8670\n",
      "Epoch 41/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 22.1332 - mean_squared_error: 22.1332 - val_loss: 21.7993 - val_mean_squared_error: 21.7993\n",
      "Epoch 42/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 21.2162 - mean_squared_error: 21.2162 - val_loss: 30.8978 - val_mean_squared_error: 30.8978\n",
      "Epoch 43/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 21.1281 - mean_squared_error: 21.1281 - val_loss: 21.3055 - val_mean_squared_error: 21.3055\n",
      "Epoch 44/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 20.1709 - mean_squared_error: 20.1709 - val_loss: 26.1434 - val_mean_squared_error: 26.1434\n",
      "Epoch 45/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 22.4472 - mean_squared_error: 22.4472 - val_loss: 53.8548 - val_mean_squared_error: 53.8548\n",
      "Epoch 46/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 22.0942 - mean_squared_error: 22.0942 - val_loss: 19.1527 - val_mean_squared_error: 19.1527\n",
      "Epoch 47/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 20.8242 - mean_squared_error: 20.8242 - val_loss: 28.0226 - val_mean_squared_error: 28.0226\n",
      "Epoch 48/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 20.9025 - mean_squared_error: 20.9025 - val_loss: 23.9617 - val_mean_squared_error: 23.9617\n",
      "Epoch 49/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 20.7411 - mean_squared_error: 20.7411 - val_loss: 23.6429 - val_mean_squared_error: 23.6429\n",
      "Epoch 50/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 21.0131 - mean_squared_error: 21.0131 - val_loss: 27.3636 - val_mean_squared_error: 27.3636\n",
      "Epoch 51/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 21.5542 - mean_squared_error: 21.5542 - val_loss: 27.3288 - val_mean_squared_error: 27.3288\n",
      "Epoch 52/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 20.3585 - mean_squared_error: 20.3585 - val_loss: 26.2294 - val_mean_squared_error: 26.2294\n",
      "Epoch 53/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 20.8015 - mean_squared_error: 20.8015 - val_loss: 23.1901 - val_mean_squared_error: 23.1901\n",
      "Epoch 54/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 20.9548 - mean_squared_error: 20.9548 - val_loss: 20.7448 - val_mean_squared_error: 20.7448\n",
      "Epoch 55/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 20.5065 - mean_squared_error: 20.5065 - val_loss: 21.5613 - val_mean_squared_error: 21.5613\n",
      "Epoch 56/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 19.5258 - mean_squared_error: 19.5258 - val_loss: 20.2209 - val_mean_squared_error: 20.2209\n",
      "Epoch 57/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 19.6297 - mean_squared_error: 19.6297 - val_loss: 20.8778 - val_mean_squared_error: 20.8778\n",
      "Epoch 58/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 20.2829 - mean_squared_error: 20.2829 - val_loss: 25.2435 - val_mean_squared_error: 25.2435\n",
      "Epoch 59/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 18.7678 - mean_squared_error: 18.7678 - val_loss: 18.4859 - val_mean_squared_error: 18.4859\n",
      "Epoch 60/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 20.5167 - mean_squared_error: 20.5167 - val_loss: 35.2097 - val_mean_squared_error: 35.2097\n",
      "Epoch 61/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 21.3373 - mean_squared_error: 21.3373 - val_loss: 23.0070 - val_mean_squared_error: 23.0070\n",
      "Epoch 62/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 20.4945 - mean_squared_error: 20.4945 - val_loss: 14.7785 - val_mean_squared_error: 14.7785\n",
      "Epoch 63/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 19.9335 - mean_squared_error: 19.9335 - val_loss: 17.5031 - val_mean_squared_error: 17.5031\n",
      "Epoch 64/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 19.8451 - mean_squared_error: 19.8451 - val_loss: 12.0199 - val_mean_squared_error: 12.0199\n",
      "Epoch 65/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 19.4282 - mean_squared_error: 19.4282 - val_loss: 18.2368 - val_mean_squared_error: 18.2368\n",
      "Epoch 66/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 19.8704 - mean_squared_error: 19.8704 - val_loss: 21.0233 - val_mean_squared_error: 21.0233\n",
      "Epoch 67/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 20.1619 - mean_squared_error: 20.1619 - val_loss: 10.7309 - val_mean_squared_error: 10.7309\n",
      "Epoch 68/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 20.2057 - mean_squared_error: 20.2057 - val_loss: 19.7681 - val_mean_squared_error: 19.7681\n",
      "Epoch 69/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 19.7539 - mean_squared_error: 19.7539 - val_loss: 33.3033 - val_mean_squared_error: 33.3033\n",
      "Epoch 70/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 18.8381 - mean_squared_error: 18.8381 - val_loss: 21.2564 - val_mean_squared_error: 21.2564\n",
      "Epoch 71/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 20.1022 - mean_squared_error: 20.1022 - val_loss: 29.3973 - val_mean_squared_error: 29.3973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 19.0269 - mean_squared_error: 19.0269 - val_loss: 17.0307 - val_mean_squared_error: 17.0307\n",
      "Epoch 73/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 19.9070 - mean_squared_error: 19.9070 - val_loss: 23.3520 - val_mean_squared_error: 23.3520\n",
      "Epoch 74/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 18.9866 - mean_squared_error: 18.9866 - val_loss: 18.7100 - val_mean_squared_error: 18.7100\n",
      "Epoch 75/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 18.5875 - mean_squared_error: 18.5875 - val_loss: 17.0308 - val_mean_squared_error: 17.0308\n",
      "Epoch 76/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 18.9238 - mean_squared_error: 18.9237 - val_loss: 26.2261 - val_mean_squared_error: 26.2261\n",
      "Epoch 77/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 18.1565 - mean_squared_error: 18.1565 - val_loss: 26.4694 - val_mean_squared_error: 26.4694\n",
      "Epoch 78/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 17.9947 - mean_squared_error: 17.9947 - val_loss: 14.6585 - val_mean_squared_error: 14.6585\n",
      "Epoch 79/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 20.0912 - mean_squared_error: 20.0912 - val_loss: 9.4250 - val_mean_squared_error: 9.4250\n",
      "Epoch 80/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 20.0723 - mean_squared_error: 20.0723 - val_loss: 22.4945 - val_mean_squared_error: 22.4945\n",
      "Epoch 81/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 18.9842 - mean_squared_error: 18.9842 - val_loss: 9.9636 - val_mean_squared_error: 9.9636\n",
      "Epoch 82/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 18.6395 - mean_squared_error: 18.6395 - val_loss: 20.1206 - val_mean_squared_error: 20.1206\n",
      "Epoch 83/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 19.0576 - mean_squared_error: 19.0576 - val_loss: 16.8484 - val_mean_squared_error: 16.8484\n",
      "Epoch 84/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 18.1413 - mean_squared_error: 18.1413 - val_loss: 22.8316 - val_mean_squared_error: 22.8316\n",
      "Epoch 85/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 17.2697 - mean_squared_error: 17.2697 - val_loss: 32.5190 - val_mean_squared_error: 32.5190\n",
      "Epoch 86/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 16.3357 - mean_squared_error: 16.3357 - val_loss: 33.2838 - val_mean_squared_error: 33.2838\n",
      "Epoch 87/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 16.3116 - mean_squared_error: 16.3116 - val_loss: 29.0626 - val_mean_squared_error: 29.0626\n",
      "Epoch 88/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 15.9469 - mean_squared_error: 15.9469 - val_loss: 36.2978 - val_mean_squared_error: 36.2978\n",
      "Epoch 89/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 17.3660 - mean_squared_error: 17.3660 - val_loss: 52.1116 - val_mean_squared_error: 52.1116\n",
      "Epoch 90/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 14.7142 - mean_squared_error: 14.7142 - val_loss: 54.9222 - val_mean_squared_error: 54.9222\n",
      "Epoch 91/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 14.5462 - mean_squared_error: 14.5462 - val_loss: 50.2096 - val_mean_squared_error: 50.2096\n",
      "Epoch 92/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 14.3516 - mean_squared_error: 14.3516 - val_loss: 61.4379 - val_mean_squared_error: 61.4379\n",
      "Epoch 93/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 13.9383 - mean_squared_error: 13.9383 - val_loss: 68.5478 - val_mean_squared_error: 68.5478\n",
      "Epoch 94/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 13.5065 - mean_squared_error: 13.5065 - val_loss: 75.2491 - val_mean_squared_error: 75.2491\n",
      "Epoch 95/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 13.5870 - mean_squared_error: 13.5870 - val_loss: 73.7783 - val_mean_squared_error: 73.7783\n",
      "Epoch 96/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 13.2611 - mean_squared_error: 13.2611 - val_loss: 110.8241 - val_mean_squared_error: 110.8241\n",
      "Epoch 97/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 13.3687 - mean_squared_error: 13.3687 - val_loss: 76.1176 - val_mean_squared_error: 76.1176\n",
      "Epoch 98/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 13.6706 - mean_squared_error: 13.6706 - val_loss: 82.6488 - val_mean_squared_error: 82.6488\n",
      "Epoch 99/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 13.4114 - mean_squared_error: 13.4114 - val_loss: 63.8990 - val_mean_squared_error: 63.8990\n",
      "Epoch 100/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.5446 - mean_squared_error: 12.5446 - val_loss: 64.5282 - val_mean_squared_error: 64.5282\n",
      "Epoch 101/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 13.0334 - mean_squared_error: 13.0334 - val_loss: 53.1607 - val_mean_squared_error: 53.1607\n",
      "Epoch 102/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.7677 - mean_squared_error: 12.7677 - val_loss: 75.0053 - val_mean_squared_error: 75.0053\n",
      "Epoch 103/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.3979 - mean_squared_error: 12.3979 - val_loss: 72.0746 - val_mean_squared_error: 72.0746\n",
      "Epoch 104/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.3187 - mean_squared_error: 12.3187 - val_loss: 65.7217 - val_mean_squared_error: 65.7217\n",
      "Epoch 105/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.9837 - mean_squared_error: 11.9837 - val_loss: 76.9233 - val_mean_squared_error: 76.9233\n",
      "Epoch 106/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.8837 - mean_squared_error: 11.8837 - val_loss: 64.2220 - val_mean_squared_error: 64.2220\n",
      "Epoch 107/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.0519 - mean_squared_error: 12.0519 - val_loss: 68.7466 - val_mean_squared_error: 68.7466\n",
      "Epoch 108/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.9238 - mean_squared_error: 11.9238 - val_loss: 62.3440 - val_mean_squared_error: 62.3440\n",
      "Epoch 109/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.7518 - mean_squared_error: 11.7518 - val_loss: 74.9504 - val_mean_squared_error: 74.9504\n",
      "Epoch 110/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.2072 - mean_squared_error: 11.2072 - val_loss: 97.0554 - val_mean_squared_error: 97.0554\n",
      "Epoch 111/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.9579 - mean_squared_error: 10.9579 - val_loss: 85.4834 - val_mean_squared_error: 85.4834\n",
      "Epoch 112/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.7641 - mean_squared_error: 11.7641 - val_loss: 79.6123 - val_mean_squared_error: 79.6123\n",
      "Epoch 113/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 12.0898 - mean_squared_error: 12.0898 - val_loss: 100.4644 - val_mean_squared_error: 100.4643\n",
      "Epoch 114/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.8945 - mean_squared_error: 10.8945 - val_loss: 73.0355 - val_mean_squared_error: 73.0355\n",
      "Epoch 115/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.1194 - mean_squared_error: 11.1194 - val_loss: 78.6613 - val_mean_squared_error: 78.6613\n",
      "Epoch 116/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.1324 - mean_squared_error: 11.1324 - val_loss: 106.9369 - val_mean_squared_error: 106.9369\n",
      "Epoch 117/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 11.0480 - mean_squared_error: 11.0480 - val_loss: 84.8498 - val_mean_squared_error: 84.8498\n",
      "Epoch 118/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.6240 - mean_squared_error: 10.6240 - val_loss: 70.0947 - val_mean_squared_error: 70.0947\n",
      "Epoch 119/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.2229 - mean_squared_error: 10.2229 - val_loss: 107.9838 - val_mean_squared_error: 107.9838\n",
      "Epoch 120/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.4223 - mean_squared_error: 10.4223 - val_loss: 52.8098 - val_mean_squared_error: 52.8098\n",
      "Epoch 121/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.2915 - mean_squared_error: 10.2915 - val_loss: 69.3399 - val_mean_squared_error: 69.3399\n",
      "Epoch 122/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.3089 - mean_squared_error: 10.3089 - val_loss: 90.2756 - val_mean_squared_error: 90.2756\n",
      "Epoch 123/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 9.9466 - mean_squared_error: 9.9466 - val_loss: 101.1008 - val_mean_squared_error: 101.1008\n",
      "Epoch 124/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 9.9793 - mean_squared_error: 9.9793 - val_loss: 117.9120 - val_mean_squared_error: 117.9120\n",
      "Epoch 125/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 10.5909 - mean_squared_error: 10.5909 - val_loss: 90.7591 - val_mean_squared_error: 90.7591\n",
      "Epoch 126/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 9.5885 - mean_squared_error: 9.5885 - val_loss: 88.1745 - val_mean_squared_error: 88.1745\n",
      "Epoch 127/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 9.2880 - mean_squared_error: 9.2880 - val_loss: 99.1795 - val_mean_squared_error: 99.1795\n",
      "Epoch 128/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 9.9667 - mean_squared_error: 9.9667 - val_loss: 103.4444 - val_mean_squared_error: 103.4444\n",
      "Epoch 129/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 9.5262 - mean_squared_error: 9.5262 - val_loss: 63.2134 - val_mean_squared_error: 63.2134\n",
      "Epoch 130/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 8.8280 - mean_squared_error: 8.8280 - val_loss: 93.3025 - val_mean_squared_error: 93.3025\n",
      "Epoch 131/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 9.0833 - mean_squared_error: 9.0833 - val_loss: 89.0395 - val_mean_squared_error: 89.0396\n",
      "Epoch 132/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 8.7076 - mean_squared_error: 8.7076 - val_loss: 83.8100 - val_mean_squared_error: 83.8100\n",
      "Epoch 133/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 8.3939 - mean_squared_error: 8.3939 - val_loss: 73.5521 - val_mean_squared_error: 73.5521\n",
      "Epoch 134/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 8.3683 - mean_squared_error: 8.3683 - val_loss: 82.6907 - val_mean_squared_error: 82.6908\n",
      "Epoch 135/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 8.1429 - mean_squared_error: 8.1429 - val_loss: 77.3055 - val_mean_squared_error: 77.3055\n",
      "Epoch 136/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 8.0438 - mean_squared_error: 8.0438 - val_loss: 60.2936 - val_mean_squared_error: 60.2936\n",
      "Epoch 137/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 8.1702 - mean_squared_error: 8.1702 - val_loss: 60.5466 - val_mean_squared_error: 60.5466\n",
      "Epoch 138/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 7.6982 - mean_squared_error: 7.6982 - val_loss: 88.2465 - val_mean_squared_error: 88.2465\n",
      "Epoch 139/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 7.8980 - mean_squared_error: 7.8980 - val_loss: 81.6125 - val_mean_squared_error: 81.6125\n",
      "Epoch 140/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 7.7124 - mean_squared_error: 7.7124 - val_loss: 77.2278 - val_mean_squared_error: 77.2278\n",
      "Epoch 141/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 7.2674 - mean_squared_error: 7.2674 - val_loss: 73.0781 - val_mean_squared_error: 73.0781\n",
      "Epoch 142/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 7.2702 - mean_squared_error: 7.2702 - val_loss: 74.3428 - val_mean_squared_error: 74.3428\n",
      "Epoch 143/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 6.8128 - mean_squared_error: 6.8128 - val_loss: 82.2928 - val_mean_squared_error: 82.2928\n",
      "Epoch 144/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 7.0920 - mean_squared_error: 7.0920 - val_loss: 94.6841 - val_mean_squared_error: 94.6841\n",
      "Epoch 145/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 7.1258 - mean_squared_error: 7.1258 - val_loss: 54.8479 - val_mean_squared_error: 54.8479\n",
      "Epoch 146/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 7.2010 - mean_squared_error: 7.2010 - val_loss: 68.5523 - val_mean_squared_error: 68.5523\n",
      "Epoch 147/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 6.7258 - mean_squared_error: 6.7258 - val_loss: 82.2634 - val_mean_squared_error: 82.2634\n",
      "Epoch 148/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 6.5875 - mean_squared_error: 6.5875 - val_loss: 72.4880 - val_mean_squared_error: 72.4880\n",
      "Epoch 149/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 6.2464 - mean_squared_error: 6.2465 - val_loss: 77.6391 - val_mean_squared_error: 77.6391\n",
      "Epoch 150/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 6.4303 - mean_squared_error: 6.4303 - val_loss: 72.7013 - val_mean_squared_error: 72.7013\n",
      "Epoch 151/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 5.9470 - mean_squared_error: 5.9470 - val_loss: 64.6144 - val_mean_squared_error: 64.6144\n",
      "Epoch 152/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 5.9424 - mean_squared_error: 5.9424 - val_loss: 66.7418 - val_mean_squared_error: 66.7418\n",
      "Epoch 153/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 5.8860 - mean_squared_error: 5.8860 - val_loss: 65.0682 - val_mean_squared_error: 65.0682\n",
      "Epoch 154/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 5.7205 - mean_squared_error: 5.7205 - val_loss: 60.4780 - val_mean_squared_error: 60.4780\n",
      "Epoch 155/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 5.5419 - mean_squared_error: 5.5419 - val_loss: 60.0316 - val_mean_squared_error: 60.0316\n",
      "Epoch 156/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 5.5004 - mean_squared_error: 5.5004 - val_loss: 57.1832 - val_mean_squared_error: 57.1832\n",
      "Epoch 157/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 5.6314 - mean_squared_error: 5.6314 - val_loss: 57.9114 - val_mean_squared_error: 57.9114\n",
      "Epoch 158/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 5.3155 - mean_squared_error: 5.3155 - val_loss: 59.8069 - val_mean_squared_error: 59.8069\n",
      "Epoch 159/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 5.1661 - mean_squared_error: 5.1661 - val_loss: 55.6618 - val_mean_squared_error: 55.6618\n",
      "Epoch 160/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 4.9635 - mean_squared_error: 4.9635 - val_loss: 54.0788 - val_mean_squared_error: 54.0788\n",
      "Epoch 161/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 5.0038 - mean_squared_error: 5.0038 - val_loss: 46.5218 - val_mean_squared_error: 46.5218\n",
      "Epoch 162/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 4.9038 - mean_squared_error: 4.9038 - val_loss: 46.6618 - val_mean_squared_error: 46.6618\n",
      "Epoch 163/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 4.7253 - mean_squared_error: 4.7253 - val_loss: 49.7542 - val_mean_squared_error: 49.7542\n",
      "Epoch 164/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 4.5470 - mean_squared_error: 4.5470 - val_loss: 44.5483 - val_mean_squared_error: 44.5483\n",
      "Epoch 165/200\n",
      "1819/1819 [==============================] - 6s 4ms/sample - loss: 4.4766 - mean_squared_error: 4.4766 - val_loss: 39.2914 - val_mean_squared_error: 39.2914\n",
      "Epoch 166/200\n",
      "1819/1819 [==============================] - 8s 4ms/sample - loss: 4.4404 - mean_squared_error: 4.4404 - val_loss: 36.4420 - val_mean_squared_error: 36.4420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 4.3332 - mean_squared_error: 4.3332 - val_loss: 33.6203 - val_mean_squared_error: 33.6203\n",
      "Epoch 168/200\n",
      "1819/1819 [==============================] - 6s 4ms/sample - loss: 4.1648 - mean_squared_error: 4.1648 - val_loss: 35.2013 - val_mean_squared_error: 35.2013\n",
      "Epoch 169/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 4.0834 - mean_squared_error: 4.0834 - val_loss: 31.2787 - val_mean_squared_error: 31.2787\n",
      "Epoch 170/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 4.0611 - mean_squared_error: 4.0611 - val_loss: 27.5671 - val_mean_squared_error: 27.5671\n",
      "Epoch 171/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 3.9753 - mean_squared_error: 3.9753 - val_loss: 27.4303 - val_mean_squared_error: 27.4303\n",
      "Epoch 172/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 3.8701 - mean_squared_error: 3.8701 - val_loss: 21.4731 - val_mean_squared_error: 21.4731\n",
      "Epoch 173/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 3.7150 - mean_squared_error: 3.7150 - val_loss: 25.5955 - val_mean_squared_error: 25.5955\n",
      "Epoch 174/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 3.6914 - mean_squared_error: 3.6914 - val_loss: 20.3596 - val_mean_squared_error: 20.3596\n",
      "Epoch 175/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 3.5464 - mean_squared_error: 3.5464 - val_loss: 21.3558 - val_mean_squared_error: 21.3558\n",
      "Epoch 176/200\n",
      "1819/1819 [==============================] - 6s 4ms/sample - loss: 3.4231 - mean_squared_error: 3.4231 - val_loss: 20.8149 - val_mean_squared_error: 20.8149\n",
      "Epoch 177/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 3.4049 - mean_squared_error: 3.4049 - val_loss: 18.0309 - val_mean_squared_error: 18.0309\n",
      "Epoch 178/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 3.3310 - mean_squared_error: 3.3310 - val_loss: 17.0385 - val_mean_squared_error: 17.0385\n",
      "Epoch 179/200\n",
      "1819/1819 [==============================] - 6s 3ms/sample - loss: 3.3023 - mean_squared_error: 3.3023 - val_loss: 15.6950 - val_mean_squared_error: 15.6950\n"
     ]
    }
   ],
   "source": [
    "# Redefine optimizer list to just focus on adam and sgd\n",
    "opt_list = {'adam':adam}\n",
    "\n",
    "# Use an early stopping callback and our timing callback\n",
    "early_stop = callbacks.EarlyStopping(monitor='val_loss', min_delta=0.1,\n",
    "                              patience=100, mode='auto')\n",
    "time_callback = TimeHistory()\n",
    "\n",
    "# Initialize a new data frame to hold our output data\n",
    "cnn_dropout_df = pd.DataFrame()\n",
    "\n",
    "# Create a list of initial dropout values and steps to increase\n",
    "dropouts = [(0.00,0.05), (0.0,0.1),\n",
    "            (0.05,0.05), (0.05,0.1),\n",
    "            (0.10,0.05), (0.10,0.1)]\n",
    "\n",
    "for opt_name, opt in opt_list.items():\n",
    "    for d in dropouts:\n",
    "        model = create_dropout_cnn_model(d[0], d[1])\n",
    "        model.compile(\n",
    "              optimizer=opt,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mean_squared_error'])\n",
    "        history = model.fit(\n",
    "            X.astype(np.float32), y.astype(np.float32),\n",
    "            epochs=200,\n",
    "            validation_split=0.15, callbacks=[time_callback, early_stop])\n",
    "        times = time_callback.times\n",
    "\n",
    "        # Convert to dataframe\n",
    "        hist = pd.DataFrame(history.history)\n",
    "        hist['epoch'] = history.epoch\n",
    "        hist['RMSE'] = np.sqrt(hist.mean_squared_error)\n",
    "        hist['val_RMSE'] = np.sqrt(hist.val_mean_squared_error)\n",
    "        hist['times'] = times\n",
    "        hist['starting_filter'] = 16\n",
    "        hist['layers'] = 3\n",
    "        hist['pooling'] = 'yes'\n",
    "        hist['fc_layer'] = 500\n",
    "        hist['activation'] = 'relu'\n",
    "        hist['optimizer'] = opt_name\n",
    "        hist['lrate'] = opt.get_config()['learning_rate']\n",
    "        hist['dropout_initial'] = d[0]\n",
    "        hist['dropout_step'] = d[1]\n",
    "\n",
    "        # Keep concatenating to dataframe\n",
    "        cnn_dropout_df = pd.concat([cnn_dropout_df,hist])\n",
    "\n",
    "        # Re-pickle after every model to retain progress\n",
    "        cnn_dropout_df.to_pickle(\"OutputData/cnn_dropout_step_df.pkl\")\n",
    "\n",
    "        # Save models.\n",
    "        filename = \"cnn_dropout_model_{}_d{}_s{}\".format(opt_name, d[0], d[1])\n",
    "        model.save(\"Models/\"+filename+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batchnorm_cnn_model(start_filter, d, step, bias):\n",
    "    '''\n",
    "    Simple function that retruns a keras cnn model \n",
    "    '''\n",
    "    cnn_model = tf.keras.models.Sequential()\n",
    "    cnn_model.add(tf.keras.layers.InputLayer(input_shape=(96, 96, 1)))\n",
    "    if bias:\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter, (3, 3), padding='valid', activation='relu'))\n",
    "    else:\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter, (3, 3), use_bias=False, \n",
    "                                             padding='valid', activation='relu'))    \n",
    "    cnn_model.add(layers.BatchNormalization())\n",
    "    cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    cnn_model.add(tf.keras.layers.Dropout(d))\n",
    "    if bias:\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter*2, (2, 2), padding='valid', activation='relu'))\n",
    "    else:\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter*2, (2, 2), use_bias=False, \n",
    "                                             padding='valid', activation='relu'))\n",
    "        \n",
    "    cnn_model.add(layers.BatchNormalization())\n",
    "    cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    cnn_model.add(tf.keras.layers.Dropout(d+step))\n",
    "    if bias:\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter*4, (2, 2), padding='valid', activation='relu'))\n",
    "    else:\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter*4, (2, 2), use_bias=False, \n",
    "                                             padding='valid', activation='relu'))\n",
    "    cnn_model.add(layers.BatchNormalization())\n",
    "    cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    cnn_model.add(tf.keras.layers.Dropout(d+2*step))\n",
    "    cnn_model.add(tf.keras.layers.Flatten())\n",
    "    cnn_model.add(tf.keras.layers.Dense(500))\n",
    "    cnn_model.add(layers.BatchNormalization())\n",
    "    cnn_model.add(tf.keras.layers.Dropout(d+3*step))\n",
    "    cnn_model.add(tf.keras.layers.Activation('relu'))\n",
    "    cnn_model.add(tf.keras.layers.Dense(500))\n",
    "    cnn_model.add(layers.BatchNormalization())\n",
    "    cnn_model.add(tf.keras.layers.Activation('relu'))\n",
    "    cnn_model.add(tf.keras.layers.Dense(30))\n",
    "    cnn_model.add(tf.keras.layers.Activation('linear'))\n",
    "\n",
    "    print(50*\"=\")\n",
    "    print(cnn_model.summary())\n",
    "    print(50*\"=\")\n",
    "    \n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_117 (Conv2D)          (None, 94, 94, 16)        144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 94, 94, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_117 (MaxPoolin (None, 47, 47, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_116 (Dropout)        (None, 47, 47, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_118 (Conv2D)          (None, 46, 46, 32)        2048      \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 46, 46, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_118 (MaxPoolin (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_117 (Dropout)        (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_119 (Conv2D)          (None, 22, 22, 64)        8192      \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 22, 22, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_119 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_118 (Dropout)        (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_39 (Flatten)         (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 500)               3872500   \n",
      "_________________________________________________________________\n",
      "batch_normalization_68 (Batc (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "dropout_119 (Dropout)        (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_69 (Batc (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 30)                15030     \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 30)                0         \n",
      "=================================================================\n",
      "Total params: 4,152,862\n",
      "Trainable params: 4,150,638\n",
      "Non-trainable params: 2,224\n",
      "_________________________________________________________________\n",
      "None\n",
      "==================================================\n",
      "Train on 1819 samples, validate on 321 samples\n",
      "Epoch 1/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 663.3386 - mean_squared_error: 663.3388 - val_loss: 107.4095 - val_mean_squared_error: 107.4094\n",
      "Epoch 2/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 23.8741 - mean_squared_error: 23.8741 - val_loss: 175.7807 - val_mean_squared_error: 175.7807\n",
      "Epoch 3/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 18.9288 - mean_squared_error: 18.9288 - val_loss: 58.4164 - val_mean_squared_error: 58.4164\n",
      "Epoch 4/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 17.3203 - mean_squared_error: 17.3203 - val_loss: 45.7055 - val_mean_squared_error: 45.7055\n",
      "Epoch 5/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 16.9946 - mean_squared_error: 16.9946 - val_loss: 19.7171 - val_mean_squared_error: 19.7171\n",
      "Epoch 6/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 14.7737 - mean_squared_error: 14.7737 - val_loss: 11.1622 - val_mean_squared_error: 11.1622\n",
      "Epoch 7/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 15.3124 - mean_squared_error: 15.3124 - val_loss: 10.6596 - val_mean_squared_error: 10.6596\n",
      "Epoch 8/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 13.9665 - mean_squared_error: 13.9665 - val_loss: 10.2236 - val_mean_squared_error: 10.2236\n",
      "Epoch 9/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 13.3353 - mean_squared_error: 13.3353 - val_loss: 14.1321 - val_mean_squared_error: 14.1321\n",
      "Epoch 10/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 13.1182 - mean_squared_error: 13.1182 - val_loss: 12.3751 - val_mean_squared_error: 12.3751\n",
      "Epoch 11/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 13.1289 - mean_squared_error: 13.1289 - val_loss: 10.1744 - val_mean_squared_error: 10.1744\n",
      "Epoch 12/200\n",
      "1819/1819 [==============================] - 15s 8ms/sample - loss: 12.4863 - mean_squared_error: 12.4863 - val_loss: 9.8398 - val_mean_squared_error: 9.8398\n",
      "Epoch 13/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 10.9293 - mean_squared_error: 10.9293 - val_loss: 10.0396 - val_mean_squared_error: 10.0396\n",
      "Epoch 14/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 11.3864 - mean_squared_error: 11.3864 - val_loss: 9.7219 - val_mean_squared_error: 9.7219\n",
      "Epoch 15/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 10.8215 - mean_squared_error: 10.8215 - val_loss: 9.9697 - val_mean_squared_error: 9.9697\n",
      "Epoch 16/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 10.0852 - mean_squared_error: 10.0852 - val_loss: 9.2357 - val_mean_squared_error: 9.2357\n",
      "Epoch 17/200\n",
      "1819/1819 [==============================] - 15s 8ms/sample - loss: 9.6100 - mean_squared_error: 9.6100 - val_loss: 9.8540 - val_mean_squared_error: 9.8540\n",
      "Epoch 18/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 9.4897 - mean_squared_error: 9.4897 - val_loss: 9.6632 - val_mean_squared_error: 9.6632\n",
      "Epoch 19/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 9.5885 - mean_squared_error: 9.5885 - val_loss: 8.6941 - val_mean_squared_error: 8.6941\n",
      "Epoch 20/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 8.9742 - mean_squared_error: 8.9742 - val_loss: 10.5127 - val_mean_squared_error: 10.5127\n",
      "Epoch 21/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 8.6823 - mean_squared_error: 8.6823 - val_loss: 10.6162 - val_mean_squared_error: 10.6162\n",
      "Epoch 22/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 8.4623 - mean_squared_error: 8.4623 - val_loss: 9.3820 - val_mean_squared_error: 9.3820\n",
      "Epoch 23/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 7.6418 - mean_squared_error: 7.6418 - val_loss: 11.0093 - val_mean_squared_error: 11.0093\n",
      "Epoch 24/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 7.8012 - mean_squared_error: 7.8012 - val_loss: 7.1561 - val_mean_squared_error: 7.1561\n",
      "Epoch 25/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 6.9319 - mean_squared_error: 6.9319 - val_loss: 7.9181 - val_mean_squared_error: 7.9181\n",
      "Epoch 26/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 6.7985 - mean_squared_error: 6.7985 - val_loss: 7.1116 - val_mean_squared_error: 7.1116\n",
      "Epoch 27/200\n",
      "1819/1819 [==============================] - 15s 8ms/sample - loss: 6.7011 - mean_squared_error: 6.7011 - val_loss: 6.4806 - val_mean_squared_error: 6.4806\n",
      "Epoch 28/200\n",
      "1819/1819 [==============================] - 15s 8ms/sample - loss: 6.0584 - mean_squared_error: 6.0584 - val_loss: 7.2077 - val_mean_squared_error: 7.2077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200\n",
      "1819/1819 [==============================] - 15s 8ms/sample - loss: 6.1459 - mean_squared_error: 6.1459 - val_loss: 6.3618 - val_mean_squared_error: 6.3618\n",
      "Epoch 30/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 5.8898 - mean_squared_error: 5.8898 - val_loss: 6.0879 - val_mean_squared_error: 6.0879\n",
      "Epoch 31/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 5.5816 - mean_squared_error: 5.5816 - val_loss: 7.3203 - val_mean_squared_error: 7.3203\n",
      "Epoch 32/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 5.4632 - mean_squared_error: 5.4632 - val_loss: 5.3745 - val_mean_squared_error: 5.3745\n",
      "Epoch 33/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 5.1318 - mean_squared_error: 5.1318 - val_loss: 5.5448 - val_mean_squared_error: 5.5448\n",
      "Epoch 34/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 5.0993 - mean_squared_error: 5.0993 - val_loss: 6.6891 - val_mean_squared_error: 6.6891\n",
      "Epoch 35/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 4.6376 - mean_squared_error: 4.6376 - val_loss: 5.0146 - val_mean_squared_error: 5.0146\n",
      "Epoch 36/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 4.4701 - mean_squared_error: 4.4701 - val_loss: 5.6281 - val_mean_squared_error: 5.6281\n",
      "Epoch 37/200\n",
      "1819/1819 [==============================] - 15s 8ms/sample - loss: 4.3016 - mean_squared_error: 4.3016 - val_loss: 5.4667 - val_mean_squared_error: 5.4667\n",
      "Epoch 38/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 4.1924 - mean_squared_error: 4.1924 - val_loss: 5.9708 - val_mean_squared_error: 5.9708\n",
      "Epoch 39/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 3.9840 - mean_squared_error: 3.9840 - val_loss: 5.0601 - val_mean_squared_error: 5.0601\n",
      "Epoch 40/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 4.0355 - mean_squared_error: 4.0355 - val_loss: 4.7079 - val_mean_squared_error: 4.7079\n",
      "Epoch 41/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 3.9883 - mean_squared_error: 3.9883 - val_loss: 4.7120 - val_mean_squared_error: 4.7120\n",
      "Epoch 42/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 4.0078 - mean_squared_error: 4.0078 - val_loss: 4.1314 - val_mean_squared_error: 4.1314\n",
      "Epoch 43/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 3.9915 - mean_squared_error: 3.9915 - val_loss: 4.2523 - val_mean_squared_error: 4.2523\n",
      "Epoch 44/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 3.8618 - mean_squared_error: 3.8618 - val_loss: 4.3068 - val_mean_squared_error: 4.3068\n",
      "Epoch 45/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 3.3776 - mean_squared_error: 3.3776 - val_loss: 3.8494 - val_mean_squared_error: 3.8494\n",
      "Epoch 46/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 3.4822 - mean_squared_error: 3.4822 - val_loss: 4.0430 - val_mean_squared_error: 4.0430\n",
      "Epoch 47/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 3.3137 - mean_squared_error: 3.3137 - val_loss: 4.1378 - val_mean_squared_error: 4.1378\n",
      "Epoch 48/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 3.3124 - mean_squared_error: 3.3124 - val_loss: 4.6791 - val_mean_squared_error: 4.6791\n",
      "Epoch 49/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 3.1458 - mean_squared_error: 3.1458 - val_loss: 3.8778 - val_mean_squared_error: 3.8778\n",
      "Epoch 50/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 3.2341 - mean_squared_error: 3.2341 - val_loss: 3.7052 - val_mean_squared_error: 3.7052\n",
      "Epoch 51/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 3.2170 - mean_squared_error: 3.2170 - val_loss: 4.6903 - val_mean_squared_error: 4.6903\n",
      "Epoch 52/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 3.1967 - mean_squared_error: 3.1967 - val_loss: 3.4468 - val_mean_squared_error: 3.4468\n",
      "Epoch 53/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 3.0034 - mean_squared_error: 3.0034 - val_loss: 3.5947 - val_mean_squared_error: 3.5947\n",
      "Epoch 54/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 3.0958 - mean_squared_error: 3.0958 - val_loss: 3.5910 - val_mean_squared_error: 3.5910\n",
      "Epoch 55/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.8896 - mean_squared_error: 2.8896 - val_loss: 3.6664 - val_mean_squared_error: 3.6664\n",
      "Epoch 56/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.9436 - mean_squared_error: 2.9436 - val_loss: 3.2872 - val_mean_squared_error: 3.2872\n",
      "Epoch 57/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 2.8911 - mean_squared_error: 2.8911 - val_loss: 3.6707 - val_mean_squared_error: 3.6707\n",
      "Epoch 58/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 2.7308 - mean_squared_error: 2.7308 - val_loss: 4.3738 - val_mean_squared_error: 4.3738\n",
      "Epoch 59/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 2.7424 - mean_squared_error: 2.7424 - val_loss: 3.7766 - val_mean_squared_error: 3.7766\n",
      "Epoch 60/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 2.6671 - mean_squared_error: 2.6671 - val_loss: 3.4106 - val_mean_squared_error: 3.4106\n",
      "Epoch 61/200\n",
      "1819/1819 [==============================] - 15s 8ms/sample - loss: 2.8846 - mean_squared_error: 2.8846 - val_loss: 4.1006 - val_mean_squared_error: 4.1006\n",
      "Epoch 62/200\n",
      "1819/1819 [==============================] - 15s 8ms/sample - loss: 2.6004 - mean_squared_error: 2.6004 - val_loss: 3.2209 - val_mean_squared_error: 3.2209\n",
      "Epoch 63/200\n",
      "1819/1819 [==============================] - 17s 9ms/sample - loss: 2.6927 - mean_squared_error: 2.6927 - val_loss: 3.4436 - val_mean_squared_error: 3.4436\n",
      "Epoch 64/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 2.6411 - mean_squared_error: 2.6411 - val_loss: 4.1728 - val_mean_squared_error: 4.1728\n",
      "Epoch 65/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.5959 - mean_squared_error: 2.5959 - val_loss: 3.5102 - val_mean_squared_error: 3.5102\n",
      "Epoch 66/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.6018 - mean_squared_error: 2.6018 - val_loss: 3.0210 - val_mean_squared_error: 3.0210\n",
      "Epoch 67/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 2.5164 - mean_squared_error: 2.5164 - val_loss: 3.1737 - val_mean_squared_error: 3.1737\n",
      "Epoch 68/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 2.5126 - mean_squared_error: 2.5126 - val_loss: 3.1491 - val_mean_squared_error: 3.1491\n",
      "Epoch 69/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.5471 - mean_squared_error: 2.5471 - val_loss: 3.0296 - val_mean_squared_error: 3.0296\n",
      "Epoch 70/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.3133 - mean_squared_error: 2.3133 - val_loss: 3.3711 - val_mean_squared_error: 3.3711\n",
      "Epoch 71/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.2732 - mean_squared_error: 2.2732 - val_loss: 3.2096 - val_mean_squared_error: 3.2096\n",
      "Epoch 72/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.2980 - mean_squared_error: 2.2980 - val_loss: 3.2969 - val_mean_squared_error: 3.2969\n",
      "Epoch 73/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.4482 - mean_squared_error: 2.4482 - val_loss: 4.3260 - val_mean_squared_error: 4.3260\n",
      "Epoch 74/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.4150 - mean_squared_error: 2.4150 - val_loss: 4.1251 - val_mean_squared_error: 4.1251\n",
      "Epoch 75/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.3671 - mean_squared_error: 2.3671 - val_loss: 3.6783 - val_mean_squared_error: 3.6783\n",
      "Epoch 76/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.2671 - mean_squared_error: 2.2671 - val_loss: 3.2629 - val_mean_squared_error: 3.2629\n",
      "Epoch 77/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 2.2542 - mean_squared_error: 2.2542 - val_loss: 3.4350 - val_mean_squared_error: 3.4350\n",
      "Epoch 78/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 2.1691 - mean_squared_error: 2.1691 - val_loss: 4.6016 - val_mean_squared_error: 4.6016\n",
      "Epoch 79/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 2.1094 - mean_squared_error: 2.1094 - val_loss: 3.0341 - val_mean_squared_error: 3.0341\n",
      "Epoch 80/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 2.2077 - mean_squared_error: 2.2077 - val_loss: 3.3791 - val_mean_squared_error: 3.3791\n",
      "Epoch 81/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 2.1367 - mean_squared_error: 2.1367 - val_loss: 3.3082 - val_mean_squared_error: 3.3082\n",
      "Epoch 82/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 2.0049 - mean_squared_error: 2.0049 - val_loss: 2.9148 - val_mean_squared_error: 2.9148\n",
      "Epoch 83/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.9691 - mean_squared_error: 1.9691 - val_loss: 3.5392 - val_mean_squared_error: 3.5392\n",
      "Epoch 84/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 2.1274 - mean_squared_error: 2.1274 - val_loss: 3.4330 - val_mean_squared_error: 3.4330\n",
      "Epoch 85/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.8439 - mean_squared_error: 1.8439 - val_loss: 2.9296 - val_mean_squared_error: 2.9296\n",
      "Epoch 86/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.9931 - mean_squared_error: 1.9931 - val_loss: 2.8600 - val_mean_squared_error: 2.8600\n",
      "Epoch 87/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 2.0729 - mean_squared_error: 2.0729 - val_loss: 2.7361 - val_mean_squared_error: 2.7361\n",
      "Epoch 88/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.9106 - mean_squared_error: 1.9106 - val_loss: 2.7611 - val_mean_squared_error: 2.7611\n",
      "Epoch 89/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.0521 - mean_squared_error: 2.0521 - val_loss: 3.0465 - val_mean_squared_error: 3.0465\n",
      "Epoch 90/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.9559 - mean_squared_error: 1.9559 - val_loss: 2.9039 - val_mean_squared_error: 2.9039\n",
      "Epoch 91/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.9613 - mean_squared_error: 1.9613 - val_loss: 2.8049 - val_mean_squared_error: 2.8049\n",
      "Epoch 92/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 2.1027 - mean_squared_error: 2.1027 - val_loss: 2.6752 - val_mean_squared_error: 2.6752\n",
      "Epoch 93/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.9674 - mean_squared_error: 1.9674 - val_loss: 2.7354 - val_mean_squared_error: 2.7354\n",
      "Epoch 94/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 1.9312 - mean_squared_error: 1.9312 - val_loss: 2.8997 - val_mean_squared_error: 2.8997\n",
      "Epoch 95/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.8252 - mean_squared_error: 1.8252 - val_loss: 2.7446 - val_mean_squared_error: 2.7446\n",
      "Epoch 96/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.7461 - mean_squared_error: 1.7461 - val_loss: 2.6877 - val_mean_squared_error: 2.6877\n",
      "Epoch 97/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.8838 - mean_squared_error: 1.8838 - val_loss: 3.1060 - val_mean_squared_error: 3.1060\n",
      "Epoch 98/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.8459 - mean_squared_error: 1.8459 - val_loss: 2.7422 - val_mean_squared_error: 2.7422\n",
      "Epoch 99/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 1.7514 - mean_squared_error: 1.7514 - val_loss: 2.9267 - val_mean_squared_error: 2.9267\n",
      "Epoch 100/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 1.7687 - mean_squared_error: 1.7687 - val_loss: 2.7424 - val_mean_squared_error: 2.7424\n",
      "Epoch 101/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.8953 - mean_squared_error: 1.8953 - val_loss: 3.3205 - val_mean_squared_error: 3.3205\n",
      "Epoch 102/200\n",
      "1819/1819 [==============================] - 16s 9ms/sample - loss: 1.8184 - mean_squared_error: 1.8184 - val_loss: 2.9626 - val_mean_squared_error: 2.9626\n",
      "Epoch 103/200\n",
      "1819/1819 [==============================] - 17s 9ms/sample - loss: 1.7993 - mean_squared_error: 1.7993 - val_loss: 2.8443 - val_mean_squared_error: 2.8443\n",
      "Epoch 104/200\n",
      "1819/1819 [==============================] - 15s 8ms/sample - loss: 1.7857 - mean_squared_error: 1.7857 - val_loss: 3.2351 - val_mean_squared_error: 3.2351\n",
      "Epoch 105/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 1.9055 - mean_squared_error: 1.9055 - val_loss: 2.6373 - val_mean_squared_error: 2.6373\n",
      "Epoch 106/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.7437 - mean_squared_error: 1.7437 - val_loss: 2.5791 - val_mean_squared_error: 2.5791\n",
      "Epoch 107/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.5996 - mean_squared_error: 1.5996 - val_loss: 2.5325 - val_mean_squared_error: 2.5325\n",
      "Epoch 108/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.7001 - mean_squared_error: 1.7001 - val_loss: 2.8086 - val_mean_squared_error: 2.8086\n",
      "Epoch 109/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.6149 - mean_squared_error: 1.6149 - val_loss: 3.1310 - val_mean_squared_error: 3.1310\n",
      "Epoch 110/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.7597 - mean_squared_error: 1.7597 - val_loss: 2.8008 - val_mean_squared_error: 2.8008\n",
      "Epoch 111/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.7044 - mean_squared_error: 1.7044 - val_loss: 2.4592 - val_mean_squared_error: 2.4592\n",
      "Epoch 112/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.6336 - mean_squared_error: 1.6336 - val_loss: 2.5849 - val_mean_squared_error: 2.5849\n",
      "Epoch 113/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.6680 - mean_squared_error: 1.6680 - val_loss: 2.6086 - val_mean_squared_error: 2.6086\n",
      "Epoch 114/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 1.6135 - mean_squared_error: 1.6135 - val_loss: 2.6710 - val_mean_squared_error: 2.6710\n",
      "Epoch 115/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.5342 - mean_squared_error: 1.5342 - val_loss: 2.7267 - val_mean_squared_error: 2.7267\n",
      "Epoch 116/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.6535 - mean_squared_error: 1.6535 - val_loss: 2.6779 - val_mean_squared_error: 2.6779\n",
      "Epoch 117/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.5792 - mean_squared_error: 1.5792 - val_loss: 2.4271 - val_mean_squared_error: 2.4271\n",
      "Epoch 118/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.5826 - mean_squared_error: 1.5826 - val_loss: 3.0989 - val_mean_squared_error: 3.0989\n",
      "Epoch 119/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.8727 - mean_squared_error: 1.8727 - val_loss: 3.2111 - val_mean_squared_error: 3.2111\n",
      "Epoch 120/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.6762 - mean_squared_error: 1.6762 - val_loss: 2.5585 - val_mean_squared_error: 2.5585\n",
      "Epoch 121/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.5181 - mean_squared_error: 1.5181 - val_loss: 2.5835 - val_mean_squared_error: 2.5835\n",
      "Epoch 122/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.4667 - mean_squared_error: 1.4667 - val_loss: 2.5206 - val_mean_squared_error: 2.5206\n",
      "Epoch 123/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.4980 - mean_squared_error: 1.4980 - val_loss: 2.8080 - val_mean_squared_error: 2.8080\n",
      "Epoch 124/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.6404 - mean_squared_error: 1.6404 - val_loss: 2.6309 - val_mean_squared_error: 2.6309\n",
      "Epoch 125/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.4903 - mean_squared_error: 1.4903 - val_loss: 2.7581 - val_mean_squared_error: 2.7581\n",
      "Epoch 126/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.5644 - mean_squared_error: 1.5644 - val_loss: 2.5363 - val_mean_squared_error: 2.5363\n",
      "Epoch 127/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.4187 - mean_squared_error: 1.4187 - val_loss: 2.4087 - val_mean_squared_error: 2.4087\n",
      "Epoch 128/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.4984 - mean_squared_error: 1.4984 - val_loss: 2.5245 - val_mean_squared_error: 2.5245\n",
      "Epoch 129/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.4774 - mean_squared_error: 1.4774 - val_loss: 2.5054 - val_mean_squared_error: 2.5054\n",
      "Epoch 130/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.5669 - mean_squared_error: 1.5669 - val_loss: 3.0054 - val_mean_squared_error: 3.0054\n",
      "Epoch 131/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.5138 - mean_squared_error: 1.5138 - val_loss: 2.7352 - val_mean_squared_error: 2.7352\n",
      "Epoch 132/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.4937 - mean_squared_error: 1.4937 - val_loss: 2.5541 - val_mean_squared_error: 2.5541\n",
      "Epoch 133/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 1.3996 - mean_squared_error: 1.3996 - val_loss: 2.4597 - val_mean_squared_error: 2.4597\n",
      "Epoch 134/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.4618 - mean_squared_error: 1.4618 - val_loss: 2.9607 - val_mean_squared_error: 2.9607\n",
      "Epoch 135/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.3998 - mean_squared_error: 1.3998 - val_loss: 2.4521 - val_mean_squared_error: 2.4521\n",
      "Epoch 136/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.4942 - mean_squared_error: 1.4942 - val_loss: 2.6327 - val_mean_squared_error: 2.6327\n",
      "Epoch 137/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.4060 - mean_squared_error: 1.4060 - val_loss: 2.4069 - val_mean_squared_error: 2.4069\n",
      "Epoch 138/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.3727 - mean_squared_error: 1.3727 - val_loss: 2.6781 - val_mean_squared_error: 2.6781\n",
      "Epoch 139/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.4436 - mean_squared_error: 1.4436 - val_loss: 3.1982 - val_mean_squared_error: 3.1982\n",
      "Epoch 140/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.5868 - mean_squared_error: 1.5868 - val_loss: 2.8658 - val_mean_squared_error: 2.8658\n",
      "Epoch 141/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.6458 - mean_squared_error: 1.6458 - val_loss: 2.5016 - val_mean_squared_error: 2.5016\n",
      "Epoch 142/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.4188 - mean_squared_error: 1.4188 - val_loss: 2.4797 - val_mean_squared_error: 2.4797\n",
      "Epoch 143/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.3760 - mean_squared_error: 1.3760 - val_loss: 2.6262 - val_mean_squared_error: 2.6262\n",
      "Epoch 144/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.3088 - mean_squared_error: 1.3088 - val_loss: 2.5348 - val_mean_squared_error: 2.5348\n",
      "Epoch 145/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.3618 - mean_squared_error: 1.3618 - val_loss: 2.7893 - val_mean_squared_error: 2.7893\n",
      "Epoch 146/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.5122 - mean_squared_error: 1.5122 - val_loss: 3.1623 - val_mean_squared_error: 3.1623\n",
      "Epoch 147/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.4672 - mean_squared_error: 1.4672 - val_loss: 2.5702 - val_mean_squared_error: 2.5702\n",
      "Epoch 148/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.3528 - mean_squared_error: 1.3528 - val_loss: 2.7382 - val_mean_squared_error: 2.7382\n",
      "Epoch 149/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.2826 - mean_squared_error: 1.2826 - val_loss: 2.5257 - val_mean_squared_error: 2.5257\n",
      "Epoch 150/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.2539 - mean_squared_error: 1.2539 - val_loss: 2.5385 - val_mean_squared_error: 2.5385\n",
      "Epoch 151/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.3210 - mean_squared_error: 1.3210 - val_loss: 2.6686 - val_mean_squared_error: 2.6686\n",
      "Epoch 152/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.3562 - mean_squared_error: 1.3562 - val_loss: 2.6361 - val_mean_squared_error: 2.6361\n",
      "Epoch 153/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.2030 - mean_squared_error: 1.2030 - val_loss: 2.8254 - val_mean_squared_error: 2.8254\n",
      "Epoch 154/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.2858 - mean_squared_error: 1.2858 - val_loss: 2.4673 - val_mean_squared_error: 2.4673\n",
      "Epoch 155/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.4834 - mean_squared_error: 1.4834 - val_loss: 2.4877 - val_mean_squared_error: 2.4877\n",
      "Epoch 156/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.2799 - mean_squared_error: 1.2799 - val_loss: 2.3733 - val_mean_squared_error: 2.3733\n",
      "Epoch 157/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.2306 - mean_squared_error: 1.2306 - val_loss: 2.5184 - val_mean_squared_error: 2.5184\n",
      "Epoch 158/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.2983 - mean_squared_error: 1.2983 - val_loss: 2.6346 - val_mean_squared_error: 2.6346\n",
      "Epoch 159/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.2302 - mean_squared_error: 1.2302 - val_loss: 2.4530 - val_mean_squared_error: 2.4530\n",
      "Epoch 160/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.2408 - mean_squared_error: 1.2408 - val_loss: 2.5680 - val_mean_squared_error: 2.5680\n",
      "Epoch 161/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.2916 - mean_squared_error: 1.2916 - val_loss: 2.5543 - val_mean_squared_error: 2.5543\n",
      "Epoch 162/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.3512 - mean_squared_error: 1.3512 - val_loss: 2.8269 - val_mean_squared_error: 2.8269\n",
      "Epoch 163/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.2512 - mean_squared_error: 1.2512 - val_loss: 2.6422 - val_mean_squared_error: 2.6422\n",
      "Epoch 164/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.2316 - mean_squared_error: 1.2316 - val_loss: 2.3316 - val_mean_squared_error: 2.3316\n",
      "Epoch 165/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 1.2055 - mean_squared_error: 1.2055 - val_loss: 2.6268 - val_mean_squared_error: 2.6268\n",
      "Epoch 166/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.2299 - mean_squared_error: 1.2299 - val_loss: 2.4140 - val_mean_squared_error: 2.4140\n",
      "Epoch 167/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.2096 - mean_squared_error: 1.2096 - val_loss: 2.6487 - val_mean_squared_error: 2.6487\n",
      "Epoch 168/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.1590 - mean_squared_error: 1.1590 - val_loss: 2.4361 - val_mean_squared_error: 2.4361\n",
      "Epoch 169/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.2764 - mean_squared_error: 1.2764 - val_loss: 2.4959 - val_mean_squared_error: 2.4959\n",
      "Epoch 170/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.2630 - mean_squared_error: 1.2630 - val_loss: 2.4702 - val_mean_squared_error: 2.4702\n",
      "Epoch 171/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.1840 - mean_squared_error: 1.1840 - val_loss: 2.4059 - val_mean_squared_error: 2.4059\n",
      "Epoch 172/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.2442 - mean_squared_error: 1.2442 - val_loss: 2.3476 - val_mean_squared_error: 2.3476\n",
      "Epoch 173/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 1.1648 - mean_squared_error: 1.1648 - val_loss: 2.3543 - val_mean_squared_error: 2.3543\n",
      "Epoch 174/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.1675 - mean_squared_error: 1.1675 - val_loss: 2.3765 - val_mean_squared_error: 2.3765\n",
      "Epoch 175/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.2428 - mean_squared_error: 1.2428 - val_loss: 2.8836 - val_mean_squared_error: 2.8836\n",
      "Epoch 176/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.2980 - mean_squared_error: 1.2980 - val_loss: 2.3904 - val_mean_squared_error: 2.3904\n",
      "Epoch 177/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.1377 - mean_squared_error: 1.1377 - val_loss: 2.5066 - val_mean_squared_error: 2.5066\n",
      "Epoch 178/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.1523 - mean_squared_error: 1.1523 - val_loss: 2.6538 - val_mean_squared_error: 2.6538\n",
      "Epoch 179/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.2198 - mean_squared_error: 1.2198 - val_loss: 2.5107 - val_mean_squared_error: 2.5107\n",
      "Epoch 180/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.2030 - mean_squared_error: 1.2030 - val_loss: 2.5456 - val_mean_squared_error: 2.5456\n",
      "Epoch 181/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.2968 - mean_squared_error: 1.2968 - val_loss: 2.6648 - val_mean_squared_error: 2.6648\n",
      "Epoch 182/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.2285 - mean_squared_error: 1.2285 - val_loss: 2.8988 - val_mean_squared_error: 2.8988\n",
      "Epoch 183/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.2136 - mean_squared_error: 1.2136 - val_loss: 2.4513 - val_mean_squared_error: 2.4513\n",
      "Epoch 184/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.3003 - mean_squared_error: 1.3003 - val_loss: 2.7816 - val_mean_squared_error: 2.7816\n",
      "Epoch 185/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.2408 - mean_squared_error: 1.2408 - val_loss: 2.5019 - val_mean_squared_error: 2.5019\n",
      "Epoch 186/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.1951 - mean_squared_error: 1.1951 - val_loss: 2.5749 - val_mean_squared_error: 2.5749\n",
      "Epoch 187/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.2149 - mean_squared_error: 1.2149 - val_loss: 2.5155 - val_mean_squared_error: 2.5155\n",
      "Epoch 188/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.1198 - mean_squared_error: 1.1198 - val_loss: 2.3088 - val_mean_squared_error: 2.3088\n",
      "Epoch 189/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.0883 - mean_squared_error: 1.0883 - val_loss: 2.4068 - val_mean_squared_error: 2.4068\n",
      "Epoch 190/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.0436 - mean_squared_error: 1.0436 - val_loss: 2.3723 - val_mean_squared_error: 2.3723\n",
      "Epoch 191/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.0791 - mean_squared_error: 1.0791 - val_loss: 2.5497 - val_mean_squared_error: 2.5497\n",
      "Epoch 192/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.0893 - mean_squared_error: 1.0893 - val_loss: 2.7015 - val_mean_squared_error: 2.7015\n",
      "Epoch 193/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.1404 - mean_squared_error: 1.1404 - val_loss: 2.6240 - val_mean_squared_error: 2.6240\n",
      "Epoch 194/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.1198 - mean_squared_error: 1.1198 - val_loss: 2.3968 - val_mean_squared_error: 2.3968\n",
      "Epoch 195/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.1422 - mean_squared_error: 1.1422 - val_loss: 2.5474 - val_mean_squared_error: 2.5474\n",
      "Epoch 196/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.0900 - mean_squared_error: 1.0900 - val_loss: 2.4326 - val_mean_squared_error: 2.4326\n",
      "Epoch 197/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.0678 - mean_squared_error: 1.0678 - val_loss: 2.4665 - val_mean_squared_error: 2.4665\n",
      "Epoch 198/200\n",
      "1819/1819 [==============================] - 15s 8ms/sample - loss: 1.0346 - mean_squared_error: 1.0346 - val_loss: 2.3138 - val_mean_squared_error: 2.3138\n",
      "Epoch 199/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.0822 - mean_squared_error: 1.0822 - val_loss: 2.4228 - val_mean_squared_error: 2.4228\n",
      "Epoch 200/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.0756 - mean_squared_error: 1.0756 - val_loss: 2.3689 - val_mean_squared_error: 2.3689\n",
      "==================================================\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_120 (Conv2D)          (None, 94, 94, 16)        144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_70 (Batc (None, 94, 94, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_120 (MaxPoolin (None, 47, 47, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_120 (Dropout)        (None, 47, 47, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_121 (Conv2D)          (None, 46, 46, 32)        2048      \n",
      "_________________________________________________________________\n",
      "batch_normalization_71 (Batc (None, 46, 46, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_121 (MaxPoolin (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_121 (Dropout)        (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_122 (Conv2D)          (None, 22, 22, 64)        8192      \n",
      "_________________________________________________________________\n",
      "batch_normalization_72 (Batc (None, 22, 22, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_122 (MaxPoolin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_122 (Dropout)        (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_40 (Flatten)         (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 500)               3872500   \n",
      "_________________________________________________________________\n",
      "batch_normalization_73 (Batc (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "dropout_123 (Dropout)        (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_74 (Batc (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 30)                15030     \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 30)                0         \n",
      "=================================================================\n",
      "Total params: 4,152,862\n",
      "Trainable params: 4,150,638\n",
      "Non-trainable params: 2,224\n",
      "_________________________________________________________________\n",
      "None\n",
      "==================================================\n",
      "Train on 1819 samples, validate on 321 samples\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1819/1819 [==============================] - 17s 10ms/sample - loss: 665.4590 - mean_squared_error: 665.4590 - val_loss: 252.6708 - val_mean_squared_error: 252.6709\n",
      "Epoch 2/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 21.5279 - mean_squared_error: 21.5279 - val_loss: 126.0280 - val_mean_squared_error: 126.0281\n",
      "Epoch 3/200\n",
      "1819/1819 [==============================] - 15s 8ms/sample - loss: 22.0912 - mean_squared_error: 22.0912 - val_loss: 73.8375 - val_mean_squared_error: 73.8375\n",
      "Epoch 4/200\n",
      "1819/1819 [==============================] - 16s 9ms/sample - loss: 19.2183 - mean_squared_error: 19.2183 - val_loss: 40.4066 - val_mean_squared_error: 40.4066\n",
      "Epoch 5/200\n",
      "1819/1819 [==============================] - 15s 8ms/sample - loss: 17.6137 - mean_squared_error: 17.6137 - val_loss: 18.0844 - val_mean_squared_error: 18.0844\n",
      "Epoch 6/200\n",
      "1819/1819 [==============================] - 15s 8ms/sample - loss: 15.9435 - mean_squared_error: 15.9435 - val_loss: 15.3900 - val_mean_squared_error: 15.3900\n",
      "Epoch 7/200\n",
      "1819/1819 [==============================] - 16s 9ms/sample - loss: 16.6106 - mean_squared_error: 16.6106 - val_loss: 11.6911 - val_mean_squared_error: 11.6911\n",
      "Epoch 8/200\n",
      "1819/1819 [==============================] - 15s 8ms/sample - loss: 14.0905 - mean_squared_error: 14.0905 - val_loss: 11.0563 - val_mean_squared_error: 11.0563\n",
      "Epoch 9/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 13.8018 - mean_squared_error: 13.8018 - val_loss: 10.2256 - val_mean_squared_error: 10.2256\n",
      "Epoch 10/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 12.1387 - mean_squared_error: 12.1387 - val_loss: 9.9775 - val_mean_squared_error: 9.9775\n",
      "Epoch 11/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 11.9765 - mean_squared_error: 11.9765 - val_loss: 11.3302 - val_mean_squared_error: 11.3302\n",
      "Epoch 12/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 11.7465 - mean_squared_error: 11.7465 - val_loss: 9.8139 - val_mean_squared_error: 9.8139\n",
      "Epoch 13/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 11.5478 - mean_squared_error: 11.5478 - val_loss: 9.8435 - val_mean_squared_error: 9.8435\n",
      "Epoch 14/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 11.1294 - mean_squared_error: 11.1294 - val_loss: 10.4181 - val_mean_squared_error: 10.4181\n",
      "Epoch 15/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 10.5074 - mean_squared_error: 10.5074 - val_loss: 10.7151 - val_mean_squared_error: 10.7151\n",
      "Epoch 16/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 9.8527 - mean_squared_error: 9.8527 - val_loss: 9.4431 - val_mean_squared_error: 9.4431\n",
      "Epoch 17/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 9.9171 - mean_squared_error: 9.9171 - val_loss: 9.2850 - val_mean_squared_error: 9.2850\n",
      "Epoch 18/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 9.6831 - mean_squared_error: 9.6831 - val_loss: 9.4611 - val_mean_squared_error: 9.4612\n",
      "Epoch 19/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 9.7844 - mean_squared_error: 9.7844 - val_loss: 10.9118 - val_mean_squared_error: 10.9118\n",
      "Epoch 20/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 9.0970 - mean_squared_error: 9.0970 - val_loss: 11.0421 - val_mean_squared_error: 11.0421\n",
      "Epoch 21/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 9.1778 - mean_squared_error: 9.1778 - val_loss: 9.8928 - val_mean_squared_error: 9.8928\n",
      "Epoch 22/200\n",
      "1819/1819 [==============================] - 15s 8ms/sample - loss: 8.6052 - mean_squared_error: 8.6052 - val_loss: 9.0294 - val_mean_squared_error: 9.0294\n",
      "Epoch 23/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 8.1876 - mean_squared_error: 8.1876 - val_loss: 8.7056 - val_mean_squared_error: 8.7056\n",
      "Epoch 24/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 7.8659 - mean_squared_error: 7.8659 - val_loss: 9.6293 - val_mean_squared_error: 9.6293\n",
      "Epoch 25/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 8.1415 - mean_squared_error: 8.1415 - val_loss: 8.9043 - val_mean_squared_error: 8.9043\n",
      "Epoch 26/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 7.4976 - mean_squared_error: 7.4976 - val_loss: 9.5182 - val_mean_squared_error: 9.5182\n",
      "Epoch 27/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 6.8088 - mean_squared_error: 6.8088 - val_loss: 8.0683 - val_mean_squared_error: 8.0683\n",
      "Epoch 28/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 6.5694 - mean_squared_error: 6.5694 - val_loss: 8.3723 - val_mean_squared_error: 8.3723\n",
      "Epoch 29/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 6.3921 - mean_squared_error: 6.3921 - val_loss: 7.6622 - val_mean_squared_error: 7.6622\n",
      "Epoch 30/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 6.3993 - mean_squared_error: 6.3993 - val_loss: 7.9996 - val_mean_squared_error: 7.9996\n",
      "Epoch 31/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 6.2338 - mean_squared_error: 6.2338 - val_loss: 7.6811 - val_mean_squared_error: 7.6811\n",
      "Epoch 32/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 5.8011 - mean_squared_error: 5.8011 - val_loss: 6.2580 - val_mean_squared_error: 6.2580\n",
      "Epoch 33/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 5.3618 - mean_squared_error: 5.3618 - val_loss: 6.3152 - val_mean_squared_error: 6.3152\n",
      "Epoch 34/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 5.4142 - mean_squared_error: 5.4142 - val_loss: 6.2989 - val_mean_squared_error: 6.2989\n",
      "Epoch 35/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 5.2358 - mean_squared_error: 5.2358 - val_loss: 5.3121 - val_mean_squared_error: 5.3121\n",
      "Epoch 36/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 5.1882 - mean_squared_error: 5.1882 - val_loss: 5.4747 - val_mean_squared_error: 5.4747\n",
      "Epoch 37/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 4.7630 - mean_squared_error: 4.7630 - val_loss: 5.5550 - val_mean_squared_error: 5.5550\n",
      "Epoch 38/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 4.5306 - mean_squared_error: 4.5306 - val_loss: 5.1035 - val_mean_squared_error: 5.1035\n",
      "Epoch 39/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 4.7529 - mean_squared_error: 4.7529 - val_loss: 5.7792 - val_mean_squared_error: 5.7792\n",
      "Epoch 40/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 4.3754 - mean_squared_error: 4.3754 - val_loss: 4.5622 - val_mean_squared_error: 4.5622\n",
      "Epoch 41/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 4.3411 - mean_squared_error: 4.3411 - val_loss: 4.3843 - val_mean_squared_error: 4.3843\n",
      "Epoch 42/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 4.0763 - mean_squared_error: 4.0763 - val_loss: 4.5307 - val_mean_squared_error: 4.5307\n",
      "Epoch 43/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 4.0929 - mean_squared_error: 4.0929 - val_loss: 4.8184 - val_mean_squared_error: 4.8184\n",
      "Epoch 44/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 4.0858 - mean_squared_error: 4.0858 - val_loss: 4.9334 - val_mean_squared_error: 4.9334\n",
      "Epoch 45/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 4.0442 - mean_squared_error: 4.0442 - val_loss: 5.0882 - val_mean_squared_error: 5.0882\n",
      "Epoch 46/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 3.8700 - mean_squared_error: 3.8700 - val_loss: 4.2051 - val_mean_squared_error: 4.2051\n",
      "Epoch 47/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 3.7055 - mean_squared_error: 3.7055 - val_loss: 4.1751 - val_mean_squared_error: 4.1751\n",
      "Epoch 48/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 3.8141 - mean_squared_error: 3.8141 - val_loss: 4.8634 - val_mean_squared_error: 4.8634\n",
      "Epoch 49/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 3.8681 - mean_squared_error: 3.8681 - val_loss: 5.1397 - val_mean_squared_error: 5.1397\n",
      "Epoch 50/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 3.4739 - mean_squared_error: 3.4739 - val_loss: 4.0274 - val_mean_squared_error: 4.0274\n",
      "Epoch 51/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 3.7238 - mean_squared_error: 3.7238 - val_loss: 4.2663 - val_mean_squared_error: 4.2663\n",
      "Epoch 52/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 3.3997 - mean_squared_error: 3.3997 - val_loss: 3.6815 - val_mean_squared_error: 3.6815\n",
      "Epoch 53/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 3.3777 - mean_squared_error: 3.3777 - val_loss: 3.7492 - val_mean_squared_error: 3.7492\n",
      "Epoch 54/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 3.1277 - mean_squared_error: 3.1277 - val_loss: 4.4263 - val_mean_squared_error: 4.4263\n",
      "Epoch 55/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 3.2804 - mean_squared_error: 3.2804 - val_loss: 3.9136 - val_mean_squared_error: 3.9136\n",
      "Epoch 56/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 3.0185 - mean_squared_error: 3.0185 - val_loss: 3.6594 - val_mean_squared_error: 3.6594\n",
      "Epoch 57/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.9062 - mean_squared_error: 2.9062 - val_loss: 3.3872 - val_mean_squared_error: 3.3872\n",
      "Epoch 58/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 3.2247 - mean_squared_error: 3.2247 - val_loss: 3.4609 - val_mean_squared_error: 3.4609\n",
      "Epoch 59/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 3.0521 - mean_squared_error: 3.0521 - val_loss: 3.3445 - val_mean_squared_error: 3.3445\n",
      "Epoch 60/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.9658 - mean_squared_error: 2.9658 - val_loss: 3.9473 - val_mean_squared_error: 3.9473\n",
      "Epoch 61/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 3.0752 - mean_squared_error: 3.0752 - val_loss: 3.3504 - val_mean_squared_error: 3.3504\n",
      "Epoch 62/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 3.0139 - mean_squared_error: 3.0139 - val_loss: 3.5062 - val_mean_squared_error: 3.5062\n",
      "Epoch 63/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.9015 - mean_squared_error: 2.9015 - val_loss: 3.5068 - val_mean_squared_error: 3.5068\n",
      "Epoch 64/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.9460 - mean_squared_error: 2.9460 - val_loss: 3.3345 - val_mean_squared_error: 3.3345\n",
      "Epoch 65/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 3.0908 - mean_squared_error: 3.0908 - val_loss: 4.4869 - val_mean_squared_error: 4.4869\n",
      "Epoch 66/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.7956 - mean_squared_error: 2.7956 - val_loss: 3.4558 - val_mean_squared_error: 3.4558\n",
      "Epoch 67/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.7794 - mean_squared_error: 2.7794 - val_loss: 3.6511 - val_mean_squared_error: 3.6511\n",
      "Epoch 68/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.7200 - mean_squared_error: 2.7200 - val_loss: 3.4989 - val_mean_squared_error: 3.4989\n",
      "Epoch 69/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.5629 - mean_squared_error: 2.5629 - val_loss: 3.1317 - val_mean_squared_error: 3.1317\n",
      "Epoch 70/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.7051 - mean_squared_error: 2.7051 - val_loss: 2.9105 - val_mean_squared_error: 2.9105\n",
      "Epoch 71/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 2.7863 - mean_squared_error: 2.7863 - val_loss: 3.4943 - val_mean_squared_error: 3.4943\n",
      "Epoch 72/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.7006 - mean_squared_error: 2.7006 - val_loss: 3.1285 - val_mean_squared_error: 3.1285\n",
      "Epoch 73/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.4934 - mean_squared_error: 2.4934 - val_loss: 3.3590 - val_mean_squared_error: 3.3590\n",
      "Epoch 74/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.7065 - mean_squared_error: 2.7065 - val_loss: 4.0492 - val_mean_squared_error: 4.0492\n",
      "Epoch 75/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.4680 - mean_squared_error: 2.4680 - val_loss: 3.5973 - val_mean_squared_error: 3.5973\n",
      "Epoch 76/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.5245 - mean_squared_error: 2.5245 - val_loss: 3.2952 - val_mean_squared_error: 3.2952\n",
      "Epoch 77/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.3809 - mean_squared_error: 2.3809 - val_loss: 2.9084 - val_mean_squared_error: 2.9084\n",
      "Epoch 78/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 2.5135 - mean_squared_error: 2.5135 - val_loss: 2.8740 - val_mean_squared_error: 2.8740\n",
      "Epoch 79/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 2.3873 - mean_squared_error: 2.3873 - val_loss: 3.1462 - val_mean_squared_error: 3.1462\n",
      "Epoch 80/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 2.4799 - mean_squared_error: 2.4799 - val_loss: 3.0388 - val_mean_squared_error: 3.0388\n",
      "Epoch 81/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 2.4259 - mean_squared_error: 2.4259 - val_loss: 2.9160 - val_mean_squared_error: 2.9160\n",
      "Epoch 82/200\n",
      "1819/1819 [==============================] - 15s 8ms/sample - loss: 2.2667 - mean_squared_error: 2.2667 - val_loss: 2.9708 - val_mean_squared_error: 2.9708\n",
      "Epoch 83/200\n",
      "1819/1819 [==============================] - 16s 9ms/sample - loss: 2.2903 - mean_squared_error: 2.2903 - val_loss: 2.8001 - val_mean_squared_error: 2.8001\n",
      "Epoch 84/200\n",
      "1819/1819 [==============================] - 15s 8ms/sample - loss: 2.1421 - mean_squared_error: 2.1421 - val_loss: 2.8659 - val_mean_squared_error: 2.8659\n",
      "Epoch 85/200\n",
      "1819/1819 [==============================] - 15s 8ms/sample - loss: 2.2540 - mean_squared_error: 2.2540 - val_loss: 2.8464 - val_mean_squared_error: 2.8464\n",
      "Epoch 86/200\n",
      "1819/1819 [==============================] - 16s 9ms/sample - loss: 2.1242 - mean_squared_error: 2.1242 - val_loss: 2.9803 - val_mean_squared_error: 2.9803\n",
      "Epoch 87/200\n",
      "1819/1819 [==============================] - 16s 9ms/sample - loss: 2.2207 - mean_squared_error: 2.2207 - val_loss: 3.5378 - val_mean_squared_error: 3.5378\n",
      "Epoch 88/200\n",
      "1819/1819 [==============================] - 15s 8ms/sample - loss: 2.1757 - mean_squared_error: 2.1757 - val_loss: 2.7014 - val_mean_squared_error: 2.7014\n",
      "Epoch 89/200\n",
      "1819/1819 [==============================] - 15s 8ms/sample - loss: 2.2025 - mean_squared_error: 2.2025 - val_loss: 2.8406 - val_mean_squared_error: 2.8406\n",
      "Epoch 90/200\n",
      "1819/1819 [==============================] - 15s 8ms/sample - loss: 2.1324 - mean_squared_error: 2.1324 - val_loss: 2.7619 - val_mean_squared_error: 2.7619\n",
      "Epoch 91/200\n",
      "1819/1819 [==============================] - 15s 8ms/sample - loss: 2.1594 - mean_squared_error: 2.1594 - val_loss: 2.7882 - val_mean_squared_error: 2.7882\n",
      "Epoch 92/200\n",
      "1819/1819 [==============================] - 15s 8ms/sample - loss: 2.1069 - mean_squared_error: 2.1069 - val_loss: 2.6849 - val_mean_squared_error: 2.6849\n",
      "Epoch 93/200\n",
      "1819/1819 [==============================] - 15s 8ms/sample - loss: 2.0437 - mean_squared_error: 2.0437 - val_loss: 3.0181 - val_mean_squared_error: 3.0181\n",
      "Epoch 94/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 2.1692 - mean_squared_error: 2.1692 - val_loss: 2.8077 - val_mean_squared_error: 2.8077\n",
      "Epoch 95/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.1165 - mean_squared_error: 2.1165 - val_loss: 2.6476 - val_mean_squared_error: 2.6476\n",
      "Epoch 96/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 2.0692 - mean_squared_error: 2.0692 - val_loss: 2.7357 - val_mean_squared_error: 2.7357\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 2.0209 - mean_squared_error: 2.0209 - val_loss: 2.8810 - val_mean_squared_error: 2.8810\n",
      "Epoch 98/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.0446 - mean_squared_error: 2.0446 - val_loss: 2.8368 - val_mean_squared_error: 2.8368\n",
      "Epoch 99/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.0278 - mean_squared_error: 2.0278 - val_loss: 2.9436 - val_mean_squared_error: 2.9436\n",
      "Epoch 100/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 2.0161 - mean_squared_error: 2.0161 - val_loss: 3.1910 - val_mean_squared_error: 3.1910\n",
      "Epoch 101/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 2.0286 - mean_squared_error: 2.0286 - val_loss: 3.0937 - val_mean_squared_error: 3.0937\n",
      "Epoch 102/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 2.0836 - mean_squared_error: 2.0836 - val_loss: 2.7559 - val_mean_squared_error: 2.7559\n",
      "Epoch 103/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 2.0157 - mean_squared_error: 2.0157 - val_loss: 3.0929 - val_mean_squared_error: 3.0929\n",
      "Epoch 104/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.9006 - mean_squared_error: 1.9006 - val_loss: 2.6083 - val_mean_squared_error: 2.6083\n",
      "Epoch 105/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.9433 - mean_squared_error: 1.9433 - val_loss: 2.8281 - val_mean_squared_error: 2.8281\n",
      "Epoch 106/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.8868 - mean_squared_error: 1.8868 - val_loss: 2.7245 - val_mean_squared_error: 2.7245\n",
      "Epoch 107/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.9896 - mean_squared_error: 1.9896 - val_loss: 3.3577 - val_mean_squared_error: 3.3577\n",
      "Epoch 108/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.8913 - mean_squared_error: 1.8913 - val_loss: 2.7078 - val_mean_squared_error: 2.7078\n",
      "Epoch 109/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 2.0082 - mean_squared_error: 2.0082 - val_loss: 3.2570 - val_mean_squared_error: 3.2570\n",
      "Epoch 110/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.9038 - mean_squared_error: 1.9038 - val_loss: 2.4975 - val_mean_squared_error: 2.4975\n",
      "Epoch 111/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.9743 - mean_squared_error: 1.9743 - val_loss: 2.6575 - val_mean_squared_error: 2.6575\n",
      "Epoch 112/200\n",
      "1819/1819 [==============================] - 15s 8ms/sample - loss: 1.8652 - mean_squared_error: 1.8652 - val_loss: 2.7265 - val_mean_squared_error: 2.7265\n",
      "Epoch 113/200\n",
      "1819/1819 [==============================] - 15s 8ms/sample - loss: 1.9055 - mean_squared_error: 1.9055 - val_loss: 2.5168 - val_mean_squared_error: 2.5168\n",
      "Epoch 114/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.8562 - mean_squared_error: 1.8562 - val_loss: 2.7978 - val_mean_squared_error: 2.7978\n",
      "Epoch 115/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.7338 - mean_squared_error: 1.7338 - val_loss: 2.8059 - val_mean_squared_error: 2.8059\n",
      "Epoch 116/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.8395 - mean_squared_error: 1.8395 - val_loss: 2.7647 - val_mean_squared_error: 2.7647\n",
      "Epoch 117/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.7154 - mean_squared_error: 1.7154 - val_loss: 2.7435 - val_mean_squared_error: 2.7435\n",
      "Epoch 118/200\n",
      "1819/1819 [==============================] - 15s 8ms/sample - loss: 1.6798 - mean_squared_error: 1.6798 - val_loss: 2.4823 - val_mean_squared_error: 2.4823\n",
      "Epoch 119/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.6780 - mean_squared_error: 1.6780 - val_loss: 2.8250 - val_mean_squared_error: 2.8250\n",
      "Epoch 120/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.7674 - mean_squared_error: 1.7674 - val_loss: 3.0561 - val_mean_squared_error: 3.0561\n",
      "Epoch 121/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.7387 - mean_squared_error: 1.7387 - val_loss: 2.9096 - val_mean_squared_error: 2.9096\n",
      "Epoch 122/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 1.8578 - mean_squared_error: 1.8578 - val_loss: 2.5922 - val_mean_squared_error: 2.5922\n",
      "Epoch 123/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.7202 - mean_squared_error: 1.7202 - val_loss: 2.5524 - val_mean_squared_error: 2.5524\n",
      "Epoch 124/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.7903 - mean_squared_error: 1.7903 - val_loss: 2.4887 - val_mean_squared_error: 2.4887\n",
      "Epoch 125/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.7097 - mean_squared_error: 1.7097 - val_loss: 2.5045 - val_mean_squared_error: 2.5045\n",
      "Epoch 126/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.6568 - mean_squared_error: 1.6568 - val_loss: 2.4921 - val_mean_squared_error: 2.4921\n",
      "Epoch 127/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.5925 - mean_squared_error: 1.5925 - val_loss: 2.5296 - val_mean_squared_error: 2.5296\n",
      "Epoch 128/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.5507 - mean_squared_error: 1.5507 - val_loss: 2.4584 - val_mean_squared_error: 2.4584\n",
      "Epoch 129/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.9587 - mean_squared_error: 1.9587 - val_loss: 2.6789 - val_mean_squared_error: 2.6789\n",
      "Epoch 130/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 1.8059 - mean_squared_error: 1.8059 - val_loss: 3.3430 - val_mean_squared_error: 3.3430\n",
      "Epoch 131/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.6916 - mean_squared_error: 1.6916 - val_loss: 2.5513 - val_mean_squared_error: 2.5513\n",
      "Epoch 132/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.5402 - mean_squared_error: 1.5402 - val_loss: 2.9509 - val_mean_squared_error: 2.9509\n",
      "Epoch 133/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.4940 - mean_squared_error: 1.4940 - val_loss: 2.4774 - val_mean_squared_error: 2.4774\n",
      "Epoch 134/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.6961 - mean_squared_error: 1.6961 - val_loss: 2.5034 - val_mean_squared_error: 2.5034\n",
      "Epoch 135/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.5468 - mean_squared_error: 1.5468 - val_loss: 2.6090 - val_mean_squared_error: 2.6090\n",
      "Epoch 136/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.5361 - mean_squared_error: 1.5361 - val_loss: 2.5681 - val_mean_squared_error: 2.5681\n",
      "Epoch 137/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.5847 - mean_squared_error: 1.5847 - val_loss: 2.7188 - val_mean_squared_error: 2.7188\n",
      "Epoch 138/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.5739 - mean_squared_error: 1.5739 - val_loss: 2.6589 - val_mean_squared_error: 2.6589\n",
      "Epoch 139/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.6528 - mean_squared_error: 1.6528 - val_loss: 2.4098 - val_mean_squared_error: 2.4098\n",
      "Epoch 140/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.5643 - mean_squared_error: 1.5643 - val_loss: 2.5991 - val_mean_squared_error: 2.5991\n",
      "Epoch 141/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.7018 - mean_squared_error: 1.7018 - val_loss: 2.4044 - val_mean_squared_error: 2.4044\n",
      "Epoch 142/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.4944 - mean_squared_error: 1.4944 - val_loss: 2.6053 - val_mean_squared_error: 2.6053\n",
      "Epoch 143/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.5767 - mean_squared_error: 1.5767 - val_loss: 2.7363 - val_mean_squared_error: 2.7363\n",
      "Epoch 144/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.5743 - mean_squared_error: 1.5743 - val_loss: 2.6507 - val_mean_squared_error: 2.6507\n",
      "Epoch 145/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.5636 - mean_squared_error: 1.5636 - val_loss: 2.6250 - val_mean_squared_error: 2.6250\n",
      "Epoch 146/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.5050 - mean_squared_error: 1.5050 - val_loss: 2.5980 - val_mean_squared_error: 2.5980\n",
      "Epoch 147/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.5690 - mean_squared_error: 1.5690 - val_loss: 2.7978 - val_mean_squared_error: 2.7978\n",
      "Epoch 148/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.5420 - mean_squared_error: 1.5420 - val_loss: 2.4790 - val_mean_squared_error: 2.4790\n",
      "Epoch 149/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.5100 - mean_squared_error: 1.5100 - val_loss: 2.5894 - val_mean_squared_error: 2.5894\n",
      "Epoch 150/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.4464 - mean_squared_error: 1.4464 - val_loss: 2.5620 - val_mean_squared_error: 2.5620\n",
      "Epoch 151/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.4417 - mean_squared_error: 1.4417 - val_loss: 2.5411 - val_mean_squared_error: 2.5411\n",
      "Epoch 152/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.5553 - mean_squared_error: 1.5553 - val_loss: 2.4015 - val_mean_squared_error: 2.4015\n",
      "Epoch 153/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.5348 - mean_squared_error: 1.5348 - val_loss: 2.8617 - val_mean_squared_error: 2.8617\n",
      "Epoch 154/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.4702 - mean_squared_error: 1.4702 - val_loss: 2.3846 - val_mean_squared_error: 2.3846\n",
      "Epoch 155/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.4853 - mean_squared_error: 1.4853 - val_loss: 2.4611 - val_mean_squared_error: 2.4611\n",
      "Epoch 156/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.4281 - mean_squared_error: 1.4281 - val_loss: 2.4828 - val_mean_squared_error: 2.4828\n",
      "Epoch 157/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.5894 - mean_squared_error: 1.5894 - val_loss: 2.7636 - val_mean_squared_error: 2.7636\n",
      "Epoch 158/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.5215 - mean_squared_error: 1.5215 - val_loss: 3.0463 - val_mean_squared_error: 3.0463\n",
      "Epoch 159/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.4676 - mean_squared_error: 1.4676 - val_loss: 2.6487 - val_mean_squared_error: 2.6487\n",
      "Epoch 160/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 1.4392 - mean_squared_error: 1.4392 - val_loss: 2.7033 - val_mean_squared_error: 2.7033\n",
      "Epoch 161/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.4400 - mean_squared_error: 1.4400 - val_loss: 2.4903 - val_mean_squared_error: 2.4903\n",
      "Epoch 162/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.3380 - mean_squared_error: 1.3380 - val_loss: 2.2917 - val_mean_squared_error: 2.2917\n",
      "Epoch 163/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.3155 - mean_squared_error: 1.3155 - val_loss: 2.4060 - val_mean_squared_error: 2.4060\n",
      "Epoch 164/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.5140 - mean_squared_error: 1.5140 - val_loss: 2.5294 - val_mean_squared_error: 2.5294\n",
      "Epoch 165/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.4191 - mean_squared_error: 1.4191 - val_loss: 2.4878 - val_mean_squared_error: 2.4878\n",
      "Epoch 166/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.3842 - mean_squared_error: 1.3842 - val_loss: 2.6725 - val_mean_squared_error: 2.6725\n",
      "Epoch 167/200\n",
      "1819/1819 [==============================] - 15s 8ms/sample - loss: 1.4659 - mean_squared_error: 1.4659 - val_loss: 2.4515 - val_mean_squared_error: 2.4515\n",
      "Epoch 168/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.3909 - mean_squared_error: 1.3909 - val_loss: 2.3507 - val_mean_squared_error: 2.3507\n",
      "Epoch 169/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.3578 - mean_squared_error: 1.3578 - val_loss: 2.3973 - val_mean_squared_error: 2.3973\n",
      "Epoch 170/200\n",
      "1819/1819 [==============================] - 15s 8ms/sample - loss: 1.3110 - mean_squared_error: 1.3110 - val_loss: 2.5484 - val_mean_squared_error: 2.5484\n",
      "Epoch 171/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.3925 - mean_squared_error: 1.3925 - val_loss: 2.4739 - val_mean_squared_error: 2.4739\n",
      "Epoch 172/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.2880 - mean_squared_error: 1.2880 - val_loss: 2.4934 - val_mean_squared_error: 2.4934\n",
      "Epoch 173/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 1.2922 - mean_squared_error: 1.2922 - val_loss: 2.3289 - val_mean_squared_error: 2.3289\n",
      "Epoch 174/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.3779 - mean_squared_error: 1.3779 - val_loss: 2.3155 - val_mean_squared_error: 2.3155\n",
      "Epoch 175/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.3247 - mean_squared_error: 1.3247 - val_loss: 2.4208 - val_mean_squared_error: 2.4208\n",
      "Epoch 176/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 1.3604 - mean_squared_error: 1.3604 - val_loss: 2.3448 - val_mean_squared_error: 2.3448\n",
      "Epoch 177/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 1.3176 - mean_squared_error: 1.3176 - val_loss: 2.4566 - val_mean_squared_error: 2.4566\n",
      "Epoch 178/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.2370 - mean_squared_error: 1.2370 - val_loss: 2.4218 - val_mean_squared_error: 2.4218\n",
      "Epoch 179/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.3112 - mean_squared_error: 1.3112 - val_loss: 2.5434 - val_mean_squared_error: 2.5434\n",
      "Epoch 180/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.2508 - mean_squared_error: 1.2508 - val_loss: 2.4081 - val_mean_squared_error: 2.4081\n",
      "Epoch 181/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.3183 - mean_squared_error: 1.3183 - val_loss: 2.4516 - val_mean_squared_error: 2.4516\n",
      "Epoch 182/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.2556 - mean_squared_error: 1.2556 - val_loss: 2.7980 - val_mean_squared_error: 2.7980\n",
      "Epoch 183/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.2185 - mean_squared_error: 1.2185 - val_loss: 2.3424 - val_mean_squared_error: 2.3424\n",
      "Epoch 184/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 1.2577 - mean_squared_error: 1.2577 - val_loss: 2.3526 - val_mean_squared_error: 2.3526\n",
      "Epoch 185/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.3502 - mean_squared_error: 1.3502 - val_loss: 2.3764 - val_mean_squared_error: 2.3764\n",
      "Epoch 186/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 1.3569 - mean_squared_error: 1.3569 - val_loss: 2.5927 - val_mean_squared_error: 2.5927\n",
      "Epoch 187/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.2874 - mean_squared_error: 1.2874 - val_loss: 2.4595 - val_mean_squared_error: 2.4595\n",
      "Epoch 188/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.2281 - mean_squared_error: 1.2281 - val_loss: 2.5896 - val_mean_squared_error: 2.5896\n",
      "Epoch 189/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.2547 - mean_squared_error: 1.2547 - val_loss: 2.4157 - val_mean_squared_error: 2.4157\n",
      "Epoch 190/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.3343 - mean_squared_error: 1.3343 - val_loss: 2.5184 - val_mean_squared_error: 2.5184\n",
      "Epoch 191/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 1.2600 - mean_squared_error: 1.2600 - val_loss: 2.5519 - val_mean_squared_error: 2.5519\n",
      "Epoch 192/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.2332 - mean_squared_error: 1.2332 - val_loss: 2.4931 - val_mean_squared_error: 2.4931\n",
      "Epoch 193/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.1520 - mean_squared_error: 1.1520 - val_loss: 2.6104 - val_mean_squared_error: 2.6104\n",
      "Epoch 194/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.1932 - mean_squared_error: 1.1932 - val_loss: 2.3528 - val_mean_squared_error: 2.3528\n",
      "Epoch 195/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.2105 - mean_squared_error: 1.2105 - val_loss: 2.2890 - val_mean_squared_error: 2.2890\n",
      "Epoch 196/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.3314 - mean_squared_error: 1.3314 - val_loss: 2.2506 - val_mean_squared_error: 2.2506\n",
      "Epoch 197/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.2289 - mean_squared_error: 1.2289 - val_loss: 2.5148 - val_mean_squared_error: 2.5148\n",
      "Epoch 198/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.1834 - mean_squared_error: 1.1834 - val_loss: 2.6824 - val_mean_squared_error: 2.6824\n",
      "Epoch 199/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 1.2115 - mean_squared_error: 1.2115 - val_loss: 2.4035 - val_mean_squared_error: 2.4035\n",
      "Epoch 200/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 1.2552 - mean_squared_error: 1.2552 - val_loss: 2.4260 - val_mean_squared_error: 2.4260\n",
      "==================================================\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_123 (Conv2D)          (None, 94, 94, 32)        288       \n",
      "_________________________________________________________________\n",
      "batch_normalization_75 (Batc (None, 94, 94, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_123 (MaxPoolin (None, 47, 47, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_124 (Dropout)        (None, 47, 47, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_124 (Conv2D)          (None, 46, 46, 64)        8192      \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 46, 46, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_124 (MaxPoolin (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_125 (Dropout)        (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_125 (Conv2D)          (None, 22, 22, 128)       32768     \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 22, 22, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_125 (MaxPoolin (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_126 (Dropout)        (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_41 (Flatten)         (None, 15488)             0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 500)               7744500   \n",
      "_________________________________________________________________\n",
      "batch_normalization_78 (Batc (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "dropout_127 (Dropout)        (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_79 (Batc (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 30)                15030     \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 30)                0         \n",
      "=================================================================\n",
      "Total params: 8,056,174\n",
      "Trainable params: 8,053,726\n",
      "Non-trainable params: 2,448\n",
      "_________________________________________________________________\n",
      "None\n",
      "==================================================\n",
      "Train on 1819 samples, validate on 321 samples\n",
      "Epoch 1/200\n",
      "1819/1819 [==============================] - 33s 18ms/sample - loss: 654.9716 - mean_squared_error: 654.9715 - val_loss: 220.3028 - val_mean_squared_error: 220.3028\n",
      "Epoch 2/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 23.1349 - mean_squared_error: 23.1349 - val_loss: 140.6453 - val_mean_squared_error: 140.6453\n",
      "Epoch 3/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 20.8579 - mean_squared_error: 20.8579 - val_loss: 61.7109 - val_mean_squared_error: 61.7109\n",
      "Epoch 4/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 14.9602 - mean_squared_error: 14.9602 - val_loss: 35.6408 - val_mean_squared_error: 35.6408\n",
      "Epoch 5/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 16.0224 - mean_squared_error: 16.0224 - val_loss: 19.5599 - val_mean_squared_error: 19.5599\n",
      "Epoch 6/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 16.2205 - mean_squared_error: 16.2205 - val_loss: 15.9102 - val_mean_squared_error: 15.9102\n",
      "Epoch 7/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 12.8648 - mean_squared_error: 12.8648 - val_loss: 10.7947 - val_mean_squared_error: 10.7947\n",
      "Epoch 8/200\n",
      "1819/1819 [==============================] - 26s 15ms/sample - loss: 13.1650 - mean_squared_error: 13.1650 - val_loss: 12.6477 - val_mean_squared_error: 12.6477\n",
      "Epoch 9/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 12.9204 - mean_squared_error: 12.9204 - val_loss: 10.7026 - val_mean_squared_error: 10.7026\n",
      "Epoch 10/200\n",
      "1819/1819 [==============================] - 25s 14ms/sample - loss: 12.5840 - mean_squared_error: 12.5840 - val_loss: 10.7017 - val_mean_squared_error: 10.7017\n",
      "Epoch 11/200\n",
      "1819/1819 [==============================] - 25s 14ms/sample - loss: 11.8666 - mean_squared_error: 11.8666 - val_loss: 9.6283 - val_mean_squared_error: 9.6283\n",
      "Epoch 12/200\n",
      "1819/1819 [==============================] - 26s 14ms/sample - loss: 10.4624 - mean_squared_error: 10.4624 - val_loss: 12.0237 - val_mean_squared_error: 12.0237\n",
      "Epoch 13/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 10.3687 - mean_squared_error: 10.3687 - val_loss: 9.7819 - val_mean_squared_error: 9.7819\n",
      "Epoch 14/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 10.5945 - mean_squared_error: 10.5945 - val_loss: 10.7844 - val_mean_squared_error: 10.7844\n",
      "Epoch 15/200\n",
      "1819/1819 [==============================] - 26s 14ms/sample - loss: 10.0819 - mean_squared_error: 10.0818 - val_loss: 12.6328 - val_mean_squared_error: 12.6328\n",
      "Epoch 16/200\n",
      "1819/1819 [==============================] - 25s 14ms/sample - loss: 9.6263 - mean_squared_error: 9.6263 - val_loss: 11.1858 - val_mean_squared_error: 11.1858\n",
      "Epoch 17/200\n",
      "1819/1819 [==============================] - 25s 14ms/sample - loss: 9.4988 - mean_squared_error: 9.4988 - val_loss: 10.9387 - val_mean_squared_error: 10.9387\n",
      "Epoch 18/200\n",
      "1819/1819 [==============================] - 25s 14ms/sample - loss: 9.5256 - mean_squared_error: 9.5256 - val_loss: 9.7498 - val_mean_squared_error: 9.7498\n",
      "Epoch 19/200\n",
      "1819/1819 [==============================] - 26s 14ms/sample - loss: 9.0379 - mean_squared_error: 9.0379 - val_loss: 9.2164 - val_mean_squared_error: 9.2164\n",
      "Epoch 20/200\n",
      "1819/1819 [==============================] - 25s 14ms/sample - loss: 8.6790 - mean_squared_error: 8.6790 - val_loss: 10.6211 - val_mean_squared_error: 10.6211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/200\n",
      "1819/1819 [==============================] - 25s 14ms/sample - loss: 8.6735 - mean_squared_error: 8.6735 - val_loss: 10.3280 - val_mean_squared_error: 10.3280\n",
      "Epoch 22/200\n",
      "1819/1819 [==============================] - 25s 14ms/sample - loss: 8.3423 - mean_squared_error: 8.3423 - val_loss: 9.5935 - val_mean_squared_error: 9.5935\n",
      "Epoch 23/200\n",
      "1819/1819 [==============================] - 26s 14ms/sample - loss: 8.2964 - mean_squared_error: 8.2964 - val_loss: 10.0857 - val_mean_squared_error: 10.0857\n",
      "Epoch 24/200\n",
      "1819/1819 [==============================] - 25s 14ms/sample - loss: 7.4174 - mean_squared_error: 7.4174 - val_loss: 8.8312 - val_mean_squared_error: 8.8312\n",
      "Epoch 25/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 7.1498 - mean_squared_error: 7.1498 - val_loss: 8.0481 - val_mean_squared_error: 8.0481\n",
      "Epoch 26/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 7.0696 - mean_squared_error: 7.0696 - val_loss: 8.8273 - val_mean_squared_error: 8.8273\n",
      "Epoch 27/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 6.6126 - mean_squared_error: 6.6126 - val_loss: 7.8903 - val_mean_squared_error: 7.8903\n",
      "Epoch 28/200\n",
      "1819/1819 [==============================] - 31s 17ms/sample - loss: 6.4474 - mean_squared_error: 6.4474 - val_loss: 7.8846 - val_mean_squared_error: 7.8846\n",
      "Epoch 29/200\n",
      "1819/1819 [==============================] - 31s 17ms/sample - loss: 6.1475 - mean_squared_error: 6.1475 - val_loss: 6.5161 - val_mean_squared_error: 6.5161\n",
      "Epoch 30/200\n",
      "1819/1819 [==============================] - 32s 17ms/sample - loss: 5.9873 - mean_squared_error: 5.9873 - val_loss: 6.8217 - val_mean_squared_error: 6.8217\n",
      "Epoch 31/200\n",
      "1819/1819 [==============================] - 31s 17ms/sample - loss: 5.5305 - mean_squared_error: 5.5305 - val_loss: 7.4330 - val_mean_squared_error: 7.4330\n",
      "Epoch 32/200\n",
      "1819/1819 [==============================] - 30s 16ms/sample - loss: 5.5185 - mean_squared_error: 5.5185 - val_loss: 7.2917 - val_mean_squared_error: 7.2917\n",
      "Epoch 33/200\n",
      "1819/1819 [==============================] - 30s 17ms/sample - loss: 5.3686 - mean_squared_error: 5.3686 - val_loss: 5.8832 - val_mean_squared_error: 5.8832\n",
      "Epoch 34/200\n",
      "1819/1819 [==============================] - 28s 16ms/sample - loss: 4.7018 - mean_squared_error: 4.7018 - val_loss: 5.3750 - val_mean_squared_error: 5.3750\n",
      "Epoch 35/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 4.5788 - mean_squared_error: 4.5788 - val_loss: 5.6494 - val_mean_squared_error: 5.6494\n",
      "Epoch 36/200\n",
      "1819/1819 [==============================] - 31s 17ms/sample - loss: 4.7400 - mean_squared_error: 4.7400 - val_loss: 7.4397 - val_mean_squared_error: 7.4397\n",
      "Epoch 37/200\n",
      "1819/1819 [==============================] - 30s 17ms/sample - loss: 4.7330 - mean_squared_error: 4.7330 - val_loss: 5.6171 - val_mean_squared_error: 5.6171\n",
      "Epoch 38/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 4.3819 - mean_squared_error: 4.3819 - val_loss: 4.8843 - val_mean_squared_error: 4.8843\n",
      "Epoch 39/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 4.1347 - mean_squared_error: 4.1347 - val_loss: 5.2470 - val_mean_squared_error: 5.2470\n",
      "Epoch 40/200\n",
      "1819/1819 [==============================] - 33s 18ms/sample - loss: 4.0394 - mean_squared_error: 4.0394 - val_loss: 4.8650 - val_mean_squared_error: 4.8650\n",
      "Epoch 41/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 3.9010 - mean_squared_error: 3.9010 - val_loss: 4.1172 - val_mean_squared_error: 4.1172\n",
      "Epoch 42/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 3.8275 - mean_squared_error: 3.8275 - val_loss: 4.9601 - val_mean_squared_error: 4.9601\n",
      "Epoch 43/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 3.8809 - mean_squared_error: 3.8809 - val_loss: 5.0610 - val_mean_squared_error: 5.0610\n",
      "Epoch 44/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 3.8993 - mean_squared_error: 3.8993 - val_loss: 5.2564 - val_mean_squared_error: 5.2564\n",
      "Epoch 45/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 3.9215 - mean_squared_error: 3.9215 - val_loss: 4.7151 - val_mean_squared_error: 4.7151\n",
      "Epoch 46/200\n",
      "1819/1819 [==============================] - 31s 17ms/sample - loss: 3.6457 - mean_squared_error: 3.6457 - val_loss: 4.2331 - val_mean_squared_error: 4.2331\n",
      "Epoch 47/200\n",
      "1819/1819 [==============================] - 30s 16ms/sample - loss: 3.3432 - mean_squared_error: 3.3432 - val_loss: 4.1480 - val_mean_squared_error: 4.1480\n",
      "Epoch 48/200\n",
      "1819/1819 [==============================] - 30s 16ms/sample - loss: 3.3370 - mean_squared_error: 3.3370 - val_loss: 3.9341 - val_mean_squared_error: 3.9341\n",
      "Epoch 49/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 3.6755 - mean_squared_error: 3.6755 - val_loss: 6.2206 - val_mean_squared_error: 6.2206\n",
      "Epoch 50/200\n",
      "1819/1819 [==============================] - 30s 17ms/sample - loss: 3.3887 - mean_squared_error: 3.3887 - val_loss: 3.8722 - val_mean_squared_error: 3.8722\n",
      "Epoch 51/200\n",
      "1819/1819 [==============================] - 30s 16ms/sample - loss: 3.3854 - mean_squared_error: 3.3854 - val_loss: 3.7178 - val_mean_squared_error: 3.7178\n",
      "Epoch 52/200\n",
      "1819/1819 [==============================] - 30s 16ms/sample - loss: 3.1970 - mean_squared_error: 3.1970 - val_loss: 3.4963 - val_mean_squared_error: 3.4963\n",
      "Epoch 53/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 3.1260 - mean_squared_error: 3.1260 - val_loss: 5.8526 - val_mean_squared_error: 5.8526\n",
      "Epoch 54/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 3.1875 - mean_squared_error: 3.1875 - val_loss: 3.6505 - val_mean_squared_error: 3.6505\n",
      "Epoch 55/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 2.7563 - mean_squared_error: 2.7563 - val_loss: 3.5458 - val_mean_squared_error: 3.5458\n",
      "Epoch 56/200\n",
      "1819/1819 [==============================] - 30s 16ms/sample - loss: 2.9827 - mean_squared_error: 2.9827 - val_loss: 3.5452 - val_mean_squared_error: 3.5452\n",
      "Epoch 57/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 2.8484 - mean_squared_error: 2.8484 - val_loss: 3.2909 - val_mean_squared_error: 3.2909\n",
      "Epoch 58/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 2.8465 - mean_squared_error: 2.8465 - val_loss: 3.5355 - val_mean_squared_error: 3.5355\n",
      "Epoch 59/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 2.6420 - mean_squared_error: 2.6420 - val_loss: 3.3112 - val_mean_squared_error: 3.3112\n",
      "Epoch 60/200\n",
      "1819/1819 [==============================] - 28s 16ms/sample - loss: 2.7464 - mean_squared_error: 2.7464 - val_loss: 3.6263 - val_mean_squared_error: 3.6263\n",
      "Epoch 61/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 2.6707 - mean_squared_error: 2.6707 - val_loss: 3.4275 - val_mean_squared_error: 3.4275\n",
      "Epoch 62/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 2.6610 - mean_squared_error: 2.6610 - val_loss: 3.2441 - val_mean_squared_error: 3.2441\n",
      "Epoch 63/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 2.7049 - mean_squared_error: 2.7049 - val_loss: 4.3200 - val_mean_squared_error: 4.3200\n",
      "Epoch 64/200\n",
      "1819/1819 [==============================] - 28s 16ms/sample - loss: 2.8150 - mean_squared_error: 2.8150 - val_loss: 3.1313 - val_mean_squared_error: 3.1313\n",
      "Epoch 65/200\n",
      "1819/1819 [==============================] - 28s 16ms/sample - loss: 2.5306 - mean_squared_error: 2.5306 - val_loss: 3.8716 - val_mean_squared_error: 3.8716\n",
      "Epoch 66/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 2.4820 - mean_squared_error: 2.4820 - val_loss: 3.8516 - val_mean_squared_error: 3.8516\n",
      "Epoch 67/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 2.4937 - mean_squared_error: 2.4937 - val_loss: 3.3544 - val_mean_squared_error: 3.3544\n",
      "Epoch 68/200\n",
      "1819/1819 [==============================] - 30s 16ms/sample - loss: 2.4608 - mean_squared_error: 2.4608 - val_loss: 3.1384 - val_mean_squared_error: 3.1384\n",
      "Epoch 69/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 2.4420 - mean_squared_error: 2.4420 - val_loss: 3.3569 - val_mean_squared_error: 3.3569\n",
      "Epoch 70/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 2.5310 - mean_squared_error: 2.5310 - val_loss: 3.4277 - val_mean_squared_error: 3.4277\n",
      "Epoch 71/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 2.3879 - mean_squared_error: 2.3879 - val_loss: 3.4415 - val_mean_squared_error: 3.4415\n",
      "Epoch 72/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 2.4162 - mean_squared_error: 2.4162 - val_loss: 3.2230 - val_mean_squared_error: 3.2230\n",
      "Epoch 73/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 2.1156 - mean_squared_error: 2.1156 - val_loss: 2.9675 - val_mean_squared_error: 2.9675\n",
      "Epoch 74/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 2.4316 - mean_squared_error: 2.4316 - val_loss: 4.4359 - val_mean_squared_error: 4.4359\n",
      "Epoch 75/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 2.4310 - mean_squared_error: 2.4310 - val_loss: 3.7000 - val_mean_squared_error: 3.7000\n",
      "Epoch 76/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 2.2392 - mean_squared_error: 2.2392 - val_loss: 2.8888 - val_mean_squared_error: 2.8888\n",
      "Epoch 77/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 2.1974 - mean_squared_error: 2.1974 - val_loss: 3.0981 - val_mean_squared_error: 3.0981\n",
      "Epoch 78/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 2.3017 - mean_squared_error: 2.3017 - val_loss: 3.4241 - val_mean_squared_error: 3.4241\n",
      "Epoch 79/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 2.1522 - mean_squared_error: 2.1522 - val_loss: 2.9457 - val_mean_squared_error: 2.9457\n",
      "Epoch 80/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 2.3275 - mean_squared_error: 2.3275 - val_loss: 3.3192 - val_mean_squared_error: 3.3192\n",
      "Epoch 81/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 2.2097 - mean_squared_error: 2.2097 - val_loss: 3.3798 - val_mean_squared_error: 3.3798\n",
      "Epoch 82/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 2.1238 - mean_squared_error: 2.1238 - val_loss: 3.6762 - val_mean_squared_error: 3.6762\n",
      "Epoch 83/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 2.0536 - mean_squared_error: 2.0536 - val_loss: 3.1531 - val_mean_squared_error: 3.1531\n",
      "Epoch 84/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 2.0883 - mean_squared_error: 2.0883 - val_loss: 3.2162 - val_mean_squared_error: 3.2162\n",
      "Epoch 85/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 2.0916 - mean_squared_error: 2.0916 - val_loss: 3.3048 - val_mean_squared_error: 3.3048\n",
      "Epoch 86/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 2.1404 - mean_squared_error: 2.1404 - val_loss: 3.4333 - val_mean_squared_error: 3.4333\n",
      "Epoch 87/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 2.0699 - mean_squared_error: 2.0699 - val_loss: 2.8409 - val_mean_squared_error: 2.8409\n",
      "Epoch 88/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.8985 - mean_squared_error: 1.8985 - val_loss: 3.2136 - val_mean_squared_error: 3.2136\n",
      "Epoch 89/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.9116 - mean_squared_error: 1.9116 - val_loss: 2.9685 - val_mean_squared_error: 2.9685\n",
      "Epoch 90/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 2.0556 - mean_squared_error: 2.0556 - val_loss: 2.8521 - val_mean_squared_error: 2.8521\n",
      "Epoch 91/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.9817 - mean_squared_error: 1.9817 - val_loss: 2.9448 - val_mean_squared_error: 2.9448\n",
      "Epoch 92/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.9590 - mean_squared_error: 1.9590 - val_loss: 3.0162 - val_mean_squared_error: 3.0162\n",
      "Epoch 93/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 2.1395 - mean_squared_error: 2.1395 - val_loss: 2.8931 - val_mean_squared_error: 2.8931\n",
      "Epoch 94/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.8826 - mean_squared_error: 1.8826 - val_loss: 2.8960 - val_mean_squared_error: 2.8960\n",
      "Epoch 95/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 1.8291 - mean_squared_error: 1.8291 - val_loss: 2.7407 - val_mean_squared_error: 2.7407\n",
      "Epoch 96/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.8628 - mean_squared_error: 1.8628 - val_loss: 2.7255 - val_mean_squared_error: 2.7255\n",
      "Epoch 97/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.7579 - mean_squared_error: 1.7579 - val_loss: 2.8813 - val_mean_squared_error: 2.8813\n",
      "Epoch 98/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.8240 - mean_squared_error: 1.8240 - val_loss: 2.5854 - val_mean_squared_error: 2.5854\n",
      "Epoch 99/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 1.7943 - mean_squared_error: 1.7943 - val_loss: 2.6146 - val_mean_squared_error: 2.6146\n",
      "Epoch 100/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.6598 - mean_squared_error: 1.6598 - val_loss: 2.6750 - val_mean_squared_error: 2.6750\n",
      "Epoch 101/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.7908 - mean_squared_error: 1.7908 - val_loss: 2.6980 - val_mean_squared_error: 2.6980\n",
      "Epoch 102/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.7427 - mean_squared_error: 1.7427 - val_loss: 2.7506 - val_mean_squared_error: 2.7506\n",
      "Epoch 103/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.6281 - mean_squared_error: 1.6281 - val_loss: 2.4699 - val_mean_squared_error: 2.4699\n",
      "Epoch 104/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.7290 - mean_squared_error: 1.7290 - val_loss: 3.0854 - val_mean_squared_error: 3.0854\n",
      "Epoch 105/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 1.7580 - mean_squared_error: 1.7580 - val_loss: 2.7732 - val_mean_squared_error: 2.7732\n",
      "Epoch 106/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.6582 - mean_squared_error: 1.6582 - val_loss: 2.9104 - val_mean_squared_error: 2.9104\n",
      "Epoch 107/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.7857 - mean_squared_error: 1.7857 - val_loss: 2.5838 - val_mean_squared_error: 2.5838\n",
      "Epoch 108/200\n",
      "1819/1819 [==============================] - 26s 15ms/sample - loss: 1.6484 - mean_squared_error: 1.6484 - val_loss: 2.5712 - val_mean_squared_error: 2.5712\n",
      "Epoch 109/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.5510 - mean_squared_error: 1.5510 - val_loss: 2.6201 - val_mean_squared_error: 2.6201\n",
      "Epoch 110/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.8739 - mean_squared_error: 1.8739 - val_loss: 3.2560 - val_mean_squared_error: 3.2560\n",
      "Epoch 111/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.7202 - mean_squared_error: 1.7202 - val_loss: 2.6878 - val_mean_squared_error: 2.6878\n",
      "Epoch 112/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.7083 - mean_squared_error: 1.7083 - val_loss: 2.4700 - val_mean_squared_error: 2.4700\n",
      "Epoch 113/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.6645 - mean_squared_error: 1.6645 - val_loss: 2.9077 - val_mean_squared_error: 2.9077\n",
      "Epoch 114/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.6935 - mean_squared_error: 1.6935 - val_loss: 2.6483 - val_mean_squared_error: 2.6483\n",
      "Epoch 115/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 1.6892 - mean_squared_error: 1.6892 - val_loss: 2.6315 - val_mean_squared_error: 2.6315\n",
      "Epoch 116/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 1.7970 - mean_squared_error: 1.7970 - val_loss: 2.6915 - val_mean_squared_error: 2.6915\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.6451 - mean_squared_error: 1.6451 - val_loss: 2.7847 - val_mean_squared_error: 2.7847\n",
      "Epoch 118/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.7546 - mean_squared_error: 1.7546 - val_loss: 2.7997 - val_mean_squared_error: 2.7997\n",
      "Epoch 119/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.6203 - mean_squared_error: 1.6203 - val_loss: 3.6750 - val_mean_squared_error: 3.6750\n",
      "Epoch 120/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.6542 - mean_squared_error: 1.6542 - val_loss: 2.7316 - val_mean_squared_error: 2.7316\n",
      "Epoch 121/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 1.5269 - mean_squared_error: 1.5269 - val_loss: 2.5771 - val_mean_squared_error: 2.5771\n",
      "Epoch 122/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 1.4419 - mean_squared_error: 1.4419 - val_loss: 2.5061 - val_mean_squared_error: 2.5061\n",
      "Epoch 123/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 1.5994 - mean_squared_error: 1.5994 - val_loss: 2.3543 - val_mean_squared_error: 2.3543\n",
      "Epoch 124/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.5176 - mean_squared_error: 1.5176 - val_loss: 2.5499 - val_mean_squared_error: 2.5499\n",
      "Epoch 125/200\n",
      "1819/1819 [==============================] - 25s 14ms/sample - loss: 1.5781 - mean_squared_error: 1.5781 - val_loss: 2.3074 - val_mean_squared_error: 2.3074\n",
      "Epoch 126/200\n",
      "1819/1819 [==============================] - 26s 14ms/sample - loss: 1.5223 - mean_squared_error: 1.5223 - val_loss: 2.7434 - val_mean_squared_error: 2.7434\n",
      "Epoch 127/200\n",
      "1819/1819 [==============================] - 26s 14ms/sample - loss: 1.6064 - mean_squared_error: 1.6064 - val_loss: 2.3828 - val_mean_squared_error: 2.3828\n",
      "Epoch 128/200\n",
      "1819/1819 [==============================] - 26s 14ms/sample - loss: 1.5039 - mean_squared_error: 1.5039 - val_loss: 2.4562 - val_mean_squared_error: 2.4562\n",
      "Epoch 129/200\n",
      "1819/1819 [==============================] - 26s 14ms/sample - loss: 1.4591 - mean_squared_error: 1.4591 - val_loss: 2.7185 - val_mean_squared_error: 2.7185\n",
      "Epoch 130/200\n",
      "1819/1819 [==============================] - 26s 14ms/sample - loss: 1.4152 - mean_squared_error: 1.4152 - val_loss: 2.7082 - val_mean_squared_error: 2.7082\n",
      "Epoch 131/200\n",
      "1819/1819 [==============================] - 25s 14ms/sample - loss: 1.5743 - mean_squared_error: 1.5743 - val_loss: 2.8819 - val_mean_squared_error: 2.8819\n",
      "Epoch 132/200\n",
      "1819/1819 [==============================] - 26s 14ms/sample - loss: 1.5217 - mean_squared_error: 1.5217 - val_loss: 2.4558 - val_mean_squared_error: 2.4558\n",
      "Epoch 133/200\n",
      "1819/1819 [==============================] - 26s 14ms/sample - loss: 1.5213 - mean_squared_error: 1.5213 - val_loss: 2.7556 - val_mean_squared_error: 2.7556\n",
      "Epoch 134/200\n",
      "1819/1819 [==============================] - 26s 14ms/sample - loss: 1.4394 - mean_squared_error: 1.4394 - val_loss: 2.4888 - val_mean_squared_error: 2.4888\n",
      "Epoch 135/200\n",
      "1819/1819 [==============================] - 26s 14ms/sample - loss: 1.4079 - mean_squared_error: 1.4079 - val_loss: 2.8684 - val_mean_squared_error: 2.8684\n",
      "Epoch 136/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.3242 - mean_squared_error: 1.3242 - val_loss: 2.4739 - val_mean_squared_error: 2.4739\n",
      "Epoch 137/200\n",
      "1819/1819 [==============================] - 26s 14ms/sample - loss: 1.5214 - mean_squared_error: 1.5214 - val_loss: 2.5041 - val_mean_squared_error: 2.5041\n",
      "Epoch 138/200\n",
      "1819/1819 [==============================] - 26s 14ms/sample - loss: 1.4064 - mean_squared_error: 1.4064 - val_loss: 2.5475 - val_mean_squared_error: 2.5475\n",
      "Epoch 139/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.3466 - mean_squared_error: 1.3466 - val_loss: 2.2590 - val_mean_squared_error: 2.2590\n",
      "Epoch 140/200\n",
      "1819/1819 [==============================] - 26s 14ms/sample - loss: 1.4908 - mean_squared_error: 1.4908 - val_loss: 2.4050 - val_mean_squared_error: 2.4050\n",
      "Epoch 141/200\n",
      "1819/1819 [==============================] - 26s 14ms/sample - loss: 1.4490 - mean_squared_error: 1.4490 - val_loss: 2.3657 - val_mean_squared_error: 2.3657\n",
      "Epoch 142/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.4091 - mean_squared_error: 1.4091 - val_loss: 2.5898 - val_mean_squared_error: 2.5898\n",
      "Epoch 143/200\n",
      "1819/1819 [==============================] - 26s 14ms/sample - loss: 1.3921 - mean_squared_error: 1.3921 - val_loss: 2.2332 - val_mean_squared_error: 2.2332\n",
      "Epoch 144/200\n",
      "1819/1819 [==============================] - 26s 14ms/sample - loss: 1.3484 - mean_squared_error: 1.3484 - val_loss: 2.3718 - val_mean_squared_error: 2.3718\n",
      "Epoch 145/200\n",
      "1819/1819 [==============================] - 26s 14ms/sample - loss: 1.3557 - mean_squared_error: 1.3557 - val_loss: 2.5570 - val_mean_squared_error: 2.5570\n",
      "Epoch 146/200\n",
      "1819/1819 [==============================] - 31s 17ms/sample - loss: 1.3797 - mean_squared_error: 1.3797 - val_loss: 2.7422 - val_mean_squared_error: 2.7422\n",
      "Epoch 147/200\n",
      "1819/1819 [==============================] - 30s 16ms/sample - loss: 1.3242 - mean_squared_error: 1.3242 - val_loss: 2.3113 - val_mean_squared_error: 2.3113\n",
      "Epoch 148/200\n",
      "1819/1819 [==============================] - 34s 18ms/sample - loss: 1.3575 - mean_squared_error: 1.3575 - val_loss: 2.8221 - val_mean_squared_error: 2.8221\n",
      "Epoch 149/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 1.2492 - mean_squared_error: 1.2492 - val_loss: 2.4043 - val_mean_squared_error: 2.4043\n",
      "Epoch 152/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 1.2317 - mean_squared_error: 1.2317 - val_loss: 2.3552 - val_mean_squared_error: 2.3552\n",
      "Epoch 153/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 1.3145 - mean_squared_error: 1.3145 - val_loss: 2.4420 - val_mean_squared_error: 2.4420\n",
      "Epoch 154/200\n",
      "1819/1819 [==============================] - 31s 17ms/sample - loss: 1.2282 - mean_squared_error: 1.2282 - val_loss: 2.4039 - val_mean_squared_error: 2.4039\n",
      "Epoch 155/200\n",
      "1819/1819 [==============================] - 45s 25ms/sample - loss: 1.3702 - mean_squared_error: 1.3702 - val_loss: 2.3283 - val_mean_squared_error: 2.3283\n",
      "Epoch 156/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 1.3530 - mean_squared_error: 1.3530 - val_loss: 2.4418 - val_mean_squared_error: 2.4418\n",
      "Epoch 157/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.3275 - mean_squared_error: 1.3275 - val_loss: 2.4368 - val_mean_squared_error: 2.4368\n",
      "Epoch 158/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 1.4009 - mean_squared_error: 1.4009 - val_loss: 2.3910 - val_mean_squared_error: 2.3910\n",
      "Epoch 159/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 1.3358 - mean_squared_error: 1.3358 - val_loss: 2.4946 - val_mean_squared_error: 2.4946\n",
      "Epoch 160/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.3075 - mean_squared_error: 1.3075 - val_loss: 2.4193 - val_mean_squared_error: 2.4193\n",
      "Epoch 161/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.3176 - mean_squared_error: 1.3176 - val_loss: 2.2689 - val_mean_squared_error: 2.2689\n",
      "Epoch 162/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.2596 - mean_squared_error: 1.2596 - val_loss: 2.7700 - val_mean_squared_error: 2.7700\n",
      "Epoch 163/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.3219 - mean_squared_error: 1.3219 - val_loss: 2.5405 - val_mean_squared_error: 2.5405\n",
      "Epoch 164/200\n",
      "1819/1819 [==============================] - 26s 14ms/sample - loss: 1.2596 - mean_squared_error: 1.2596 - val_loss: 2.5958 - val_mean_squared_error: 2.5958\n",
      "Epoch 165/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.3324 - mean_squared_error: 1.3324 - val_loss: 2.2633 - val_mean_squared_error: 2.2633\n",
      "Epoch 166/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 1.1272 - mean_squared_error: 1.1272 - val_loss: 2.3235 - val_mean_squared_error: 2.3235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.2443 - mean_squared_error: 1.2443 - val_loss: 2.3241 - val_mean_squared_error: 2.3241\n",
      "Epoch 168/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.2054 - mean_squared_error: 1.2054 - val_loss: 2.2313 - val_mean_squared_error: 2.2313\n",
      "Epoch 169/200\n",
      "1819/1819 [==============================] - 25s 14ms/sample - loss: 1.2166 - mean_squared_error: 1.2166 - val_loss: 2.3775 - val_mean_squared_error: 2.3775\n",
      "Epoch 170/200\n",
      "1819/1819 [==============================] - 26s 14ms/sample - loss: 1.1879 - mean_squared_error: 1.1879 - val_loss: 2.4365 - val_mean_squared_error: 2.4365\n",
      "Epoch 171/200\n",
      "1819/1819 [==============================] - 26s 14ms/sample - loss: 1.1743 - mean_squared_error: 1.1743 - val_loss: 2.3487 - val_mean_squared_error: 2.3487\n",
      "Epoch 172/200\n",
      "1819/1819 [==============================] - 26s 14ms/sample - loss: 1.1732 - mean_squared_error: 1.1732 - val_loss: 2.2536 - val_mean_squared_error: 2.2536\n",
      "Epoch 173/200\n",
      "1819/1819 [==============================] - 26s 15ms/sample - loss: 1.2116 - mean_squared_error: 1.2116 - val_loss: 2.4203 - val_mean_squared_error: 2.4203\n",
      "Epoch 174/200\n",
      "1819/1819 [==============================] - 30s 16ms/sample - loss: 1.1581 - mean_squared_error: 1.1581 - val_loss: 2.7513 - val_mean_squared_error: 2.7513\n",
      "Epoch 175/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 1.1908 - mean_squared_error: 1.1908 - val_loss: 2.2706 - val_mean_squared_error: 2.2706\n",
      "Epoch 176/200\n",
      "1819/1819 [==============================] - 28s 16ms/sample - loss: 1.1682 - mean_squared_error: 1.1682 - val_loss: 2.8722 - val_mean_squared_error: 2.8722\n",
      "Epoch 177/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 1.2339 - mean_squared_error: 1.2339 - val_loss: 2.2875 - val_mean_squared_error: 2.2875\n",
      "Epoch 178/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.1511 - mean_squared_error: 1.1511 - val_loss: 2.3534 - val_mean_squared_error: 2.3534\n",
      "Epoch 179/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 1.1630 - mean_squared_error: 1.1630 - val_loss: 2.5327 - val_mean_squared_error: 2.5327\n",
      "Epoch 180/200\n",
      "1819/1819 [==============================] - 28s 16ms/sample - loss: 1.1168 - mean_squared_error: 1.1168 - val_loss: 2.4304 - val_mean_squared_error: 2.4304\n",
      "Epoch 181/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 1.1635 - mean_squared_error: 1.1635 - val_loss: 2.5467 - val_mean_squared_error: 2.5467\n",
      "Epoch 182/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 1.1227 - mean_squared_error: 1.1227 - val_loss: 2.4483 - val_mean_squared_error: 2.4483\n",
      "Epoch 183/200\n",
      "1819/1819 [==============================] - 28s 16ms/sample - loss: 1.1751 - mean_squared_error: 1.1751 - val_loss: 2.1698 - val_mean_squared_error: 2.1698\n",
      "Epoch 184/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 1.2034 - mean_squared_error: 1.2034 - val_loss: 2.4457 - val_mean_squared_error: 2.4457\n",
      "Epoch 185/200\n",
      "1819/1819 [==============================] - 28s 16ms/sample - loss: 1.0898 - mean_squared_error: 1.0898 - val_loss: 2.2723 - val_mean_squared_error: 2.2723\n",
      "Epoch 186/200\n",
      "1819/1819 [==============================] - 39s 22ms/sample - loss: 1.1080 - mean_squared_error: 1.1080 - val_loss: 2.1843 - val_mean_squared_error: 2.1843\n",
      "Epoch 187/200\n",
      "1819/1819 [==============================] - 30s 16ms/sample - loss: 1.0582 - mean_squared_error: 1.0582 - val_loss: 2.1956 - val_mean_squared_error: 2.1956\n",
      "Epoch 188/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 1.1890 - mean_squared_error: 1.1890 - val_loss: 2.4447 - val_mean_squared_error: 2.4447\n",
      "Epoch 189/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.0884 - mean_squared_error: 1.0884 - val_loss: 2.2525 - val_mean_squared_error: 2.2525\n",
      "Epoch 190/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 1.0789 - mean_squared_error: 1.0789 - val_loss: 2.3292 - val_mean_squared_error: 2.3292\n",
      "Epoch 191/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 1.1740 - mean_squared_error: 1.1740 - val_loss: 2.3842 - val_mean_squared_error: 2.3842\n",
      "Epoch 192/200\n",
      "1819/1819 [==============================] - 28s 15ms/sample - loss: 1.0587 - mean_squared_error: 1.0587 - val_loss: 2.3336 - val_mean_squared_error: 2.3336\n",
      "Epoch 193/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.1187 - mean_squared_error: 1.1187 - val_loss: 2.4347 - val_mean_squared_error: 2.4347\n",
      "Epoch 194/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.0693 - mean_squared_error: 1.0693 - val_loss: 2.1565 - val_mean_squared_error: 2.1565\n",
      "Epoch 195/200\n",
      "1819/1819 [==============================] - 26s 14ms/sample - loss: 1.1139 - mean_squared_error: 1.1139 - val_loss: 2.4077 - val_mean_squared_error: 2.4077\n",
      "Epoch 196/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.0943 - mean_squared_error: 1.0943 - val_loss: 2.6002 - val_mean_squared_error: 2.6002\n",
      "Epoch 197/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 1.0235 - mean_squared_error: 1.0235 - val_loss: 2.1423 - val_mean_squared_error: 2.1423\n",
      "Epoch 198/200\n",
      "1819/1819 [==============================] - 29s 16ms/sample - loss: 1.0772 - mean_squared_error: 1.0772 - val_loss: 2.1960 - val_mean_squared_error: 2.1960\n",
      "Epoch 199/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.0593 - mean_squared_error: 1.0593 - val_loss: 2.3348 - val_mean_squared_error: 2.3348\n",
      "Epoch 200/200\n",
      "1819/1819 [==============================] - 27s 15ms/sample - loss: 1.2075 - mean_squared_error: 1.2075 - val_loss: 2.8409 - val_mean_squared_error: 2.8409\n"
     ]
    }
   ],
   "source": [
    "# Redefine optimizer list to just focus on adam and sgd\n",
    "opt_list = {'adam':adam}\n",
    "\n",
    "# Use an early stopping callback and our timing callback\n",
    "early_stop = callbacks.EarlyStopping(monitor='val_loss', min_delta=0.1,\n",
    "                              patience=100, mode='auto')\n",
    "time_callback = TimeHistory()\n",
    "\n",
    "# Initialize a new data frame to hold our output data\n",
    "cnn_dropout_bn_df = pd.DataFrame()\n",
    "\n",
    "# Start filter list\n",
    "start_filters = [16, 32]\n",
    "\n",
    "# Flag for using or not using bias term\n",
    "biases = [False]\n",
    "\n",
    "# Create a list of initial dropout values and steps to increase\n",
    "dropouts = [(0.0,0.01), (0.00,0.02), (0.00,0.03)]\n",
    "\n",
    "for opt_name, opt in opt_list.items():\n",
    "    for start_filter in start_filters:\n",
    "        for bias in biases:\n",
    "            for d in dropouts:\n",
    "                model = create_batchnorm_cnn_model(start_filter, d[0], d[1], bias)\n",
    "                model.compile(\n",
    "                      optimizer=opt,\n",
    "                      loss='mean_squared_error',\n",
    "                      metrics=['mean_squared_error'])\n",
    "                history = model.fit(\n",
    "                    X.astype(np.float32), y.astype(np.float32),\n",
    "                    epochs=200,\n",
    "                    validation_split=0.15, callbacks=[time_callback, early_stop])\n",
    "                times = time_callback.times\n",
    "\n",
    "                # Convert to dataframe\n",
    "                hist = pd.DataFrame(history.history)\n",
    "                hist['epoch'] = history.epoch\n",
    "                hist['RMSE'] = np.sqrt(hist.mean_squared_error)\n",
    "                hist['val_RMSE'] = np.sqrt(hist.val_mean_squared_error)\n",
    "                hist['times'] = times\n",
    "                hist['starting_filter'] = start_filter\n",
    "                hist['layers'] = 3\n",
    "                hist['pooling'] = 'yes'\n",
    "                hist['fc_layer'] = 500\n",
    "                hist['activation'] = 'relu'\n",
    "                hist['optimizer'] = opt_name\n",
    "                hist['lrate'] = opt.get_config()['learning_rate']\n",
    "                hist['dropout_initial'] = d[0]\n",
    "                hist['dropout_step'] = d[1]\n",
    "                hist['batch_norm'] = 1\n",
    "                hist['bias'] = int(bias)\n",
    "\n",
    "                # Keep concatenating to dataframe\n",
    "                cnn_dropout_bn_df = pd.concat([cnn_dropout_bn_df,hist])\n",
    "\n",
    "                # Re-pickle after every model to retain progress\n",
    "                cnn_dropout_bn_df.to_pickle(\"OutputData/cnn_dropout_bn_df2.pkl\")\n",
    "\n",
    "                # Save models.\n",
    "                filename = \"cnn_dropout_bn_model_{}_d{}_s{}_sf{}\".format(opt_name, d[0], d[1], start_filter)\n",
    "                model.save(\"Models/\"+filename+\".h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with flipped image data\n",
    "Let's see if we can get accuracy improvements when we double the size of our training data by flipping all of our images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flipped = pd.read_pickle('df_nostache_nonan_w_flip.pkl')\n",
    "\n",
    "# # Grab training data\n",
    "flipped_X = np.array([x.reshape(96,96,1) for x in df_flipped.iloc[:,-1]])\n",
    "\n",
    "# # Grab the keypoints and stick into our y-variable\n",
    "flipped_y = np.array(df_flipped.iloc[:,:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 94, 94, 12)        108       \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 94, 94, 12)        48        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 47, 47, 12)        0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 47, 47, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 46, 46, 24)        1152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 46, 46, 24)        96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 23, 23, 24)        0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 23, 23, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 22, 22, 48)        4608      \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 22, 22, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 11, 11, 48)        0         \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 11, 11, 48)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 5808)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 500)               2904500   \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 30)                15030     \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 30)                0         \n",
      "=================================================================\n",
      "Total params: 3,180,234\n",
      "Trainable params: 3,178,066\n",
      "Non-trainable params: 2,168\n",
      "_________________________________________________________________\n",
      "None\n",
      "==================================================\n",
      "Train on 1819 samples, validate on 321 samples\n",
      "Epoch 1/200\n",
      "1819/1819 [==============================] - 15s 8ms/sample - loss: 796.4186 - mean_squared_error: 796.4186 - val_loss: 279.5459 - val_mean_squared_error: 279.5460\n",
      "Epoch 2/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 27.3770 - mean_squared_error: 27.3770 - val_loss: 129.2164 - val_mean_squared_error: 129.2164\n",
      "Epoch 3/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 19.5271 - mean_squared_error: 19.5271 - val_loss: 75.2436 - val_mean_squared_error: 75.2436\n",
      "Epoch 4/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 21.9218 - mean_squared_error: 21.9218 - val_loss: 42.2968 - val_mean_squared_error: 42.2968\n",
      "Epoch 5/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 16.0141 - mean_squared_error: 16.0141 - val_loss: 22.1237 - val_mean_squared_error: 22.1237\n",
      "Epoch 6/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 16.2099 - mean_squared_error: 16.2099 - val_loss: 16.0532 - val_mean_squared_error: 16.0532\n",
      "Epoch 7/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 13.1003 - mean_squared_error: 13.1003 - val_loss: 15.2518 - val_mean_squared_error: 15.2518\n",
      "Epoch 8/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 14.2847 - mean_squared_error: 14.2847 - val_loss: 12.4652 - val_mean_squared_error: 12.4652\n",
      "Epoch 9/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 11.8631 - mean_squared_error: 11.8631 - val_loss: 10.5931 - val_mean_squared_error: 10.5931\n",
      "Epoch 10/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 12.9793 - mean_squared_error: 12.9793 - val_loss: 10.7142 - val_mean_squared_error: 10.7142\n",
      "Epoch 11/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 11.5637 - mean_squared_error: 11.5637 - val_loss: 10.7292 - val_mean_squared_error: 10.7292\n",
      "Epoch 12/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 11.9740 - mean_squared_error: 11.9740 - val_loss: 15.2467 - val_mean_squared_error: 15.2467\n",
      "Epoch 13/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 11.2577 - mean_squared_error: 11.2577 - val_loss: 9.1087 - val_mean_squared_error: 9.1087\n",
      "Epoch 14/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 10.6133 - mean_squared_error: 10.6133 - val_loss: 9.2696 - val_mean_squared_error: 9.2696\n",
      "Epoch 15/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 10.5439 - mean_squared_error: 10.5439 - val_loss: 10.9350 - val_mean_squared_error: 10.9350\n",
      "Epoch 16/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 10.3092 - mean_squared_error: 10.3092 - val_loss: 12.2966 - val_mean_squared_error: 12.2966\n",
      "Epoch 17/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 10.3217 - mean_squared_error: 10.3217 - val_loss: 9.2625 - val_mean_squared_error: 9.2625\n",
      "Epoch 18/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 9.0447 - mean_squared_error: 9.0447 - val_loss: 10.0982 - val_mean_squared_error: 10.0982\n",
      "Epoch 19/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 8.5338 - mean_squared_error: 8.5338 - val_loss: 8.8112 - val_mean_squared_error: 8.8112\n",
      "Epoch 20/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 8.2498 - mean_squared_error: 8.2498 - val_loss: 9.4329 - val_mean_squared_error: 9.4329\n",
      "Epoch 21/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 7.9517 - mean_squared_error: 7.9517 - val_loss: 9.2525 - val_mean_squared_error: 9.2525\n",
      "Epoch 22/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 7.6650 - mean_squared_error: 7.6650 - val_loss: 8.5584 - val_mean_squared_error: 8.5584\n",
      "Epoch 23/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 7.5842 - mean_squared_error: 7.5842 - val_loss: 9.0693 - val_mean_squared_error: 9.0693\n",
      "Epoch 24/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 7.0788 - mean_squared_error: 7.0788 - val_loss: 8.5614 - val_mean_squared_error: 8.5614\n",
      "Epoch 25/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 6.8775 - mean_squared_error: 6.8775 - val_loss: 8.8960 - val_mean_squared_error: 8.8960\n",
      "Epoch 26/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 6.8371 - mean_squared_error: 6.8371 - val_loss: 6.9466 - val_mean_squared_error: 6.9466\n",
      "Epoch 27/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 6.3649 - mean_squared_error: 6.3649 - val_loss: 8.1193 - val_mean_squared_error: 8.1193\n",
      "Epoch 28/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 5.7077 - mean_squared_error: 5.7077 - val_loss: 7.1305 - val_mean_squared_error: 7.1305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 5.7895 - mean_squared_error: 5.7895 - val_loss: 5.9019 - val_mean_squared_error: 5.9019\n",
      "Epoch 30/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 5.3692 - mean_squared_error: 5.3692 - val_loss: 6.6326 - val_mean_squared_error: 6.6326\n",
      "Epoch 31/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 5.3128 - mean_squared_error: 5.3128 - val_loss: 5.4822 - val_mean_squared_error: 5.4822\n",
      "Epoch 32/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 4.8442 - mean_squared_error: 4.8442 - val_loss: 5.8146 - val_mean_squared_error: 5.8146\n",
      "Epoch 33/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 4.5908 - mean_squared_error: 4.5908 - val_loss: 5.2413 - val_mean_squared_error: 5.2413\n",
      "Epoch 34/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 4.6726 - mean_squared_error: 4.6726 - val_loss: 5.6167 - val_mean_squared_error: 5.6167\n",
      "Epoch 35/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 4.1854 - mean_squared_error: 4.1854 - val_loss: 5.7151 - val_mean_squared_error: 5.7151\n",
      "Epoch 36/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 4.5049 - mean_squared_error: 4.5049 - val_loss: 5.2187 - val_mean_squared_error: 5.2187\n",
      "Epoch 37/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 4.1863 - mean_squared_error: 4.1863 - val_loss: 5.0423 - val_mean_squared_error: 5.0423\n",
      "Epoch 38/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 3.9565 - mean_squared_error: 3.9565 - val_loss: 4.6524 - val_mean_squared_error: 4.6524\n",
      "Epoch 39/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 3.8517 - mean_squared_error: 3.8517 - val_loss: 4.3863 - val_mean_squared_error: 4.3863\n",
      "Epoch 40/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 3.8994 - mean_squared_error: 3.8994 - val_loss: 4.5167 - val_mean_squared_error: 4.5167\n",
      "Epoch 41/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 3.7712 - mean_squared_error: 3.7712 - val_loss: 5.0662 - val_mean_squared_error: 5.0662\n",
      "Epoch 42/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 3.6785 - mean_squared_error: 3.6785 - val_loss: 5.8994 - val_mean_squared_error: 5.8994\n",
      "Epoch 43/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 3.4834 - mean_squared_error: 3.4834 - val_loss: 5.3447 - val_mean_squared_error: 5.3447\n",
      "Epoch 44/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 3.5007 - mean_squared_error: 3.5007 - val_loss: 4.5181 - val_mean_squared_error: 4.5181\n",
      "Epoch 45/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 3.7451 - mean_squared_error: 3.7451 - val_loss: 4.4475 - val_mean_squared_error: 4.4475\n",
      "Epoch 46/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 3.7944 - mean_squared_error: 3.7944 - val_loss: 3.7308 - val_mean_squared_error: 3.7308\n",
      "Epoch 47/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 3.3128 - mean_squared_error: 3.3128 - val_loss: 3.9439 - val_mean_squared_error: 3.9439\n",
      "Epoch 48/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 3.6873 - mean_squared_error: 3.6873 - val_loss: 4.2850 - val_mean_squared_error: 4.2850\n",
      "Epoch 49/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 3.3287 - mean_squared_error: 3.3287 - val_loss: 4.1038 - val_mean_squared_error: 4.1038\n",
      "Epoch 50/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 3.2299 - mean_squared_error: 3.2299 - val_loss: 4.0493 - val_mean_squared_error: 4.0493\n",
      "Epoch 51/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 3.0417 - mean_squared_error: 3.0417 - val_loss: 3.8787 - val_mean_squared_error: 3.8787\n",
      "Epoch 52/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 3.1881 - mean_squared_error: 3.1881 - val_loss: 4.6028 - val_mean_squared_error: 4.6028\n",
      "Epoch 53/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.9884 - mean_squared_error: 2.9884 - val_loss: 3.7739 - val_mean_squared_error: 3.7739\n",
      "Epoch 54/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.9117 - mean_squared_error: 2.9117 - val_loss: 3.4455 - val_mean_squared_error: 3.4455\n",
      "Epoch 55/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 2.7397 - mean_squared_error: 2.7397 - val_loss: 3.7719 - val_mean_squared_error: 3.7719\n",
      "Epoch 56/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.6905 - mean_squared_error: 2.6905 - val_loss: 3.5828 - val_mean_squared_error: 3.5828\n",
      "Epoch 57/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.6044 - mean_squared_error: 2.6044 - val_loss: 3.5262 - val_mean_squared_error: 3.5262\n",
      "Epoch 58/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 2.6537 - mean_squared_error: 2.6537 - val_loss: 3.4001 - val_mean_squared_error: 3.4001\n",
      "Epoch 59/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 2.6170 - mean_squared_error: 2.6170 - val_loss: 3.7254 - val_mean_squared_error: 3.7254\n",
      "Epoch 60/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 2.6596 - mean_squared_error: 2.6596 - val_loss: 3.7545 - val_mean_squared_error: 3.7545\n",
      "Epoch 61/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.6392 - mean_squared_error: 2.6392 - val_loss: 4.2180 - val_mean_squared_error: 4.2180\n",
      "Epoch 62/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.5273 - mean_squared_error: 2.5273 - val_loss: 3.5919 - val_mean_squared_error: 3.5919\n",
      "Epoch 63/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.6536 - mean_squared_error: 2.6536 - val_loss: 3.9759 - val_mean_squared_error: 3.9759\n",
      "Epoch 64/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 2.6926 - mean_squared_error: 2.6926 - val_loss: 3.8756 - val_mean_squared_error: 3.8756\n",
      "Epoch 65/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 2.4862 - mean_squared_error: 2.4862 - val_loss: 4.0587 - val_mean_squared_error: 4.0587\n",
      "Epoch 66/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 2.5583 - mean_squared_error: 2.5583 - val_loss: 3.4065 - val_mean_squared_error: 3.4065\n",
      "Epoch 67/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.4741 - mean_squared_error: 2.4741 - val_loss: 3.4346 - val_mean_squared_error: 3.4346\n",
      "Epoch 68/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 2.3036 - mean_squared_error: 2.3036 - val_loss: 3.8696 - val_mean_squared_error: 3.8696\n",
      "Epoch 69/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.4079 - mean_squared_error: 2.4079 - val_loss: 3.2911 - val_mean_squared_error: 3.2911\n",
      "Epoch 70/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.3446 - mean_squared_error: 2.3446 - val_loss: 3.1212 - val_mean_squared_error: 3.1212\n",
      "Epoch 71/200\n",
      "1819/1819 [==============================] - 14s 7ms/sample - loss: 2.3383 - mean_squared_error: 2.3383 - val_loss: 3.1691 - val_mean_squared_error: 3.1691\n",
      "Epoch 72/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.2940 - mean_squared_error: 2.2940 - val_loss: 3.0594 - val_mean_squared_error: 3.0594\n",
      "Epoch 73/200\n",
      "1819/1819 [==============================] - 14s 8ms/sample - loss: 2.3004 - mean_squared_error: 2.3004 - val_loss: 3.9200 - val_mean_squared_error: 3.9200\n",
      "Epoch 74/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 2.1535 - mean_squared_error: 2.1535 - val_loss: 3.1662 - val_mean_squared_error: 3.1662\n",
      "Epoch 75/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.3861 - mean_squared_error: 2.3861 - val_loss: 4.0848 - val_mean_squared_error: 4.0848\n",
      "Epoch 76/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 2.1626 - mean_squared_error: 2.1626 - val_loss: 3.5866 - val_mean_squared_error: 3.5866\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.3169 - mean_squared_error: 2.3169 - val_loss: 3.2890 - val_mean_squared_error: 3.2890\n",
      "Epoch 78/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 2.2189 - mean_squared_error: 2.2189 - val_loss: 3.8378 - val_mean_squared_error: 3.8378\n",
      "Epoch 79/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 2.3883 - mean_squared_error: 2.3883 - val_loss: 3.3183 - val_mean_squared_error: 3.3183\n",
      "Epoch 80/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 2.1125 - mean_squared_error: 2.1125 - val_loss: 2.8445 - val_mean_squared_error: 2.8445\n",
      "Epoch 81/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 2.0523 - mean_squared_error: 2.0523 - val_loss: 2.8366 - val_mean_squared_error: 2.8366\n",
      "Epoch 82/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 2.1869 - mean_squared_error: 2.1869 - val_loss: 3.1136 - val_mean_squared_error: 3.1136\n",
      "Epoch 83/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 2.0336 - mean_squared_error: 2.0336 - val_loss: 2.9036 - val_mean_squared_error: 2.9036\n",
      "Epoch 84/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.0065 - mean_squared_error: 2.0065 - val_loss: 2.8619 - val_mean_squared_error: 2.8619\n",
      "Epoch 85/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 2.0738 - mean_squared_error: 2.0738 - val_loss: 2.9731 - val_mean_squared_error: 2.9731\n",
      "Epoch 86/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 2.0655 - mean_squared_error: 2.0655 - val_loss: 3.1213 - val_mean_squared_error: 3.1213\n",
      "Epoch 87/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.9298 - mean_squared_error: 1.9298 - val_loss: 3.0174 - val_mean_squared_error: 3.0174\n",
      "Epoch 88/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 2.0916 - mean_squared_error: 2.0916 - val_loss: 2.8660 - val_mean_squared_error: 2.8660\n",
      "Epoch 89/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 2.0164 - mean_squared_error: 2.0164 - val_loss: 2.9128 - val_mean_squared_error: 2.9128\n",
      "Epoch 90/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.9267 - mean_squared_error: 1.9267 - val_loss: 3.1250 - val_mean_squared_error: 3.1250\n",
      "Epoch 91/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.9650 - mean_squared_error: 1.9650 - val_loss: 3.1595 - val_mean_squared_error: 3.1595\n",
      "Epoch 92/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.9861 - mean_squared_error: 1.9861 - val_loss: 3.1093 - val_mean_squared_error: 3.1093\n",
      "Epoch 93/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.9010 - mean_squared_error: 1.9010 - val_loss: 2.9757 - val_mean_squared_error: 2.9757\n",
      "Epoch 94/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.8175 - mean_squared_error: 1.8175 - val_loss: 3.2554 - val_mean_squared_error: 3.2554\n",
      "Epoch 95/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.8225 - mean_squared_error: 1.8225 - val_loss: 3.5748 - val_mean_squared_error: 3.5748\n",
      "Epoch 96/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.8990 - mean_squared_error: 1.8990 - val_loss: 3.0798 - val_mean_squared_error: 3.0798\n",
      "Epoch 97/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.8155 - mean_squared_error: 1.8155 - val_loss: 3.1913 - val_mean_squared_error: 3.1913\n",
      "Epoch 98/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.8700 - mean_squared_error: 1.8700 - val_loss: 3.7334 - val_mean_squared_error: 3.7334\n",
      "Epoch 99/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.8188 - mean_squared_error: 1.8188 - val_loss: 2.8013 - val_mean_squared_error: 2.8013\n",
      "Epoch 100/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.8487 - mean_squared_error: 1.8487 - val_loss: 3.2970 - val_mean_squared_error: 3.2970\n",
      "Epoch 101/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.8507 - mean_squared_error: 1.8507 - val_loss: 2.7700 - val_mean_squared_error: 2.7700\n",
      "Epoch 102/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.8623 - mean_squared_error: 1.8623 - val_loss: 2.9504 - val_mean_squared_error: 2.9504\n",
      "Epoch 103/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.7331 - mean_squared_error: 1.7331 - val_loss: 2.8186 - val_mean_squared_error: 2.8186\n",
      "Epoch 104/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.6867 - mean_squared_error: 1.6867 - val_loss: 2.9748 - val_mean_squared_error: 2.9748\n",
      "Epoch 105/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.7059 - mean_squared_error: 1.7059 - val_loss: 3.1511 - val_mean_squared_error: 3.1511\n",
      "Epoch 106/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.8194 - mean_squared_error: 1.8194 - val_loss: 2.7627 - val_mean_squared_error: 2.7627\n",
      "Epoch 107/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.6714 - mean_squared_error: 1.6714 - val_loss: 2.8856 - val_mean_squared_error: 2.8856\n",
      "Epoch 108/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.9553 - mean_squared_error: 1.9553 - val_loss: 2.6807 - val_mean_squared_error: 2.6807\n",
      "Epoch 109/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.7114 - mean_squared_error: 1.7114 - val_loss: 2.7656 - val_mean_squared_error: 2.7656\n",
      "Epoch 110/200\n",
      "1819/1819 [==============================] - 11s 6ms/sample - loss: 1.7429 - mean_squared_error: 1.7429 - val_loss: 2.9426 - val_mean_squared_error: 2.9426\n",
      "Epoch 111/200\n",
      "1819/1819 [==============================] - 12s 6ms/sample - loss: 1.7503 - mean_squared_error: 1.7503 - val_loss: 2.8119 - val_mean_squared_error: 2.8119\n",
      "Epoch 112/200\n",
      "1819/1819 [==============================] - 12s 6ms/sample - loss: 1.6275 - mean_squared_error: 1.6275 - val_loss: 2.9232 - val_mean_squared_error: 2.9232\n",
      "Epoch 113/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.7583 - mean_squared_error: 1.7583 - val_loss: 3.2089 - val_mean_squared_error: 3.2089\n",
      "Epoch 114/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.6264 - mean_squared_error: 1.6264 - val_loss: 2.7955 - val_mean_squared_error: 2.7955\n",
      "Epoch 115/200\n",
      "1819/1819 [==============================] - 12s 6ms/sample - loss: 1.5386 - mean_squared_error: 1.5386 - val_loss: 2.7962 - val_mean_squared_error: 2.7962\n",
      "Epoch 116/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.5374 - mean_squared_error: 1.5374 - val_loss: 2.6832 - val_mean_squared_error: 2.6832\n",
      "Epoch 117/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.5548 - mean_squared_error: 1.5548 - val_loss: 2.6455 - val_mean_squared_error: 2.6455\n",
      "Epoch 118/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.5706 - mean_squared_error: 1.5706 - val_loss: 2.6157 - val_mean_squared_error: 2.6157\n",
      "Epoch 119/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.6380 - mean_squared_error: 1.6380 - val_loss: 2.7901 - val_mean_squared_error: 2.7901\n",
      "Epoch 120/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.5668 - mean_squared_error: 1.5668 - val_loss: 2.6276 - val_mean_squared_error: 2.6276\n",
      "Epoch 121/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.5540 - mean_squared_error: 1.5540 - val_loss: 2.9515 - val_mean_squared_error: 2.9515\n",
      "Epoch 122/200\n",
      "1819/1819 [==============================] - 12s 6ms/sample - loss: 1.6227 - mean_squared_error: 1.6227 - val_loss: 2.9238 - val_mean_squared_error: 2.9238\n",
      "Epoch 123/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.5074 - mean_squared_error: 1.5074 - val_loss: 2.7318 - val_mean_squared_error: 2.7318\n",
      "Epoch 124/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.5719 - mean_squared_error: 1.5719 - val_loss: 2.7174 - val_mean_squared_error: 2.7174\n",
      "Epoch 125/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.4719 - mean_squared_error: 1.4719 - val_loss: 2.9137 - val_mean_squared_error: 2.9137\n",
      "Epoch 126/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.5084 - mean_squared_error: 1.5084 - val_loss: 2.5448 - val_mean_squared_error: 2.5448\n",
      "Epoch 127/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.5153 - mean_squared_error: 1.5153 - val_loss: 2.7734 - val_mean_squared_error: 2.7734\n",
      "Epoch 128/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.4915 - mean_squared_error: 1.4915 - val_loss: 2.6974 - val_mean_squared_error: 2.6974\n",
      "Epoch 129/200\n",
      "1819/1819 [==============================] - 12s 6ms/sample - loss: 1.3887 - mean_squared_error: 1.3887 - val_loss: 2.5810 - val_mean_squared_error: 2.5810\n",
      "Epoch 130/200\n",
      "1819/1819 [==============================] - 12s 6ms/sample - loss: 1.4827 - mean_squared_error: 1.4827 - val_loss: 2.8224 - val_mean_squared_error: 2.8224\n",
      "Epoch 131/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.4122 - mean_squared_error: 1.4122 - val_loss: 2.9146 - val_mean_squared_error: 2.9146\n",
      "Epoch 132/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.4953 - mean_squared_error: 1.4953 - val_loss: 2.9121 - val_mean_squared_error: 2.9121\n",
      "Epoch 133/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.6043 - mean_squared_error: 1.6043 - val_loss: 2.7400 - val_mean_squared_error: 2.7400\n",
      "Epoch 134/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.4519 - mean_squared_error: 1.4519 - val_loss: 2.8328 - val_mean_squared_error: 2.8328\n",
      "Epoch 135/200\n",
      "1819/1819 [==============================] - 12s 6ms/sample - loss: 1.6016 - mean_squared_error: 1.6016 - val_loss: 2.6464 - val_mean_squared_error: 2.6464\n",
      "Epoch 136/200\n",
      "1819/1819 [==============================] - 12s 6ms/sample - loss: 1.4337 - mean_squared_error: 1.4337 - val_loss: 2.8458 - val_mean_squared_error: 2.8458\n",
      "Epoch 137/200\n",
      "1819/1819 [==============================] - 12s 6ms/sample - loss: 1.2947 - mean_squared_error: 1.2947 - val_loss: 2.4740 - val_mean_squared_error: 2.4740\n",
      "Epoch 138/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.4036 - mean_squared_error: 1.4036 - val_loss: 2.5969 - val_mean_squared_error: 2.5969\n",
      "Epoch 139/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.3525 - mean_squared_error: 1.3525 - val_loss: 2.7479 - val_mean_squared_error: 2.7479\n",
      "Epoch 140/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.4316 - mean_squared_error: 1.4316 - val_loss: 2.5533 - val_mean_squared_error: 2.5533\n",
      "Epoch 141/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.3585 - mean_squared_error: 1.3585 - val_loss: 2.9029 - val_mean_squared_error: 2.9029\n",
      "Epoch 142/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.4786 - mean_squared_error: 1.4786 - val_loss: 2.6506 - val_mean_squared_error: 2.6506\n",
      "Epoch 143/200\n",
      "1819/1819 [==============================] - 12s 6ms/sample - loss: 1.2664 - mean_squared_error: 1.2664 - val_loss: 2.7162 - val_mean_squared_error: 2.7162\n",
      "Epoch 144/200\n",
      "1819/1819 [==============================] - 12s 6ms/sample - loss: 1.3698 - mean_squared_error: 1.3698 - val_loss: 2.7399 - val_mean_squared_error: 2.7399\n",
      "Epoch 145/200\n",
      "1819/1819 [==============================] - 12s 6ms/sample - loss: 1.2991 - mean_squared_error: 1.2991 - val_loss: 2.8361 - val_mean_squared_error: 2.8361\n",
      "Epoch 146/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.3099 - mean_squared_error: 1.3099 - val_loss: 2.6840 - val_mean_squared_error: 2.6840\n",
      "Epoch 147/200\n",
      "1819/1819 [==============================] - 12s 6ms/sample - loss: 1.2999 - mean_squared_error: 1.2999 - val_loss: 2.9909 - val_mean_squared_error: 2.9909\n",
      "Epoch 148/200\n",
      "1819/1819 [==============================] - 12s 6ms/sample - loss: 1.4873 - mean_squared_error: 1.4873 - val_loss: 2.5284 - val_mean_squared_error: 2.5284\n",
      "Epoch 149/200\n",
      "1819/1819 [==============================] - 12s 6ms/sample - loss: 1.3241 - mean_squared_error: 1.3241 - val_loss: 2.6657 - val_mean_squared_error: 2.6657\n",
      "Epoch 150/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.3463 - mean_squared_error: 1.3463 - val_loss: 2.9471 - val_mean_squared_error: 2.9471\n",
      "Epoch 151/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.3371 - mean_squared_error: 1.3371 - val_loss: 3.1850 - val_mean_squared_error: 3.1850\n",
      "Epoch 152/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.2637 - mean_squared_error: 1.2637 - val_loss: 2.7793 - val_mean_squared_error: 2.7793\n",
      "Epoch 153/200\n",
      "1819/1819 [==============================] - 12s 6ms/sample - loss: 1.3446 - mean_squared_error: 1.3446 - val_loss: 2.8634 - val_mean_squared_error: 2.8634\n",
      "Epoch 154/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.3842 - mean_squared_error: 1.3842 - val_loss: 2.7284 - val_mean_squared_error: 2.7284\n",
      "Epoch 155/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.3491 - mean_squared_error: 1.3491 - val_loss: 2.8900 - val_mean_squared_error: 2.8900\n",
      "Epoch 156/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.2965 - mean_squared_error: 1.2965 - val_loss: 2.7038 - val_mean_squared_error: 2.7038\n",
      "Epoch 157/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.3458 - mean_squared_error: 1.3458 - val_loss: 2.9113 - val_mean_squared_error: 2.9113\n",
      "Epoch 158/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.3722 - mean_squared_error: 1.3722 - val_loss: 3.0211 - val_mean_squared_error: 3.0211\n",
      "Epoch 159/200\n",
      "1819/1819 [==============================] - 12s 6ms/sample - loss: 1.3047 - mean_squared_error: 1.3047 - val_loss: 2.6014 - val_mean_squared_error: 2.6014\n",
      "Epoch 160/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.2356 - mean_squared_error: 1.2356 - val_loss: 3.1593 - val_mean_squared_error: 3.1593\n",
      "Epoch 161/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.2435 - mean_squared_error: 1.2435 - val_loss: 2.7011 - val_mean_squared_error: 2.7011\n",
      "Epoch 162/200\n",
      "1819/1819 [==============================] - 12s 6ms/sample - loss: 1.3430 - mean_squared_error: 1.3430 - val_loss: 2.6721 - val_mean_squared_error: 2.6721\n",
      "Epoch 163/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.2264 - mean_squared_error: 1.2264 - val_loss: 2.5861 - val_mean_squared_error: 2.5861\n",
      "Epoch 164/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.2578 - mean_squared_error: 1.2578 - val_loss: 2.6537 - val_mean_squared_error: 2.6537\n",
      "Epoch 165/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.2903 - mean_squared_error: 1.2903 - val_loss: 3.3364 - val_mean_squared_error: 3.3364\n",
      "Epoch 166/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.2218 - mean_squared_error: 1.2218 - val_loss: 2.6590 - val_mean_squared_error: 2.6590\n",
      "Epoch 167/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.2407 - mean_squared_error: 1.2407 - val_loss: 2.6704 - val_mean_squared_error: 2.6704\n",
      "Epoch 168/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.2493 - mean_squared_error: 1.2493 - val_loss: 2.7694 - val_mean_squared_error: 2.7694\n",
      "Epoch 169/200\n",
      "1819/1819 [==============================] - 12s 6ms/sample - loss: 1.2189 - mean_squared_error: 1.2189 - val_loss: 2.5981 - val_mean_squared_error: 2.5981\n",
      "Epoch 170/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.2276 - mean_squared_error: 1.2276 - val_loss: 3.0747 - val_mean_squared_error: 3.0747\n",
      "Epoch 171/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.2141 - mean_squared_error: 1.2141 - val_loss: 2.7183 - val_mean_squared_error: 2.7183\n",
      "Epoch 172/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.3408 - mean_squared_error: 1.3408 - val_loss: 2.4628 - val_mean_squared_error: 2.4628\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.2065 - mean_squared_error: 1.2065 - val_loss: 2.5533 - val_mean_squared_error: 2.5533\n",
      "Epoch 174/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.2170 - mean_squared_error: 1.2170 - val_loss: 2.9342 - val_mean_squared_error: 2.9342\n",
      "Epoch 175/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.2118 - mean_squared_error: 1.2118 - val_loss: 2.6220 - val_mean_squared_error: 2.6220\n",
      "Epoch 176/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.2388 - mean_squared_error: 1.2388 - val_loss: 2.5504 - val_mean_squared_error: 2.5504\n",
      "Epoch 177/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.1988 - mean_squared_error: 1.1988 - val_loss: 2.9284 - val_mean_squared_error: 2.9284\n",
      "Epoch 178/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.1347 - mean_squared_error: 1.1347 - val_loss: 2.7356 - val_mean_squared_error: 2.7356\n",
      "Epoch 179/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.1695 - mean_squared_error: 1.1695 - val_loss: 2.5871 - val_mean_squared_error: 2.5871\n",
      "Epoch 180/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.2699 - mean_squared_error: 1.2699 - val_loss: 2.9357 - val_mean_squared_error: 2.9357\n",
      "Epoch 181/200\n",
      "1819/1819 [==============================] - 13s 7ms/sample - loss: 1.1850 - mean_squared_error: 1.1850 - val_loss: 2.4529 - val_mean_squared_error: 2.4529\n",
      "Epoch 182/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.1178 - mean_squared_error: 1.1178 - val_loss: 2.6877 - val_mean_squared_error: 2.6877\n",
      "Epoch 183/200\n",
      "1819/1819 [==============================] - 12s 6ms/sample - loss: 1.1426 - mean_squared_error: 1.1426 - val_loss: 2.7056 - val_mean_squared_error: 2.7056\n",
      "Epoch 184/200\n",
      "1819/1819 [==============================] - 12s 6ms/sample - loss: 1.2164 - mean_squared_error: 1.2164 - val_loss: 2.7715 - val_mean_squared_error: 2.7715\n",
      "Epoch 185/200\n",
      "1819/1819 [==============================] - 12s 6ms/sample - loss: 1.1548 - mean_squared_error: 1.1548 - val_loss: 2.8596 - val_mean_squared_error: 2.8596\n",
      "Epoch 186/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.1044 - mean_squared_error: 1.1044 - val_loss: 2.6706 - val_mean_squared_error: 2.6706\n",
      "Epoch 187/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.1046 - mean_squared_error: 1.1046 - val_loss: 2.4451 - val_mean_squared_error: 2.4451\n",
      "Epoch 188/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.1298 - mean_squared_error: 1.1298 - val_loss: 2.6880 - val_mean_squared_error: 2.6880\n",
      "Epoch 189/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.0678 - mean_squared_error: 1.0678 - val_loss: 2.5733 - val_mean_squared_error: 2.5733\n",
      "Epoch 190/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.1430 - mean_squared_error: 1.1430 - val_loss: 2.5686 - val_mean_squared_error: 2.5686\n",
      "Epoch 191/200\n",
      "1819/1819 [==============================] - 12s 6ms/sample - loss: 1.0751 - mean_squared_error: 1.0751 - val_loss: 2.5775 - val_mean_squared_error: 2.5775\n",
      "Epoch 192/200\n",
      "1819/1819 [==============================] - 12s 6ms/sample - loss: 1.0993 - mean_squared_error: 1.0993 - val_loss: 2.5972 - val_mean_squared_error: 2.5972\n",
      "Epoch 193/200\n",
      "1819/1819 [==============================] - 12s 6ms/sample - loss: 1.0511 - mean_squared_error: 1.0511 - val_loss: 2.7163 - val_mean_squared_error: 2.7163\n",
      "Epoch 194/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.2161 - mean_squared_error: 1.2161 - val_loss: 3.0734 - val_mean_squared_error: 3.0734\n",
      "Epoch 195/200\n",
      "1819/1819 [==============================] - 12s 6ms/sample - loss: 1.1541 - mean_squared_error: 1.1541 - val_loss: 2.8107 - val_mean_squared_error: 2.8107\n",
      "Epoch 196/200\n",
      "1819/1819 [==============================] - 12s 6ms/sample - loss: 1.1321 - mean_squared_error: 1.1321 - val_loss: 2.4524 - val_mean_squared_error: 2.4524\n",
      "Epoch 197/200\n",
      "1819/1819 [==============================] - 12s 6ms/sample - loss: 1.1122 - mean_squared_error: 1.1122 - val_loss: 2.5597 - val_mean_squared_error: 2.5597\n",
      "Epoch 198/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.0401 - mean_squared_error: 1.0401 - val_loss: 2.9413 - val_mean_squared_error: 2.9413\n",
      "Epoch 199/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.1820 - mean_squared_error: 1.1820 - val_loss: 2.7309 - val_mean_squared_error: 2.7309\n",
      "Epoch 200/200\n",
      "1819/1819 [==============================] - 12s 7ms/sample - loss: 1.1250 - mean_squared_error: 1.1250 - val_loss: 2.7404 - val_mean_squared_error: 2.7404\n"
     ]
    }
   ],
   "source": [
    "# Redefine optimizer list to just focus on adam and sgd\n",
    "opt_list = {'adam':adam}\n",
    "\n",
    "# Use an early stopping callback and our timing callback\n",
    "early_stop = callbacks.EarlyStopping(monitor='val_loss', min_delta=0.1,\n",
    "                              patience=100, mode='auto')\n",
    "time_callback = TimeHistory()\n",
    "\n",
    "# Initialize a new data frame to hold our output data\n",
    "cnn_flipped_df = pd.DataFrame()\n",
    "\n",
    "# Start filter list\n",
    "start_filters = [12]\n",
    "\n",
    "# Flag for using or not using bias term\n",
    "biases = [False]\n",
    "\n",
    "# Create a list of initial dropout values and steps to increase\n",
    "dropouts = [(0.00,0.01)]\n",
    "\n",
    "for opt_name, opt in opt_list.items():\n",
    "    for start_filter in start_filters:\n",
    "        for bias in biases:\n",
    "            for d in dropouts:\n",
    "                model = create_batchnorm_cnn_model(start_filter, d[0], d[1], bias)\n",
    "                model.compile(\n",
    "                      optimizer=opt,\n",
    "                      loss='mean_squared_error',\n",
    "                      metrics=['mean_squared_error'])\n",
    "                history = model.fit(\n",
    "                    flipped_X.astype(np.float32), flipped_y.astype(np.float32),\n",
    "                    epochs=200,\n",
    "                    validation_split=0.15, callbacks=[time_callback, early_stop])\n",
    "                times = time_callback.times\n",
    "\n",
    "                # Convert to dataframe\n",
    "                hist = pd.DataFrame(history.history)\n",
    "                hist['epoch'] = history.epoch\n",
    "                hist['RMSE'] = np.sqrt(hist.mean_squared_error)\n",
    "                hist['val_RMSE'] = np.sqrt(hist.val_mean_squared_error)\n",
    "                hist['times'] = times\n",
    "                hist['starting_filter'] = start_filter\n",
    "                hist['layers'] = 3\n",
    "                hist['pooling'] = 'yes'\n",
    "                hist['fc_layer'] = 500\n",
    "                hist['activation'] = 'relu'\n",
    "                hist['optimizer'] = opt_name\n",
    "                hist['lrate'] = opt.get_config()['learning_rate']\n",
    "                hist['dropout_initial'] = d[0]\n",
    "                hist['dropout_step'] = d[1]\n",
    "                hist['batch_norm'] = 1\n",
    "                hist['bias'] = int(bias)\n",
    "                hist['w_flipped'] = 1\n",
    "\n",
    "                # Keep concatenating to dataframe\n",
    "                cnn_flipped_df = pd.concat([cnn_flipped_df,hist])\n",
    "\n",
    "                # Re-pickle after every model to retain progress\n",
    "                cnn_flipped_df.to_pickle(\"OutputData/cnn_flipped_df.pkl\")\n",
    "\n",
    "                # Save models.\n",
    "                filename = \"cnn_flipped_model_{}_d{}_s{}_sf{}\".format(opt_name, d[0], d[1], start_filter)\n",
    "                model.save(\"Models/\"+filename+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_eye_center_x</th>\n",
       "      <th>left_eye_center_y</th>\n",
       "      <th>right_eye_center_x</th>\n",
       "      <th>right_eye_center_y</th>\n",
       "      <th>left_eye_inner_corner_x</th>\n",
       "      <th>left_eye_inner_corner_y</th>\n",
       "      <th>left_eye_outer_corner_x</th>\n",
       "      <th>left_eye_outer_corner_y</th>\n",
       "      <th>right_eye_inner_corner_x</th>\n",
       "      <th>right_eye_inner_corner_y</th>\n",
       "      <th>...</th>\n",
       "      <th>nose_tip_x</th>\n",
       "      <th>nose_tip_y</th>\n",
       "      <th>mouth_left_corner_x</th>\n",
       "      <th>mouth_left_corner_y</th>\n",
       "      <th>mouth_right_corner_x</th>\n",
       "      <th>mouth_right_corner_y</th>\n",
       "      <th>mouth_center_top_lip_x</th>\n",
       "      <th>mouth_center_top_lip_y</th>\n",
       "      <th>mouth_center_bottom_lip_x</th>\n",
       "      <th>mouth_center_bottom_lip_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2140.000000</td>\n",
       "      <td>2140.000000</td>\n",
       "      <td>2140.000000</td>\n",
       "      <td>2140.000000</td>\n",
       "      <td>2140.000000</td>\n",
       "      <td>2140.000000</td>\n",
       "      <td>2140.000000</td>\n",
       "      <td>2140.000000</td>\n",
       "      <td>2140.000000</td>\n",
       "      <td>2140.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2140.000000</td>\n",
       "      <td>2140.000000</td>\n",
       "      <td>2140.000000</td>\n",
       "      <td>2140.000000</td>\n",
       "      <td>2140.000000</td>\n",
       "      <td>2140.000000</td>\n",
       "      <td>2140.000000</td>\n",
       "      <td>2140.000000</td>\n",
       "      <td>2140.000000</td>\n",
       "      <td>2140.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>66.221549</td>\n",
       "      <td>36.842274</td>\n",
       "      <td>29.640269</td>\n",
       "      <td>37.063815</td>\n",
       "      <td>59.272128</td>\n",
       "      <td>37.856014</td>\n",
       "      <td>73.412473</td>\n",
       "      <td>37.640110</td>\n",
       "      <td>36.603107</td>\n",
       "      <td>37.920852</td>\n",
       "      <td>...</td>\n",
       "      <td>47.952141</td>\n",
       "      <td>57.253926</td>\n",
       "      <td>63.419076</td>\n",
       "      <td>75.887660</td>\n",
       "      <td>32.967365</td>\n",
       "      <td>76.134065</td>\n",
       "      <td>48.081325</td>\n",
       "      <td>72.681125</td>\n",
       "      <td>48.149654</td>\n",
       "      <td>82.630412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.087683</td>\n",
       "      <td>2.294027</td>\n",
       "      <td>2.051575</td>\n",
       "      <td>2.234334</td>\n",
       "      <td>2.005631</td>\n",
       "      <td>2.034500</td>\n",
       "      <td>2.701639</td>\n",
       "      <td>2.684162</td>\n",
       "      <td>1.822784</td>\n",
       "      <td>2.009505</td>\n",
       "      <td>...</td>\n",
       "      <td>3.276053</td>\n",
       "      <td>4.528635</td>\n",
       "      <td>3.650131</td>\n",
       "      <td>4.438565</td>\n",
       "      <td>3.595103</td>\n",
       "      <td>4.259514</td>\n",
       "      <td>2.723274</td>\n",
       "      <td>5.108675</td>\n",
       "      <td>3.032389</td>\n",
       "      <td>4.813557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>47.835757</td>\n",
       "      <td>23.832996</td>\n",
       "      <td>18.922611</td>\n",
       "      <td>24.773072</td>\n",
       "      <td>41.779381</td>\n",
       "      <td>27.190098</td>\n",
       "      <td>52.947144</td>\n",
       "      <td>26.250023</td>\n",
       "      <td>24.112624</td>\n",
       "      <td>26.250023</td>\n",
       "      <td>...</td>\n",
       "      <td>24.472590</td>\n",
       "      <td>41.558400</td>\n",
       "      <td>43.869480</td>\n",
       "      <td>57.023258</td>\n",
       "      <td>9.778137</td>\n",
       "      <td>56.690208</td>\n",
       "      <td>32.260312</td>\n",
       "      <td>56.719043</td>\n",
       "      <td>33.047605</td>\n",
       "      <td>57.232296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>65.046300</td>\n",
       "      <td>35.468842</td>\n",
       "      <td>28.472224</td>\n",
       "      <td>35.818377</td>\n",
       "      <td>58.113054</td>\n",
       "      <td>36.607950</td>\n",
       "      <td>71.741978</td>\n",
       "      <td>36.102409</td>\n",
       "      <td>35.495730</td>\n",
       "      <td>36.766783</td>\n",
       "      <td>...</td>\n",
       "      <td>46.495330</td>\n",
       "      <td>54.466000</td>\n",
       "      <td>61.341291</td>\n",
       "      <td>72.874263</td>\n",
       "      <td>30.879288</td>\n",
       "      <td>73.280038</td>\n",
       "      <td>46.580004</td>\n",
       "      <td>69.271669</td>\n",
       "      <td>46.492000</td>\n",
       "      <td>79.417480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>66.129065</td>\n",
       "      <td>36.913319</td>\n",
       "      <td>29.655440</td>\n",
       "      <td>37.048085</td>\n",
       "      <td>59.327154</td>\n",
       "      <td>37.845220</td>\n",
       "      <td>73.240045</td>\n",
       "      <td>37.624207</td>\n",
       "      <td>36.620735</td>\n",
       "      <td>37.920336</td>\n",
       "      <td>...</td>\n",
       "      <td>47.900511</td>\n",
       "      <td>57.638582</td>\n",
       "      <td>63.199057</td>\n",
       "      <td>75.682465</td>\n",
       "      <td>33.034022</td>\n",
       "      <td>75.941985</td>\n",
       "      <td>47.939031</td>\n",
       "      <td>72.395978</td>\n",
       "      <td>47.980854</td>\n",
       "      <td>82.388899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>67.332093</td>\n",
       "      <td>38.286438</td>\n",
       "      <td>30.858673</td>\n",
       "      <td>38.333884</td>\n",
       "      <td>60.521492</td>\n",
       "      <td>39.195431</td>\n",
       "      <td>74.978684</td>\n",
       "      <td>39.308331</td>\n",
       "      <td>37.665280</td>\n",
       "      <td>39.143921</td>\n",
       "      <td>...</td>\n",
       "      <td>49.260657</td>\n",
       "      <td>60.303524</td>\n",
       "      <td>65.302398</td>\n",
       "      <td>78.774969</td>\n",
       "      <td>35.063575</td>\n",
       "      <td>78.884031</td>\n",
       "      <td>49.290000</td>\n",
       "      <td>75.840286</td>\n",
       "      <td>49.551936</td>\n",
       "      <td>85.697976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>78.013082</td>\n",
       "      <td>46.132421</td>\n",
       "      <td>42.495172</td>\n",
       "      <td>45.980981</td>\n",
       "      <td>69.023030</td>\n",
       "      <td>47.190316</td>\n",
       "      <td>87.032252</td>\n",
       "      <td>49.653825</td>\n",
       "      <td>47.293746</td>\n",
       "      <td>44.887301</td>\n",
       "      <td>...</td>\n",
       "      <td>65.279654</td>\n",
       "      <td>75.992731</td>\n",
       "      <td>84.767123</td>\n",
       "      <td>94.673637</td>\n",
       "      <td>50.973348</td>\n",
       "      <td>93.443176</td>\n",
       "      <td>61.804506</td>\n",
       "      <td>93.916338</td>\n",
       "      <td>62.438095</td>\n",
       "      <td>95.808983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       left_eye_center_x  left_eye_center_y  right_eye_center_x  \\\n",
       "count        2140.000000        2140.000000         2140.000000   \n",
       "mean           66.221549          36.842274           29.640269   \n",
       "std             2.087683           2.294027            2.051575   \n",
       "min            47.835757          23.832996           18.922611   \n",
       "25%            65.046300          35.468842           28.472224   \n",
       "50%            66.129065          36.913319           29.655440   \n",
       "75%            67.332093          38.286438           30.858673   \n",
       "max            78.013082          46.132421           42.495172   \n",
       "\n",
       "       right_eye_center_y  left_eye_inner_corner_x  left_eye_inner_corner_y  \\\n",
       "count         2140.000000              2140.000000              2140.000000   \n",
       "mean            37.063815                59.272128                37.856014   \n",
       "std              2.234334                 2.005631                 2.034500   \n",
       "min             24.773072                41.779381                27.190098   \n",
       "25%             35.818377                58.113054                36.607950   \n",
       "50%             37.048085                59.327154                37.845220   \n",
       "75%             38.333884                60.521492                39.195431   \n",
       "max             45.980981                69.023030                47.190316   \n",
       "\n",
       "       left_eye_outer_corner_x  left_eye_outer_corner_y  \\\n",
       "count              2140.000000              2140.000000   \n",
       "mean                 73.412473                37.640110   \n",
       "std                   2.701639                 2.684162   \n",
       "min                  52.947144                26.250023   \n",
       "25%                  71.741978                36.102409   \n",
       "50%                  73.240045                37.624207   \n",
       "75%                  74.978684                39.308331   \n",
       "max                  87.032252                49.653825   \n",
       "\n",
       "       right_eye_inner_corner_x  right_eye_inner_corner_y  ...   nose_tip_x  \\\n",
       "count               2140.000000               2140.000000  ...  2140.000000   \n",
       "mean                  36.603107                 37.920852  ...    47.952141   \n",
       "std                    1.822784                  2.009505  ...     3.276053   \n",
       "min                   24.112624                 26.250023  ...    24.472590   \n",
       "25%                   35.495730                 36.766783  ...    46.495330   \n",
       "50%                   36.620735                 37.920336  ...    47.900511   \n",
       "75%                   37.665280                 39.143921  ...    49.260657   \n",
       "max                   47.293746                 44.887301  ...    65.279654   \n",
       "\n",
       "        nose_tip_y  mouth_left_corner_x  mouth_left_corner_y  \\\n",
       "count  2140.000000          2140.000000          2140.000000   \n",
       "mean     57.253926            63.419076            75.887660   \n",
       "std       4.528635             3.650131             4.438565   \n",
       "min      41.558400            43.869480            57.023258   \n",
       "25%      54.466000            61.341291            72.874263   \n",
       "50%      57.638582            63.199057            75.682465   \n",
       "75%      60.303524            65.302398            78.774969   \n",
       "max      75.992731            84.767123            94.673637   \n",
       "\n",
       "       mouth_right_corner_x  mouth_right_corner_y  mouth_center_top_lip_x  \\\n",
       "count           2140.000000           2140.000000             2140.000000   \n",
       "mean              32.967365             76.134065               48.081325   \n",
       "std                3.595103              4.259514                2.723274   \n",
       "min                9.778137             56.690208               32.260312   \n",
       "25%               30.879288             73.280038               46.580004   \n",
       "50%               33.034022             75.941985               47.939031   \n",
       "75%               35.063575             78.884031               49.290000   \n",
       "max               50.973348             93.443176               61.804506   \n",
       "\n",
       "       mouth_center_top_lip_y  mouth_center_bottom_lip_x  \\\n",
       "count             2140.000000                2140.000000   \n",
       "mean                72.681125                  48.149654   \n",
       "std                  5.108675                   3.032389   \n",
       "min                 56.719043                  33.047605   \n",
       "25%                 69.271669                  46.492000   \n",
       "50%                 72.395978                  47.980854   \n",
       "75%                 75.840286                  49.551936   \n",
       "max                 93.916338                  62.438095   \n",
       "\n",
       "       mouth_center_bottom_lip_y  \n",
       "count                2140.000000  \n",
       "mean                   82.630412  \n",
       "std                     4.813557  \n",
       "min                    57.232296  \n",
       "25%                    79.417480  \n",
       "50%                    82.388899  \n",
       "75%                    85.697976  \n",
       "max                    95.808983  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nostache_nonan.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_eye_center_x</th>\n",
       "      <th>left_eye_center_y</th>\n",
       "      <th>right_eye_center_x</th>\n",
       "      <th>right_eye_center_y</th>\n",
       "      <th>left_eye_inner_corner_x</th>\n",
       "      <th>left_eye_inner_corner_y</th>\n",
       "      <th>left_eye_outer_corner_x</th>\n",
       "      <th>left_eye_outer_corner_y</th>\n",
       "      <th>right_eye_inner_corner_x</th>\n",
       "      <th>right_eye_inner_corner_y</th>\n",
       "      <th>...</th>\n",
       "      <th>nose_tip_x</th>\n",
       "      <th>nose_tip_y</th>\n",
       "      <th>mouth_left_corner_x</th>\n",
       "      <th>mouth_left_corner_y</th>\n",
       "      <th>mouth_right_corner_x</th>\n",
       "      <th>mouth_right_corner_y</th>\n",
       "      <th>mouth_center_top_lip_x</th>\n",
       "      <th>mouth_center_top_lip_y</th>\n",
       "      <th>mouth_center_bottom_lip_x</th>\n",
       "      <th>mouth_center_bottom_lip_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>2140.000000</td>\n",
       "      <td>2140.000000</td>\n",
       "      <td>2140.000000</td>\n",
       "      <td>2140.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>66.290640</td>\n",
       "      <td>36.953045</td>\n",
       "      <td>29.709360</td>\n",
       "      <td>36.953045</td>\n",
       "      <td>59.334511</td>\n",
       "      <td>37.888433</td>\n",
       "      <td>73.525428</td>\n",
       "      <td>37.837340</td>\n",
       "      <td>36.665489</td>\n",
       "      <td>37.888433</td>\n",
       "      <td>...</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>57.253926</td>\n",
       "      <td>63.419076</td>\n",
       "      <td>75.887660</td>\n",
       "      <td>32.967365</td>\n",
       "      <td>76.134065</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>72.681125</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>82.630412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.070619</td>\n",
       "      <td>2.266821</td>\n",
       "      <td>2.070619</td>\n",
       "      <td>2.266821</td>\n",
       "      <td>1.917181</td>\n",
       "      <td>2.022065</td>\n",
       "      <td>2.737440</td>\n",
       "      <td>2.676539</td>\n",
       "      <td>1.917181</td>\n",
       "      <td>2.022065</td>\n",
       "      <td>...</td>\n",
       "      <td>3.276020</td>\n",
       "      <td>4.528106</td>\n",
       "      <td>3.650131</td>\n",
       "      <td>4.438565</td>\n",
       "      <td>3.595103</td>\n",
       "      <td>4.259514</td>\n",
       "      <td>2.724170</td>\n",
       "      <td>5.108078</td>\n",
       "      <td>3.035727</td>\n",
       "      <td>4.812995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>47.835757</td>\n",
       "      <td>23.832996</td>\n",
       "      <td>17.986918</td>\n",
       "      <td>23.832996</td>\n",
       "      <td>41.779381</td>\n",
       "      <td>26.250023</td>\n",
       "      <td>52.947144</td>\n",
       "      <td>26.250023</td>\n",
       "      <td>24.112624</td>\n",
       "      <td>26.250023</td>\n",
       "      <td>...</td>\n",
       "      <td>24.472590</td>\n",
       "      <td>41.558400</td>\n",
       "      <td>43.869480</td>\n",
       "      <td>57.023258</td>\n",
       "      <td>9.778137</td>\n",
       "      <td>56.690208</td>\n",
       "      <td>32.260312</td>\n",
       "      <td>56.719043</td>\n",
       "      <td>33.047605</td>\n",
       "      <td>57.232296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>65.079955</td>\n",
       "      <td>35.633097</td>\n",
       "      <td>28.551911</td>\n",
       "      <td>35.633097</td>\n",
       "      <td>58.232667</td>\n",
       "      <td>36.697102</td>\n",
       "      <td>71.759468</td>\n",
       "      <td>36.312200</td>\n",
       "      <td>35.487722</td>\n",
       "      <td>36.697102</td>\n",
       "      <td>...</td>\n",
       "      <td>46.592401</td>\n",
       "      <td>54.466000</td>\n",
       "      <td>61.341291</td>\n",
       "      <td>72.874263</td>\n",
       "      <td>30.879288</td>\n",
       "      <td>73.280038</td>\n",
       "      <td>46.637398</td>\n",
       "      <td>69.271669</td>\n",
       "      <td>46.468306</td>\n",
       "      <td>79.417480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>66.229337</td>\n",
       "      <td>36.993760</td>\n",
       "      <td>29.770663</td>\n",
       "      <td>36.993760</td>\n",
       "      <td>59.349723</td>\n",
       "      <td>37.885465</td>\n",
       "      <td>73.337304</td>\n",
       "      <td>37.760388</td>\n",
       "      <td>36.650277</td>\n",
       "      <td>37.885465</td>\n",
       "      <td>...</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>57.638582</td>\n",
       "      <td>63.199057</td>\n",
       "      <td>75.682465</td>\n",
       "      <td>33.034022</td>\n",
       "      <td>75.941985</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>72.395978</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>82.388899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>67.448089</td>\n",
       "      <td>38.313314</td>\n",
       "      <td>30.920045</td>\n",
       "      <td>38.313314</td>\n",
       "      <td>60.512278</td>\n",
       "      <td>39.179978</td>\n",
       "      <td>75.174171</td>\n",
       "      <td>39.348700</td>\n",
       "      <td>37.767333</td>\n",
       "      <td>39.179978</td>\n",
       "      <td>...</td>\n",
       "      <td>49.407599</td>\n",
       "      <td>60.303524</td>\n",
       "      <td>65.302398</td>\n",
       "      <td>78.774969</td>\n",
       "      <td>35.063575</td>\n",
       "      <td>78.884031</td>\n",
       "      <td>49.362602</td>\n",
       "      <td>75.840286</td>\n",
       "      <td>49.531694</td>\n",
       "      <td>85.697976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>78.013082</td>\n",
       "      <td>46.132421</td>\n",
       "      <td>48.164243</td>\n",
       "      <td>46.132421</td>\n",
       "      <td>71.887376</td>\n",
       "      <td>47.190316</td>\n",
       "      <td>87.032252</td>\n",
       "      <td>50.002113</td>\n",
       "      <td>54.220619</td>\n",
       "      <td>47.190316</td>\n",
       "      <td>...</td>\n",
       "      <td>71.527410</td>\n",
       "      <td>75.992731</td>\n",
       "      <td>84.767123</td>\n",
       "      <td>94.673637</td>\n",
       "      <td>50.973348</td>\n",
       "      <td>93.443176</td>\n",
       "      <td>63.739688</td>\n",
       "      <td>93.916338</td>\n",
       "      <td>62.952395</td>\n",
       "      <td>95.808983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       left_eye_center_x  left_eye_center_y  right_eye_center_x  \\\n",
       "count        4280.000000        4280.000000         4280.000000   \n",
       "mean           66.290640          36.953045           29.709360   \n",
       "std             2.070619           2.266821            2.070619   \n",
       "min            47.835757          23.832996           17.986918   \n",
       "25%            65.079955          35.633097           28.551911   \n",
       "50%            66.229337          36.993760           29.770663   \n",
       "75%            67.448089          38.313314           30.920045   \n",
       "max            78.013082          46.132421           48.164243   \n",
       "\n",
       "       right_eye_center_y  left_eye_inner_corner_x  left_eye_inner_corner_y  \\\n",
       "count         4280.000000              4280.000000              4280.000000   \n",
       "mean            36.953045                59.334511                37.888433   \n",
       "std              2.266821                 1.917181                 2.022065   \n",
       "min             23.832996                41.779381                26.250023   \n",
       "25%             35.633097                58.232667                36.697102   \n",
       "50%             36.993760                59.349723                37.885465   \n",
       "75%             38.313314                60.512278                39.179978   \n",
       "max             46.132421                71.887376                47.190316   \n",
       "\n",
       "       left_eye_outer_corner_x  left_eye_outer_corner_y  \\\n",
       "count              4280.000000              4280.000000   \n",
       "mean                 73.525428                37.837340   \n",
       "std                   2.737440                 2.676539   \n",
       "min                  52.947144                26.250023   \n",
       "25%                  71.759468                36.312200   \n",
       "50%                  73.337304                37.760388   \n",
       "75%                  75.174171                39.348700   \n",
       "max                  87.032252                50.002113   \n",
       "\n",
       "       right_eye_inner_corner_x  right_eye_inner_corner_y  ...   nose_tip_x  \\\n",
       "count               4280.000000               4280.000000  ...  4280.000000   \n",
       "mean                  36.665489                 37.888433  ...    48.000000   \n",
       "std                    1.917181                  2.022065  ...     3.276020   \n",
       "min                   24.112624                 26.250023  ...    24.472590   \n",
       "25%                   35.487722                 36.697102  ...    46.592401   \n",
       "50%                   36.650277                 37.885465  ...    48.000000   \n",
       "75%                   37.767333                 39.179978  ...    49.407599   \n",
       "max                   54.220619                 47.190316  ...    71.527410   \n",
       "\n",
       "        nose_tip_y  mouth_left_corner_x  mouth_left_corner_y  \\\n",
       "count  4280.000000          2140.000000          2140.000000   \n",
       "mean     57.253926            63.419076            75.887660   \n",
       "std       4.528106             3.650131             4.438565   \n",
       "min      41.558400            43.869480            57.023258   \n",
       "25%      54.466000            61.341291            72.874263   \n",
       "50%      57.638582            63.199057            75.682465   \n",
       "75%      60.303524            65.302398            78.774969   \n",
       "max      75.992731            84.767123            94.673637   \n",
       "\n",
       "       mouth_right_corner_x  mouth_right_corner_y  mouth_center_top_lip_x  \\\n",
       "count           2140.000000           2140.000000             4280.000000   \n",
       "mean              32.967365             76.134065               48.000000   \n",
       "std                3.595103              4.259514                2.724170   \n",
       "min                9.778137             56.690208               32.260312   \n",
       "25%               30.879288             73.280038               46.637398   \n",
       "50%               33.034022             75.941985               48.000000   \n",
       "75%               35.063575             78.884031               49.362602   \n",
       "max               50.973348             93.443176               63.739688   \n",
       "\n",
       "       mouth_center_top_lip_y  mouth_center_bottom_lip_x  \\\n",
       "count             4280.000000                4280.000000   \n",
       "mean                72.681125                  48.000000   \n",
       "std                  5.108078                   3.035727   \n",
       "min                 56.719043                  33.047605   \n",
       "25%                 69.271669                  46.468306   \n",
       "50%                 72.395978                  48.000000   \n",
       "75%                 75.840286                  49.531694   \n",
       "max                 93.916338                  62.952395   \n",
       "\n",
       "       mouth_center_bottom_lip_y  \n",
       "count                4280.000000  \n",
       "mean                   82.630412  \n",
       "std                     4.812995  \n",
       "min                    57.232296  \n",
       "25%                    79.417480  \n",
       "50%                    82.388899  \n",
       "75%                    85.697976  \n",
       "max                    95.808983  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flipped.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG Net\n",
    "Visual Graphics Group at Oxford came up with this architecture. It uses many stacked convolution layers. We will use it as inspiration and see how it performs relative to our base cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vgg_model(start_filter, d, step, bias):\n",
    "    '''\n",
    "    Simple function that retruns a keras cnn model \n",
    "    '''\n",
    "    cnn_model = tf.keras.models.Sequential()\n",
    "    \n",
    "    # Input layer is our grayscale image that is 96 pixels by 96 pixels\n",
    "    cnn_model.add(tf.keras.layers.InputLayer(input_shape=(96, 96, 1)))\n",
    "    \n",
    "    # Add our first convolution layers which is two back-to-back conv with 3x3 kernel and same padding\n",
    "    # Add depth with filters\n",
    "    # Our output from these convolutions will be (96,96,start_filter)\n",
    "    if bias:\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter, (3, 3), padding='same', activation='relu'))\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter, (3, 3), padding='same', activation='relu'))\n",
    "    else:\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter, (3, 3), use_bias=False, \n",
    "                                             padding='same', activation='relu'))\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter, (3, 3), use_bias=False, \n",
    "                                             padding='same', activation='relu'))\n",
    "    # Normalize our features\n",
    "    cnn_model.add(layers.BatchNormalization())\n",
    "    \n",
    "    # Use a max pooling layer to cut our features in half\n",
    "    # Output size will be (48,48,32)\n",
    "    cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Add some random dropout\n",
    "    cnn_model.add(tf.keras.layers.Dropout(d))\n",
    "    \n",
    "    # Add our second convolution layers which is three back-to-back conv with 3x3 kernel and same padding\n",
    "    # Double filter depth - output layer will be (48,48,start_filter*2)\n",
    "    if bias:\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter*2, (3, 3), padding='same', activation='relu'))\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter*2, (3, 3), padding='same', activation='relu'))\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter*2, (3, 3), padding='same', activation='relu'))\n",
    "    else:\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter*2, (3, 3), use_bias=False, \n",
    "                                             padding='same', activation='relu'))\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter*2, (3, 3), use_bias=False, \n",
    "                                             padding='same', activation='relu'))\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter*2, (3, 3), use_bias=False, \n",
    "                                             padding='same', activation='relu'))\n",
    "    \n",
    "    # Normalize our features\n",
    "    cnn_model.add(layers.BatchNormalization())\n",
    "    \n",
    "    # Use a max pooling layer to cut our features in half\n",
    "    # Output size will be (24,24,start_filter*2)\n",
    "    cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Add some random dropout\n",
    "    cnn_model.add(tf.keras.layers.Dropout(d+step))\n",
    "    \n",
    "    # Add our third convolution layers which is three back-to-back conv with 3x3 kernel and same padding\n",
    "    # Double filter depth again - output layer will be (24,24,start_filter*4)\n",
    "    if bias:\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter*4, (3, 3), padding='same', activation='relu'))\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter*4, (3, 3), padding='same', activation='relu'))\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter*4, (3, 3), padding='same', activation='relu'))\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter*4, (3, 3), padding='same', activation='relu'))\n",
    "    else:\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter*4, (3, 3), use_bias=False, \n",
    "                                             padding='same', activation='relu'))\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter*4, (3, 3), use_bias=False, \n",
    "                                             padding='same', activation='relu'))\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter*4, (3, 3), use_bias=False, \n",
    "                                             padding='same', activation='relu'))\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter*4, (3, 3), use_bias=False, \n",
    "                                             padding='same', activation='relu'))\n",
    "    \n",
    "    # Normalize our features\n",
    "    cnn_model.add(layers.BatchNormalization())\n",
    "    \n",
    "    # Use a max pooling layer to cut our features in half\n",
    "    # Output size will be (12,12,start_filter*4)\n",
    "    cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Add some random dropout\n",
    "    cnn_model.add(tf.keras.layers.Dropout(d+2*step))\n",
    "    \n",
    "    # Add our fourth and final convolution layers which is three back-to-back conv with 3x3 kernel and same padding\n",
    "    # Double filter depth again - output layer will be (12,12,start_filter*8)\n",
    "    if bias:\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter*8, (3, 3), padding='same', activation='relu'))\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter*8, (3, 3), padding='same', activation='relu'))\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter*8, (3, 3), padding='same', activation='relu'))\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter*8, (3, 3), padding='same', activation='relu'))\n",
    "    else:\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter*8, (3, 3), use_bias=False, \n",
    "                                             padding='same', activation='relu'))\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter*8, (3, 3), use_bias=False, \n",
    "                                             padding='same', activation='relu'))\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter*8, (3, 3), use_bias=False, \n",
    "                                             padding='same', activation='relu'))\n",
    "        cnn_model.add(tf.keras.layers.Conv2D(start_filter*8, (3, 3), use_bias=False, \n",
    "                                             padding='same', activation='relu'))\n",
    "        \n",
    "    # Normalize our features\n",
    "    cnn_model.add(layers.BatchNormalization())\n",
    "    \n",
    "    # Use a max pooling layer to cut our features in half\n",
    "    # Output size will be (6,6,start_filter*8)\n",
    "    cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Flatten and transition to fully connected layers\n",
    "    cnn_model.add(tf.keras.layers.Flatten())\n",
    "    cnn_model.add(tf.keras.layers.Dense(500))\n",
    "    cnn_model.add(layers.BatchNormalization())\n",
    "    cnn_model.add(tf.keras.layers.Dropout(d+3*step))\n",
    "    cnn_model.add(tf.keras.layers.Activation('relu'))\n",
    "    cnn_model.add(tf.keras.layers.Dense(500))\n",
    "    cnn_model.add(layers.BatchNormalization())\n",
    "    cnn_model.add(tf.keras.layers.Activation('relu'))\n",
    "    cnn_model.add(tf.keras.layers.Dense(30))\n",
    "    cnn_model.add(tf.keras.layers.Activation('linear'))\n",
    "\n",
    "    print(50*\"=\")\n",
    "    print(cnn_model.summary())\n",
    "    print(50*\"=\")\n",
    "    \n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 96, 96, 16)        144       \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 96, 96, 16)        2304      \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 96, 96, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 48, 48, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 48, 48, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 48, 48, 32)        4608      \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 48, 48, 32)        9216      \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 48, 48, 32)        9216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 24, 24, 64)        18432     \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 24, 24, 64)        36864     \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 24, 24, 64)        36864     \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 24, 24, 64)        36864     \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 12, 12, 128)       73728     \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 12, 12, 128)       147456    \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 12, 12, 128)       147456    \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 12, 12, 128)       147456    \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 500)               2304500   \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 30)                15030     \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 30)                0         \n",
      "=================================================================\n",
      "Total params: 3,245,598\n",
      "Trainable params: 3,243,118\n",
      "Non-trainable params: 2,480\n",
      "_________________________________________________________________\n",
      "None\n",
      "==================================================\n",
      "Train on 1819 samples, validate on 321 samples\n",
      "Epoch 1/200\n",
      "1819/1819 [==============================] - 40s 22ms/sample - loss: 689.6851 - mean_squared_error: 689.6851 - val_loss: 581.2650 - val_mean_squared_error: 581.2649\n",
      "Epoch 2/200\n",
      "1819/1819 [==============================] - 37s 20ms/sample - loss: 28.3836 - mean_squared_error: 28.3836 - val_loss: 45.2646 - val_mean_squared_error: 45.2646\n",
      "Epoch 3/200\n",
      "1819/1819 [==============================] - 41s 23ms/sample - loss: 19.9271 - mean_squared_error: 19.9271 - val_loss: 25.8761 - val_mean_squared_error: 25.8761\n",
      "Epoch 4/200\n",
      "1819/1819 [==============================] - 37s 20ms/sample - loss: 17.1823 - mean_squared_error: 17.1823 - val_loss: 20.3940 - val_mean_squared_error: 20.3940\n",
      "Epoch 5/200\n",
      "1819/1819 [==============================] - 35s 19ms/sample - loss: 18.8397 - mean_squared_error: 18.8397 - val_loss: 16.9772 - val_mean_squared_error: 16.9772\n",
      "Epoch 6/200\n",
      "1819/1819 [==============================] - 37s 20ms/sample - loss: 15.5589 - mean_squared_error: 15.5588 - val_loss: 19.4891 - val_mean_squared_error: 19.4891\n",
      "Epoch 7/200\n",
      "1819/1819 [==============================] - 36s 20ms/sample - loss: 15.2700 - mean_squared_error: 15.2700 - val_loss: 12.0536 - val_mean_squared_error: 12.0536\n",
      "Epoch 8/200\n",
      "1819/1819 [==============================] - 37s 20ms/sample - loss: 16.9458 - mean_squared_error: 16.9458 - val_loss: 11.5016 - val_mean_squared_error: 11.5016\n",
      "Epoch 9/200\n",
      "1819/1819 [==============================] - 36s 20ms/sample - loss: 14.3164 - mean_squared_error: 14.3164 - val_loss: 11.0034 - val_mean_squared_error: 11.0034\n",
      "Epoch 10/200\n",
      "1819/1819 [==============================] - 38s 21ms/sample - loss: 13.7713 - mean_squared_error: 13.7713 - val_loss: 12.2465 - val_mean_squared_error: 12.2465\n",
      "Epoch 11/200\n",
      "1819/1819 [==============================] - 35s 19ms/sample - loss: 14.4110 - mean_squared_error: 14.4110 - val_loss: 12.1149 - val_mean_squared_error: 12.1149\n",
      "Epoch 12/200\n",
      "1819/1819 [==============================] - 39s 21ms/sample - loss: 13.3304 - mean_squared_error: 13.3304 - val_loss: 10.8526 - val_mean_squared_error: 10.8526\n",
      "Epoch 13/200\n",
      "1819/1819 [==============================] - 51s 28ms/sample - loss: 12.7122 - mean_squared_error: 12.7122 - val_loss: 10.5057 - val_mean_squared_error: 10.5057\n",
      "Epoch 14/200\n",
      "1600/1819 [=========================>....] - ETA: 14s - loss: 13.8200 - mean_squared_error: 13.8200"
     ]
    }
   ],
   "source": [
    "# Redefine optimizer list to just focus on adam and sgd\n",
    "opt_list = {'adam':adam}\n",
    "\n",
    "# Use an early stopping callback and our timing callback\n",
    "early_stop = callbacks.EarlyStopping(monitor='val_loss', min_delta=0.1,\n",
    "                              patience=100, mode='auto')\n",
    "time_callback = TimeHistory()\n",
    "\n",
    "# Initialize a new data frame to hold our output data\n",
    "cnn_vgg_df = pd.DataFrame()\n",
    "\n",
    "# Start filter list\n",
    "start_filters = [16]\n",
    "\n",
    "# Flag for using or not using bias term\n",
    "biases = [False]\n",
    "\n",
    "# Create a list of initial dropout values and steps to increase\n",
    "dropouts = [(0.0,0.00)]\n",
    "\n",
    "for opt_name, opt in opt_list.items():\n",
    "    for start_filter in start_filters:\n",
    "        for bias in biases:\n",
    "            for d in dropouts:\n",
    "                model = create_vgg_model(start_filter, d[0], d[1], bias)\n",
    "                model.compile(\n",
    "                      optimizer=opt,\n",
    "                      loss='mean_squared_error',\n",
    "                      metrics=['mean_squared_error'])\n",
    "                history = model.fit(\n",
    "                    X.astype(np.float32), y.astype(np.float32),\n",
    "                    epochs=200,\n",
    "                    validation_split=0.15, callbacks=[time_callback, early_stop])\n",
    "                times = time_callback.times\n",
    "\n",
    "                # Convert to dataframe\n",
    "                hist = pd.DataFrame(history.history)\n",
    "                hist['epoch'] = history.epoch\n",
    "                hist['RMSE'] = np.sqrt(hist.mean_squared_error)\n",
    "                hist['val_RMSE'] = np.sqrt(hist.val_mean_squared_error)\n",
    "                hist['times'] = times\n",
    "                hist['starting_filter'] = start_filter\n",
    "                hist['layers'] = 4\n",
    "                hist['pooling'] = 'yes'\n",
    "                hist['fc_layer'] = 500\n",
    "                hist['activation'] = 'relu'\n",
    "                hist['optimizer'] = opt_name\n",
    "                hist['lrate'] = opt.get_config()['learning_rate']\n",
    "                hist['dropout_initial'] = d[0]\n",
    "                hist['dropout_step'] = d[1]\n",
    "                hist['batch_norm'] = 1\n",
    "                hist['bias'] = int(bias)\n",
    "                hist['arch'] = 'vgg'\n",
    "\n",
    "                # Keep concatenating to dataframe\n",
    "                cnn_vgg_df = pd.concat([cnn_vgg_df,hist])\n",
    "\n",
    "                # Re-pickle after every model to retain progress\n",
    "                cnn_vgg_df.to_pickle(\"OutputData/cnn_vgg_df.pkl\")\n",
    "\n",
    "                # Save models.\n",
    "                filename = \"cnn_vgg_model_{}_d{}_s{}_sf{}\".format(opt_name, d[0], d[1], start_filter)\n",
    "                model.save(\"Models/\"+filename+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
