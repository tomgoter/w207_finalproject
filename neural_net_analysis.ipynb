{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net Analysis Notebook\n",
    "## W207 Final Project\n",
    "### T. P. Goter\n",
    "### July 6, 2019\n",
    "\n",
    "This workbook is used to assess various models created as part of the Facial Keypoint Detection project for W207."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the packages we need\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual, fixed\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mean_squared_error</th>\n",
       "      <th>epoch</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>val_RMSE</th>\n",
       "      <th>times</th>\n",
       "      <th>hunits</th>\n",
       "      <th>activation</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>lrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>2.036483</td>\n",
       "      <td>2.036483</td>\n",
       "      <td>32.099414</td>\n",
       "      <td>32.099411</td>\n",
       "      <td>320</td>\n",
       "      <td>1.427054</td>\n",
       "      <td>5.665634</td>\n",
       "      <td>0.480469</td>\n",
       "      <td>200</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>11.933042</td>\n",
       "      <td>11.933043</td>\n",
       "      <td>11.323600</td>\n",
       "      <td>11.323601</td>\n",
       "      <td>31</td>\n",
       "      <td>3.454424</td>\n",
       "      <td>3.365056</td>\n",
       "      <td>0.794000</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>10.228678</td>\n",
       "      <td>10.228679</td>\n",
       "      <td>9.917707</td>\n",
       "      <td>9.917706</td>\n",
       "      <td>242</td>\n",
       "      <td>3.198231</td>\n",
       "      <td>3.149239</td>\n",
       "      <td>0.372951</td>\n",
       "      <td>150</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>9.929816</td>\n",
       "      <td>9.929816</td>\n",
       "      <td>9.631700</td>\n",
       "      <td>9.631701</td>\n",
       "      <td>269</td>\n",
       "      <td>3.151161</td>\n",
       "      <td>3.103498</td>\n",
       "      <td>0.543546</td>\n",
       "      <td>150</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>10.225569</td>\n",
       "      <td>10.225570</td>\n",
       "      <td>9.914820</td>\n",
       "      <td>9.914820</td>\n",
       "      <td>251</td>\n",
       "      <td>3.197744</td>\n",
       "      <td>3.148781</td>\n",
       "      <td>1.192174</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>nadam</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>14.142279</td>\n",
       "      <td>14.142282</td>\n",
       "      <td>44.739003</td>\n",
       "      <td>44.739006</td>\n",
       "      <td>179</td>\n",
       "      <td>3.760622</td>\n",
       "      <td>6.688722</td>\n",
       "      <td>0.196416</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>10.271638</td>\n",
       "      <td>10.271636</td>\n",
       "      <td>9.937835</td>\n",
       "      <td>9.937836</td>\n",
       "      <td>115</td>\n",
       "      <td>3.204939</td>\n",
       "      <td>3.152433</td>\n",
       "      <td>0.268572</td>\n",
       "      <td>100</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>10.194059</td>\n",
       "      <td>10.194060</td>\n",
       "      <td>9.886653</td>\n",
       "      <td>9.886653</td>\n",
       "      <td>70</td>\n",
       "      <td>3.192814</td>\n",
       "      <td>3.144305</td>\n",
       "      <td>0.190728</td>\n",
       "      <td>50</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>16.051545</td>\n",
       "      <td>16.051546</td>\n",
       "      <td>42.511925</td>\n",
       "      <td>42.511925</td>\n",
       "      <td>95</td>\n",
       "      <td>4.006438</td>\n",
       "      <td>6.520117</td>\n",
       "      <td>0.385449</td>\n",
       "      <td>150</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>10.229621</td>\n",
       "      <td>10.229621</td>\n",
       "      <td>9.928338</td>\n",
       "      <td>9.928338</td>\n",
       "      <td>191</td>\n",
       "      <td>3.198378</td>\n",
       "      <td>3.150927</td>\n",
       "      <td>0.477043</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss  mean_squared_error   val_loss  val_mean_squared_error  epoch  \\\n",
       "320   2.036483            2.036483  32.099414               32.099411    320   \n",
       "31   11.933042           11.933043  11.323600               11.323601     31   \n",
       "242  10.228678           10.228679   9.917707                9.917706    242   \n",
       "269   9.929816            9.929816   9.631700                9.631701    269   \n",
       "251  10.225569           10.225570   9.914820                9.914820    251   \n",
       "179  14.142279           14.142282  44.739003               44.739006    179   \n",
       "115  10.271638           10.271636   9.937835                9.937836    115   \n",
       "70   10.194059           10.194060   9.886653                9.886653     70   \n",
       "95   16.051545           16.051546  42.511925               42.511925     95   \n",
       "191  10.229621           10.229621   9.928338                9.928338    191   \n",
       "\n",
       "         RMSE  val_RMSE     times  hunits activation optimizer  lrate  \n",
       "320  1.427054  5.665634  0.480469     200       relu      adam  0.001  \n",
       "31   3.454424  3.365056  0.794000     200    sigmoid   adagrad  0.010  \n",
       "242  3.198231  3.149239  0.372951     150       tanh      adam  0.001  \n",
       "269  3.151161  3.103498  0.543546     150    sigmoid   adagrad  0.010  \n",
       "251  3.197744  3.148781  1.192174     200    sigmoid     nadam  0.002  \n",
       "179  3.760622  6.688722  0.196416      50       relu      adam  0.001  \n",
       "115  3.204939  3.152433  0.268572     100    sigmoid       sgd  0.010  \n",
       "70   3.192814  3.144305  0.190728      50       tanh      adam  0.001  \n",
       "95   4.006438  6.520117  0.385449     150       relu      adam  0.001  \n",
       "191  3.198378  3.150927  0.477043     200       tanh      adam  0.001  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pkled dataframe for the baseline single layer neural net\n",
    "bl_sl_df = pd.read_pickle(\"OutputData/single_layer_df.pkl\")\n",
    "bl_sl_df['cum_times'] = bl_sl_df.groupby(['hunits', 'activation', 'optimizer', 'lrate']).times.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mean_squared_error</th>\n",
       "      <th>epoch</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>val_RMSE</th>\n",
       "      <th>times</th>\n",
       "      <th>hunits</th>\n",
       "      <th>activation</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>lrate</th>\n",
       "      <th>cum_times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28010.575914</td>\n",
       "      <td>28010.572266</td>\n",
       "      <td>2291.178069</td>\n",
       "      <td>2291.178223</td>\n",
       "      <td>0</td>\n",
       "      <td>167.363593</td>\n",
       "      <td>47.866253</td>\n",
       "      <td>0.265849</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.265849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1619.893235</td>\n",
       "      <td>1619.893311</td>\n",
       "      <td>1050.184416</td>\n",
       "      <td>1050.184448</td>\n",
       "      <td>1</td>\n",
       "      <td>40.247898</td>\n",
       "      <td>32.406549</td>\n",
       "      <td>0.166498</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.432347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>731.095874</td>\n",
       "      <td>731.095886</td>\n",
       "      <td>472.246410</td>\n",
       "      <td>472.246399</td>\n",
       "      <td>2</td>\n",
       "      <td>27.038785</td>\n",
       "      <td>21.731231</td>\n",
       "      <td>0.166131</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.598478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>330.953334</td>\n",
       "      <td>330.953400</td>\n",
       "      <td>215.345170</td>\n",
       "      <td>215.345169</td>\n",
       "      <td>3</td>\n",
       "      <td>18.192125</td>\n",
       "      <td>14.674644</td>\n",
       "      <td>0.165214</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.763692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>152.905530</td>\n",
       "      <td>152.905533</td>\n",
       "      <td>101.042233</td>\n",
       "      <td>101.042221</td>\n",
       "      <td>4</td>\n",
       "      <td>12.365498</td>\n",
       "      <td>10.051976</td>\n",
       "      <td>0.192475</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.956167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>73.695376</td>\n",
       "      <td>73.695374</td>\n",
       "      <td>50.227416</td>\n",
       "      <td>50.227413</td>\n",
       "      <td>5</td>\n",
       "      <td>8.584601</td>\n",
       "      <td>7.087130</td>\n",
       "      <td>0.173594</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.129761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>38.447532</td>\n",
       "      <td>38.447533</td>\n",
       "      <td>27.734740</td>\n",
       "      <td>27.734743</td>\n",
       "      <td>6</td>\n",
       "      <td>6.200607</td>\n",
       "      <td>5.266379</td>\n",
       "      <td>0.179937</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.309698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22.766007</td>\n",
       "      <td>22.766003</td>\n",
       "      <td>17.744032</td>\n",
       "      <td>17.744032</td>\n",
       "      <td>7</td>\n",
       "      <td>4.771373</td>\n",
       "      <td>4.212367</td>\n",
       "      <td>0.197338</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.507036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15.785918</td>\n",
       "      <td>15.785920</td>\n",
       "      <td>13.324637</td>\n",
       "      <td>13.324637</td>\n",
       "      <td>8</td>\n",
       "      <td>3.973150</td>\n",
       "      <td>3.650293</td>\n",
       "      <td>0.196654</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.703690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.676719</td>\n",
       "      <td>12.676719</td>\n",
       "      <td>11.381038</td>\n",
       "      <td>11.381038</td>\n",
       "      <td>9</td>\n",
       "      <td>3.560438</td>\n",
       "      <td>3.373579</td>\n",
       "      <td>0.197424</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.901114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.295556</td>\n",
       "      <td>11.295556</td>\n",
       "      <td>10.524236</td>\n",
       "      <td>10.524236</td>\n",
       "      <td>10</td>\n",
       "      <td>3.360886</td>\n",
       "      <td>3.244108</td>\n",
       "      <td>0.195943</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.097057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.680425</td>\n",
       "      <td>10.680424</td>\n",
       "      <td>10.151030</td>\n",
       "      <td>10.151030</td>\n",
       "      <td>11</td>\n",
       "      <td>3.268092</td>\n",
       "      <td>3.186068</td>\n",
       "      <td>0.194626</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.291683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.407656</td>\n",
       "      <td>10.407654</td>\n",
       "      <td>9.994275</td>\n",
       "      <td>9.994275</td>\n",
       "      <td>12</td>\n",
       "      <td>3.226090</td>\n",
       "      <td>3.161372</td>\n",
       "      <td>0.191835</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.483518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10.285179</td>\n",
       "      <td>10.285176</td>\n",
       "      <td>9.926514</td>\n",
       "      <td>9.926513</td>\n",
       "      <td>13</td>\n",
       "      <td>3.207051</td>\n",
       "      <td>3.150637</td>\n",
       "      <td>0.190176</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.673694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.232328</td>\n",
       "      <td>10.232327</td>\n",
       "      <td>9.897226</td>\n",
       "      <td>9.897226</td>\n",
       "      <td>14</td>\n",
       "      <td>3.198801</td>\n",
       "      <td>3.145986</td>\n",
       "      <td>0.197212</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.870906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10.208601</td>\n",
       "      <td>10.208599</td>\n",
       "      <td>9.886523</td>\n",
       "      <td>9.886524</td>\n",
       "      <td>15</td>\n",
       "      <td>3.195090</td>\n",
       "      <td>3.144284</td>\n",
       "      <td>0.195675</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.066581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10.197788</td>\n",
       "      <td>10.197786</td>\n",
       "      <td>9.883666</td>\n",
       "      <td>9.883667</td>\n",
       "      <td>16</td>\n",
       "      <td>3.193397</td>\n",
       "      <td>3.143830</td>\n",
       "      <td>0.198677</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.265258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10.193322</td>\n",
       "      <td>10.193323</td>\n",
       "      <td>9.881729</td>\n",
       "      <td>9.881729</td>\n",
       "      <td>17</td>\n",
       "      <td>3.192698</td>\n",
       "      <td>3.143522</td>\n",
       "      <td>0.190144</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.455402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10.190890</td>\n",
       "      <td>10.190888</td>\n",
       "      <td>9.882380</td>\n",
       "      <td>9.882380</td>\n",
       "      <td>18</td>\n",
       "      <td>3.192317</td>\n",
       "      <td>3.143625</td>\n",
       "      <td>0.192386</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.647788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10.189954</td>\n",
       "      <td>10.189955</td>\n",
       "      <td>9.882910</td>\n",
       "      <td>9.882910</td>\n",
       "      <td>19</td>\n",
       "      <td>3.192171</td>\n",
       "      <td>3.143710</td>\n",
       "      <td>0.189246</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.837034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10.189060</td>\n",
       "      <td>10.189058</td>\n",
       "      <td>9.883073</td>\n",
       "      <td>9.883073</td>\n",
       "      <td>20</td>\n",
       "      <td>3.192030</td>\n",
       "      <td>3.143735</td>\n",
       "      <td>0.197904</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.034938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10.189136</td>\n",
       "      <td>10.189137</td>\n",
       "      <td>9.883344</td>\n",
       "      <td>9.883344</td>\n",
       "      <td>21</td>\n",
       "      <td>3.192043</td>\n",
       "      <td>3.143779</td>\n",
       "      <td>0.193161</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.228099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10.188972</td>\n",
       "      <td>10.188971</td>\n",
       "      <td>9.882991</td>\n",
       "      <td>9.882991</td>\n",
       "      <td>22</td>\n",
       "      <td>3.192017</td>\n",
       "      <td>3.143722</td>\n",
       "      <td>0.190955</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.419054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10.190036</td>\n",
       "      <td>10.190036</td>\n",
       "      <td>9.883156</td>\n",
       "      <td>9.883156</td>\n",
       "      <td>23</td>\n",
       "      <td>3.192184</td>\n",
       "      <td>3.143749</td>\n",
       "      <td>0.196169</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.615223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10.189199</td>\n",
       "      <td>10.189199</td>\n",
       "      <td>9.883128</td>\n",
       "      <td>9.883126</td>\n",
       "      <td>24</td>\n",
       "      <td>3.192053</td>\n",
       "      <td>3.143744</td>\n",
       "      <td>0.192374</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.807597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10.189037</td>\n",
       "      <td>10.189037</td>\n",
       "      <td>9.883755</td>\n",
       "      <td>9.883755</td>\n",
       "      <td>25</td>\n",
       "      <td>3.192027</td>\n",
       "      <td>3.143844</td>\n",
       "      <td>0.192280</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.999877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10.189171</td>\n",
       "      <td>10.189171</td>\n",
       "      <td>9.883424</td>\n",
       "      <td>9.883424</td>\n",
       "      <td>26</td>\n",
       "      <td>3.192048</td>\n",
       "      <td>3.143791</td>\n",
       "      <td>0.190844</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5.190721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10.189639</td>\n",
       "      <td>10.189639</td>\n",
       "      <td>9.883240</td>\n",
       "      <td>9.883240</td>\n",
       "      <td>27</td>\n",
       "      <td>3.192121</td>\n",
       "      <td>3.143762</td>\n",
       "      <td>0.190339</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5.381060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10.189099</td>\n",
       "      <td>10.189096</td>\n",
       "      <td>9.883447</td>\n",
       "      <td>9.883448</td>\n",
       "      <td>28</td>\n",
       "      <td>3.192036</td>\n",
       "      <td>3.143795</td>\n",
       "      <td>0.191548</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5.572608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10.188727</td>\n",
       "      <td>10.188728</td>\n",
       "      <td>9.883504</td>\n",
       "      <td>9.883505</td>\n",
       "      <td>29</td>\n",
       "      <td>3.191979</td>\n",
       "      <td>3.143804</td>\n",
       "      <td>0.193201</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5.765809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>10.346942</td>\n",
       "      <td>10.346941</td>\n",
       "      <td>9.920106</td>\n",
       "      <td>9.920107</td>\n",
       "      <td>370</td>\n",
       "      <td>3.216666</td>\n",
       "      <td>3.149620</td>\n",
       "      <td>0.395988</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>151.741212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>10.313827</td>\n",
       "      <td>10.313828</td>\n",
       "      <td>10.002073</td>\n",
       "      <td>10.002071</td>\n",
       "      <td>371</td>\n",
       "      <td>3.211515</td>\n",
       "      <td>3.162605</td>\n",
       "      <td>0.397263</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>152.138475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>10.306898</td>\n",
       "      <td>10.306899</td>\n",
       "      <td>9.967006</td>\n",
       "      <td>9.967007</td>\n",
       "      <td>372</td>\n",
       "      <td>3.210436</td>\n",
       "      <td>3.157057</td>\n",
       "      <td>0.397621</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>152.536096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>10.310567</td>\n",
       "      <td>10.310567</td>\n",
       "      <td>10.082919</td>\n",
       "      <td>10.082919</td>\n",
       "      <td>373</td>\n",
       "      <td>3.211007</td>\n",
       "      <td>3.175361</td>\n",
       "      <td>0.396995</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>152.933091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>10.309304</td>\n",
       "      <td>10.309303</td>\n",
       "      <td>10.013269</td>\n",
       "      <td>10.013270</td>\n",
       "      <td>374</td>\n",
       "      <td>3.210810</td>\n",
       "      <td>3.164375</td>\n",
       "      <td>0.395976</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>153.329067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>10.308249</td>\n",
       "      <td>10.308249</td>\n",
       "      <td>9.979765</td>\n",
       "      <td>9.979766</td>\n",
       "      <td>375</td>\n",
       "      <td>3.210646</td>\n",
       "      <td>3.159077</td>\n",
       "      <td>0.395793</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>153.724860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>10.316122</td>\n",
       "      <td>10.316121</td>\n",
       "      <td>9.984764</td>\n",
       "      <td>9.984764</td>\n",
       "      <td>376</td>\n",
       "      <td>3.211872</td>\n",
       "      <td>3.159868</td>\n",
       "      <td>0.397340</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>154.122200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>10.305968</td>\n",
       "      <td>10.305968</td>\n",
       "      <td>10.145667</td>\n",
       "      <td>10.145666</td>\n",
       "      <td>377</td>\n",
       "      <td>3.210291</td>\n",
       "      <td>3.185226</td>\n",
       "      <td>0.395974</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>154.518174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>10.319811</td>\n",
       "      <td>10.319810</td>\n",
       "      <td>10.059600</td>\n",
       "      <td>10.059599</td>\n",
       "      <td>378</td>\n",
       "      <td>3.212446</td>\n",
       "      <td>3.171687</td>\n",
       "      <td>0.398185</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>154.916359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>10.324991</td>\n",
       "      <td>10.324991</td>\n",
       "      <td>10.008092</td>\n",
       "      <td>10.008091</td>\n",
       "      <td>379</td>\n",
       "      <td>3.213252</td>\n",
       "      <td>3.163557</td>\n",
       "      <td>0.396807</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>155.313166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>10.316302</td>\n",
       "      <td>10.316301</td>\n",
       "      <td>10.274332</td>\n",
       "      <td>10.274332</td>\n",
       "      <td>380</td>\n",
       "      <td>3.211900</td>\n",
       "      <td>3.205360</td>\n",
       "      <td>0.395872</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>155.709038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>10.355930</td>\n",
       "      <td>10.355928</td>\n",
       "      <td>10.035330</td>\n",
       "      <td>10.035331</td>\n",
       "      <td>381</td>\n",
       "      <td>3.218063</td>\n",
       "      <td>3.167859</td>\n",
       "      <td>0.395187</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>156.104225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>10.322531</td>\n",
       "      <td>10.322530</td>\n",
       "      <td>9.982851</td>\n",
       "      <td>9.982849</td>\n",
       "      <td>382</td>\n",
       "      <td>3.212869</td>\n",
       "      <td>3.159565</td>\n",
       "      <td>0.397494</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>156.501719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>10.300704</td>\n",
       "      <td>10.300705</td>\n",
       "      <td>9.972132</td>\n",
       "      <td>9.972132</td>\n",
       "      <td>383</td>\n",
       "      <td>3.209471</td>\n",
       "      <td>3.157868</td>\n",
       "      <td>0.396135</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>156.897854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>10.356612</td>\n",
       "      <td>10.356612</td>\n",
       "      <td>9.964415</td>\n",
       "      <td>9.964416</td>\n",
       "      <td>384</td>\n",
       "      <td>3.218169</td>\n",
       "      <td>3.156646</td>\n",
       "      <td>0.397479</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>157.295333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>10.315353</td>\n",
       "      <td>10.315351</td>\n",
       "      <td>9.969181</td>\n",
       "      <td>9.969180</td>\n",
       "      <td>385</td>\n",
       "      <td>3.211752</td>\n",
       "      <td>3.157401</td>\n",
       "      <td>0.394701</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>157.690034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>10.334829</td>\n",
       "      <td>10.334830</td>\n",
       "      <td>9.952611</td>\n",
       "      <td>9.952612</td>\n",
       "      <td>386</td>\n",
       "      <td>3.214783</td>\n",
       "      <td>3.154776</td>\n",
       "      <td>0.396619</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>158.086653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>10.323140</td>\n",
       "      <td>10.323138</td>\n",
       "      <td>9.920694</td>\n",
       "      <td>9.920694</td>\n",
       "      <td>387</td>\n",
       "      <td>3.212964</td>\n",
       "      <td>3.149713</td>\n",
       "      <td>0.395752</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>158.482405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>10.299123</td>\n",
       "      <td>10.299122</td>\n",
       "      <td>9.903626</td>\n",
       "      <td>9.903626</td>\n",
       "      <td>388</td>\n",
       "      <td>3.209224</td>\n",
       "      <td>3.147003</td>\n",
       "      <td>0.400494</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>158.882899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>10.339846</td>\n",
       "      <td>10.339847</td>\n",
       "      <td>9.966111</td>\n",
       "      <td>9.966110</td>\n",
       "      <td>389</td>\n",
       "      <td>3.215563</td>\n",
       "      <td>3.156915</td>\n",
       "      <td>0.395095</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>159.277994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>10.329108</td>\n",
       "      <td>10.329108</td>\n",
       "      <td>10.059111</td>\n",
       "      <td>10.059111</td>\n",
       "      <td>390</td>\n",
       "      <td>3.213893</td>\n",
       "      <td>3.171610</td>\n",
       "      <td>0.396951</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>159.674945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>10.297079</td>\n",
       "      <td>10.297081</td>\n",
       "      <td>9.971048</td>\n",
       "      <td>9.971048</td>\n",
       "      <td>391</td>\n",
       "      <td>3.208907</td>\n",
       "      <td>3.157697</td>\n",
       "      <td>0.396823</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>160.071768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>10.305806</td>\n",
       "      <td>10.305807</td>\n",
       "      <td>10.114078</td>\n",
       "      <td>10.114079</td>\n",
       "      <td>392</td>\n",
       "      <td>3.210266</td>\n",
       "      <td>3.180264</td>\n",
       "      <td>0.397766</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>160.469534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>10.326233</td>\n",
       "      <td>10.326232</td>\n",
       "      <td>10.078709</td>\n",
       "      <td>10.078709</td>\n",
       "      <td>393</td>\n",
       "      <td>3.213445</td>\n",
       "      <td>3.174698</td>\n",
       "      <td>0.397049</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>160.866583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>10.308622</td>\n",
       "      <td>10.308621</td>\n",
       "      <td>10.017620</td>\n",
       "      <td>10.017621</td>\n",
       "      <td>394</td>\n",
       "      <td>3.210704</td>\n",
       "      <td>3.165063</td>\n",
       "      <td>0.398645</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>161.265228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>10.311956</td>\n",
       "      <td>10.311956</td>\n",
       "      <td>10.031062</td>\n",
       "      <td>10.031063</td>\n",
       "      <td>395</td>\n",
       "      <td>3.211224</td>\n",
       "      <td>3.167185</td>\n",
       "      <td>0.396075</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>161.661303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>10.323963</td>\n",
       "      <td>10.323963</td>\n",
       "      <td>10.076065</td>\n",
       "      <td>10.076065</td>\n",
       "      <td>396</td>\n",
       "      <td>3.213092</td>\n",
       "      <td>3.174282</td>\n",
       "      <td>0.396886</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>162.058189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>10.344393</td>\n",
       "      <td>10.344391</td>\n",
       "      <td>9.960818</td>\n",
       "      <td>9.960818</td>\n",
       "      <td>397</td>\n",
       "      <td>3.216270</td>\n",
       "      <td>3.156076</td>\n",
       "      <td>0.395299</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>162.453488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>10.293114</td>\n",
       "      <td>10.293115</td>\n",
       "      <td>9.939336</td>\n",
       "      <td>9.939336</td>\n",
       "      <td>398</td>\n",
       "      <td>3.208288</td>\n",
       "      <td>3.152671</td>\n",
       "      <td>0.396431</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>162.849919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>10.302657</td>\n",
       "      <td>10.302656</td>\n",
       "      <td>9.948581</td>\n",
       "      <td>9.948582</td>\n",
       "      <td>399</td>\n",
       "      <td>3.209775</td>\n",
       "      <td>3.154137</td>\n",
       "      <td>0.396593</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>163.246512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4800 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             loss  mean_squared_error     val_loss  val_mean_squared_error  \\\n",
       "0    28010.575914        28010.572266  2291.178069             2291.178223   \n",
       "1     1619.893235         1619.893311  1050.184416             1050.184448   \n",
       "2      731.095874          731.095886   472.246410              472.246399   \n",
       "3      330.953334          330.953400   215.345170              215.345169   \n",
       "4      152.905530          152.905533   101.042233              101.042221   \n",
       "5       73.695376           73.695374    50.227416               50.227413   \n",
       "6       38.447532           38.447533    27.734740               27.734743   \n",
       "7       22.766007           22.766003    17.744032               17.744032   \n",
       "8       15.785918           15.785920    13.324637               13.324637   \n",
       "9       12.676719           12.676719    11.381038               11.381038   \n",
       "10      11.295556           11.295556    10.524236               10.524236   \n",
       "11      10.680425           10.680424    10.151030               10.151030   \n",
       "12      10.407656           10.407654     9.994275                9.994275   \n",
       "13      10.285179           10.285176     9.926514                9.926513   \n",
       "14      10.232328           10.232327     9.897226                9.897226   \n",
       "15      10.208601           10.208599     9.886523                9.886524   \n",
       "16      10.197788           10.197786     9.883666                9.883667   \n",
       "17      10.193322           10.193323     9.881729                9.881729   \n",
       "18      10.190890           10.190888     9.882380                9.882380   \n",
       "19      10.189954           10.189955     9.882910                9.882910   \n",
       "20      10.189060           10.189058     9.883073                9.883073   \n",
       "21      10.189136           10.189137     9.883344                9.883344   \n",
       "22      10.188972           10.188971     9.882991                9.882991   \n",
       "23      10.190036           10.190036     9.883156                9.883156   \n",
       "24      10.189199           10.189199     9.883128                9.883126   \n",
       "25      10.189037           10.189037     9.883755                9.883755   \n",
       "26      10.189171           10.189171     9.883424                9.883424   \n",
       "27      10.189639           10.189639     9.883240                9.883240   \n",
       "28      10.189099           10.189096     9.883447                9.883448   \n",
       "29      10.188727           10.188728     9.883504                9.883505   \n",
       "..            ...                 ...          ...                     ...   \n",
       "370     10.346942           10.346941     9.920106                9.920107   \n",
       "371     10.313827           10.313828    10.002073               10.002071   \n",
       "372     10.306898           10.306899     9.967006                9.967007   \n",
       "373     10.310567           10.310567    10.082919               10.082919   \n",
       "374     10.309304           10.309303    10.013269               10.013270   \n",
       "375     10.308249           10.308249     9.979765                9.979766   \n",
       "376     10.316122           10.316121     9.984764                9.984764   \n",
       "377     10.305968           10.305968    10.145667               10.145666   \n",
       "378     10.319811           10.319810    10.059600               10.059599   \n",
       "379     10.324991           10.324991    10.008092               10.008091   \n",
       "380     10.316302           10.316301    10.274332               10.274332   \n",
       "381     10.355930           10.355928    10.035330               10.035331   \n",
       "382     10.322531           10.322530     9.982851                9.982849   \n",
       "383     10.300704           10.300705     9.972132                9.972132   \n",
       "384     10.356612           10.356612     9.964415                9.964416   \n",
       "385     10.315353           10.315351     9.969181                9.969180   \n",
       "386     10.334829           10.334830     9.952611                9.952612   \n",
       "387     10.323140           10.323138     9.920694                9.920694   \n",
       "388     10.299123           10.299122     9.903626                9.903626   \n",
       "389     10.339846           10.339847     9.966111                9.966110   \n",
       "390     10.329108           10.329108    10.059111               10.059111   \n",
       "391     10.297079           10.297081     9.971048                9.971048   \n",
       "392     10.305806           10.305807    10.114078               10.114079   \n",
       "393     10.326233           10.326232    10.078709               10.078709   \n",
       "394     10.308622           10.308621    10.017620               10.017621   \n",
       "395     10.311956           10.311956    10.031062               10.031063   \n",
       "396     10.323963           10.323963    10.076065               10.076065   \n",
       "397     10.344393           10.344391     9.960818                9.960818   \n",
       "398     10.293114           10.293115     9.939336                9.939336   \n",
       "399     10.302657           10.302656     9.948581                9.948582   \n",
       "\n",
       "     epoch        RMSE   val_RMSE     times  hunits activation optimizer  \\\n",
       "0        0  167.363593  47.866253  0.265849      50       relu       sgd   \n",
       "1        1   40.247898  32.406549  0.166498      50       relu       sgd   \n",
       "2        2   27.038785  21.731231  0.166131      50       relu       sgd   \n",
       "3        3   18.192125  14.674644  0.165214      50       relu       sgd   \n",
       "4        4   12.365498  10.051976  0.192475      50       relu       sgd   \n",
       "5        5    8.584601   7.087130  0.173594      50       relu       sgd   \n",
       "6        6    6.200607   5.266379  0.179937      50       relu       sgd   \n",
       "7        7    4.771373   4.212367  0.197338      50       relu       sgd   \n",
       "8        8    3.973150   3.650293  0.196654      50       relu       sgd   \n",
       "9        9    3.560438   3.373579  0.197424      50       relu       sgd   \n",
       "10      10    3.360886   3.244108  0.195943      50       relu       sgd   \n",
       "11      11    3.268092   3.186068  0.194626      50       relu       sgd   \n",
       "12      12    3.226090   3.161372  0.191835      50       relu       sgd   \n",
       "13      13    3.207051   3.150637  0.190176      50       relu       sgd   \n",
       "14      14    3.198801   3.145986  0.197212      50       relu       sgd   \n",
       "15      15    3.195090   3.144284  0.195675      50       relu       sgd   \n",
       "16      16    3.193397   3.143830  0.198677      50       relu       sgd   \n",
       "17      17    3.192698   3.143522  0.190144      50       relu       sgd   \n",
       "18      18    3.192317   3.143625  0.192386      50       relu       sgd   \n",
       "19      19    3.192171   3.143710  0.189246      50       relu       sgd   \n",
       "20      20    3.192030   3.143735  0.197904      50       relu       sgd   \n",
       "21      21    3.192043   3.143779  0.193161      50       relu       sgd   \n",
       "22      22    3.192017   3.143722  0.190955      50       relu       sgd   \n",
       "23      23    3.192184   3.143749  0.196169      50       relu       sgd   \n",
       "24      24    3.192053   3.143744  0.192374      50       relu       sgd   \n",
       "25      25    3.192027   3.143844  0.192280      50       relu       sgd   \n",
       "26      26    3.192048   3.143791  0.190844      50       relu       sgd   \n",
       "27      27    3.192121   3.143762  0.190339      50       relu       sgd   \n",
       "28      28    3.192036   3.143795  0.191548      50       relu       sgd   \n",
       "29      29    3.191979   3.143804  0.193201      50       relu       sgd   \n",
       "..     ...         ...        ...       ...     ...        ...       ...   \n",
       "370    370    3.216666   3.149620  0.395988     200       tanh       sgd   \n",
       "371    371    3.211515   3.162605  0.397263     200       tanh       sgd   \n",
       "372    372    3.210436   3.157057  0.397621     200       tanh       sgd   \n",
       "373    373    3.211007   3.175361  0.396995     200       tanh       sgd   \n",
       "374    374    3.210810   3.164375  0.395976     200       tanh       sgd   \n",
       "375    375    3.210646   3.159077  0.395793     200       tanh       sgd   \n",
       "376    376    3.211872   3.159868  0.397340     200       tanh       sgd   \n",
       "377    377    3.210291   3.185226  0.395974     200       tanh       sgd   \n",
       "378    378    3.212446   3.171687  0.398185     200       tanh       sgd   \n",
       "379    379    3.213252   3.163557  0.396807     200       tanh       sgd   \n",
       "380    380    3.211900   3.205360  0.395872     200       tanh       sgd   \n",
       "381    381    3.218063   3.167859  0.395187     200       tanh       sgd   \n",
       "382    382    3.212869   3.159565  0.397494     200       tanh       sgd   \n",
       "383    383    3.209471   3.157868  0.396135     200       tanh       sgd   \n",
       "384    384    3.218169   3.156646  0.397479     200       tanh       sgd   \n",
       "385    385    3.211752   3.157401  0.394701     200       tanh       sgd   \n",
       "386    386    3.214783   3.154776  0.396619     200       tanh       sgd   \n",
       "387    387    3.212964   3.149713  0.395752     200       tanh       sgd   \n",
       "388    388    3.209224   3.147003  0.400494     200       tanh       sgd   \n",
       "389    389    3.215563   3.156915  0.395095     200       tanh       sgd   \n",
       "390    390    3.213893   3.171610  0.396951     200       tanh       sgd   \n",
       "391    391    3.208907   3.157697  0.396823     200       tanh       sgd   \n",
       "392    392    3.210266   3.180264  0.397766     200       tanh       sgd   \n",
       "393    393    3.213445   3.174698  0.397049     200       tanh       sgd   \n",
       "394    394    3.210704   3.165063  0.398645     200       tanh       sgd   \n",
       "395    395    3.211224   3.167185  0.396075     200       tanh       sgd   \n",
       "396    396    3.213092   3.174282  0.396886     200       tanh       sgd   \n",
       "397    397    3.216270   3.156076  0.395299     200       tanh       sgd   \n",
       "398    398    3.208288   3.152671  0.396431     200       tanh       sgd   \n",
       "399    399    3.209775   3.154137  0.396593     200       tanh       sgd   \n",
       "\n",
       "     lrate   cum_times  \n",
       "0     0.01    0.265849  \n",
       "1     0.01    0.432347  \n",
       "2     0.01    0.598478  \n",
       "3     0.01    0.763692  \n",
       "4     0.01    0.956167  \n",
       "5     0.01    1.129761  \n",
       "6     0.01    1.309698  \n",
       "7     0.01    1.507036  \n",
       "8     0.01    1.703690  \n",
       "9     0.01    1.901114  \n",
       "10    0.01    2.097057  \n",
       "11    0.01    2.291683  \n",
       "12    0.01    2.483518  \n",
       "13    0.01    2.673694  \n",
       "14    0.01    2.870906  \n",
       "15    0.01    3.066581  \n",
       "16    0.01    3.265258  \n",
       "17    0.01    3.455402  \n",
       "18    0.01    3.647788  \n",
       "19    0.01    3.837034  \n",
       "20    0.01    4.034938  \n",
       "21    0.01    4.228099  \n",
       "22    0.01    4.419054  \n",
       "23    0.01    4.615223  \n",
       "24    0.01    4.807597  \n",
       "25    0.01    4.999877  \n",
       "26    0.01    5.190721  \n",
       "27    0.01    5.381060  \n",
       "28    0.01    5.572608  \n",
       "29    0.01    5.765809  \n",
       "..     ...         ...  \n",
       "370   0.01  151.741212  \n",
       "371   0.01  152.138475  \n",
       "372   0.01  152.536096  \n",
       "373   0.01  152.933091  \n",
       "374   0.01  153.329067  \n",
       "375   0.01  153.724860  \n",
       "376   0.01  154.122200  \n",
       "377   0.01  154.518174  \n",
       "378   0.01  154.916359  \n",
       "379   0.01  155.313166  \n",
       "380   0.01  155.709038  \n",
       "381   0.01  156.104225  \n",
       "382   0.01  156.501719  \n",
       "383   0.01  156.897854  \n",
       "384   0.01  157.295333  \n",
       "385   0.01  157.690034  \n",
       "386   0.01  158.086653  \n",
       "387   0.01  158.482405  \n",
       "388   0.01  158.882899  \n",
       "389   0.01  159.277994  \n",
       "390   0.01  159.674945  \n",
       "391   0.01  160.071768  \n",
       "392   0.01  160.469534  \n",
       "393   0.01  160.866583  \n",
       "394   0.01  161.265228  \n",
       "395   0.01  161.661303  \n",
       "396   0.01  162.058189  \n",
       "397   0.01  162.453488  \n",
       "398   0.01  162.849919  \n",
       "399   0.01  163.246512  \n",
       "\n",
       "[4800 rows x 13 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bl_sl_df[bl_sl_df.optimizer == 'sgd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plotting function to pass to the interact widget function\n",
    "def plot_validation_loss(df=bl_sl_df, optimizer = bl_sl_df.optimizer.unique(), \n",
    "                    activation = bl_sl_df.activation.unique(), \n",
    "                         ymax=[y for y in range(0,100)],\n",
    "                        timemax=250):\n",
    "    \n",
    "    # Subset the baseline df by the specified optimizer and activation\n",
    "    sub_df = df[df.optimizer.str.match(optimizer)]\n",
    "    sub_df = sub_df[sub_df.activation.str.match(activation)]\n",
    "     \n",
    "    # Group the neural net data by optimizer and activation\n",
    "    groups = sub_df.groupby(['hunits'])\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 20))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Loop over the grouped data and plot out epoch timing and validation loss data\n",
    "    for name, group in groups:\n",
    "        \n",
    "        # Plot training and validation losses by epoch\n",
    "        axes[0].plot(group.epoch, group.val_RMSE, label=str(name)+' Validation Loss')\n",
    "        axes[0].scatter(group.epoch, group.RMSE, label=str(name)+' Training Loss')\n",
    "        axes[0].set_ylim([0,ymax])\n",
    "        axes[0].set_xlabel('Epoch')\n",
    "        axes[0].set_ylabel('Root Mean Square Error')\n",
    "        axes[0].set_title(\"{} Optimizer and {} Activation\".format(group.optimizer.unique(), group.activation.unique()))\n",
    "        \n",
    "        # Plot train time by epoch\n",
    "        axes[1].scatter(group.epoch, group.times*1000, label=str(name)+' Fit Time')\n",
    "        axes[1].set_xlabel('Epoch')\n",
    "        axes[1].set_ylabel('Fit Time (milliseconds)')\n",
    "        axes[1].set_ylim([0,1000])\n",
    "        axes[1].legend()\n",
    "        \n",
    "        # Plot cumulative training time\n",
    "        axes[2].plot(group.epoch, group.cum_times, label=str(name)+' Fit Time (s)', lw=4)\n",
    "        axes[2].set_xlabel('Epoch')\n",
    "        axes[2].set_ylabel('Cumulative Fit Time (seconds)')\n",
    "        axes[2].grid(b=True)\n",
    "        axes[2].set_ylim([0,timemax])\n",
    "        axes[2].legend()\n",
    "        \n",
    "        # Plot cumulative validation loss by cumulative time\n",
    "        axes[3].plot(group.cum_times, group.val_RMSE, label=str(name)+' Validation Loss', lw=3)\n",
    "        axes[3].set_xlabel('Cumulative Fit Time (seconds)')\n",
    "        axes[3].set_ylabel('Validation RMSE')\n",
    "        axes[3].set_xlim([0,timemax])\n",
    "        axes[3].set_ylim([0,ymax])\n",
    "        axes[3].legend()\n",
    "    \n",
    "    # Add line for knr score\n",
    "    axes[0].axhline(2.49, label='kNR Score', lw=5, c='k')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Adjust the spacing of the subplots\n",
    "    fig.subplots_adjust(left=0.03, right=0.97, hspace=0.1, wspace=0.15)\n",
    "\n",
    "    # Add an overarching title for these plots\n",
    "    fig.suptitle(\"Performance Comparison for Single Layer, Fully Connected Neural Nets\",\n",
    "                 fontsize=18, y=0.93)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4c492eba134e598d24370511c61f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='optimizer', options=('adam', 'sgd', 'nadam', 'adagrad'), value='ad…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "interact_manual(plot_validation_loss, df=fixed(bl_sl_df), \n",
    "                optimizer = bl_sl_df.optimizer.unique(), \n",
    "                    activation = bl_sl_df.activation.unique(), ymax=10, timemax=250)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessment of Baseline Results\n",
    "\n",
    "Now that we have some real results, we can make some real assessments of what is working and what is not.\n",
    "\n",
    "1. Overall the sgd optimizer seems to be working the best. There is not a large difference between training and validation accuracies. In other words we aren't overfitting to the data.\n",
    "2. SGD is also faster than the other optimizers. It is relatively close to Adam. NAdam on the other hand is twice as slow.\n",
    "3. No neural net does better than our kNR model\n",
    "\n",
    "In the evaluation above, both the output layer used a linear activation function while the hidden layer used a user specified optimizer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Layer Assessment\n",
    "Based on the three different experiments run, we will use a linear final layer activation function. We will continue to assess sgd and adam optimizers. We likely do not need to train for more than 200 epochs or so to get reasonably converged nets.\n",
    "## Need to redo learning rate study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mean_squared_error</th>\n",
       "      <th>epoch</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>val_RMSE</th>\n",
       "      <th>times</th>\n",
       "      <th>hunits</th>\n",
       "      <th>activation</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>lrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>585.102651</td>\n",
       "      <td>585.102600</td>\n",
       "      <td>602.217882</td>\n",
       "      <td>602.217896</td>\n",
       "      <td>166</td>\n",
       "      <td>24.188894</td>\n",
       "      <td>24.540128</td>\n",
       "      <td>0.777923</td>\n",
       "      <td>200</td>\n",
       "      <td>relu</td>\n",
       "      <td>adagrad_02</td>\n",
       "      <td>0.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>101.179164</td>\n",
       "      <td>101.179169</td>\n",
       "      <td>121.990278</td>\n",
       "      <td>121.990288</td>\n",
       "      <td>197</td>\n",
       "      <td>10.058786</td>\n",
       "      <td>11.044921</td>\n",
       "      <td>0.195769</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam_005</td>\n",
       "      <td>0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1382.132048</td>\n",
       "      <td>1382.132080</td>\n",
       "      <td>1389.458887</td>\n",
       "      <td>1389.458862</td>\n",
       "      <td>190</td>\n",
       "      <td>37.177037</td>\n",
       "      <td>37.275446</td>\n",
       "      <td>0.561554</td>\n",
       "      <td>150</td>\n",
       "      <td>relu</td>\n",
       "      <td>adagrad_005</td>\n",
       "      <td>0.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>84.662256</td>\n",
       "      <td>84.662247</td>\n",
       "      <td>116.007755</td>\n",
       "      <td>116.007736</td>\n",
       "      <td>184</td>\n",
       "      <td>9.201209</td>\n",
       "      <td>10.770689</td>\n",
       "      <td>0.490967</td>\n",
       "      <td>200</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam_0005</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>154.702597</td>\n",
       "      <td>154.702591</td>\n",
       "      <td>174.748838</td>\n",
       "      <td>174.748825</td>\n",
       "      <td>154</td>\n",
       "      <td>12.437950</td>\n",
       "      <td>13.219260</td>\n",
       "      <td>0.468345</td>\n",
       "      <td>200</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam_005</td>\n",
       "      <td>0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>293.815909</td>\n",
       "      <td>293.815887</td>\n",
       "      <td>292.408084</td>\n",
       "      <td>292.408112</td>\n",
       "      <td>121</td>\n",
       "      <td>17.141059</td>\n",
       "      <td>17.099945</td>\n",
       "      <td>0.259666</td>\n",
       "      <td>50</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adagrad_02</td>\n",
       "      <td>0.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>360.313932</td>\n",
       "      <td>360.313965</td>\n",
       "      <td>370.613009</td>\n",
       "      <td>370.613007</td>\n",
       "      <td>62</td>\n",
       "      <td>18.981938</td>\n",
       "      <td>19.251312</td>\n",
       "      <td>0.271495</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>adagrad_005</td>\n",
       "      <td>0.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>244.381297</td>\n",
       "      <td>244.381256</td>\n",
       "      <td>244.194078</td>\n",
       "      <td>244.194077</td>\n",
       "      <td>60</td>\n",
       "      <td>15.632698</td>\n",
       "      <td>15.626710</td>\n",
       "      <td>0.247615</td>\n",
       "      <td>50</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adagrad_005</td>\n",
       "      <td>0.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>87.490673</td>\n",
       "      <td>87.490669</td>\n",
       "      <td>87.137560</td>\n",
       "      <td>87.137558</td>\n",
       "      <td>115</td>\n",
       "      <td>9.353645</td>\n",
       "      <td>9.334750</td>\n",
       "      <td>0.756261</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adagrad_005</td>\n",
       "      <td>0.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1393.413407</td>\n",
       "      <td>1393.413452</td>\n",
       "      <td>1396.197367</td>\n",
       "      <td>1396.197388</td>\n",
       "      <td>60</td>\n",
       "      <td>37.328454</td>\n",
       "      <td>37.365725</td>\n",
       "      <td>0.543673</td>\n",
       "      <td>150</td>\n",
       "      <td>relu</td>\n",
       "      <td>adagrad_005</td>\n",
       "      <td>0.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            loss  mean_squared_error     val_loss  val_mean_squared_error  \\\n",
       "166   585.102651          585.102600   602.217882              602.217896   \n",
       "197   101.179164          101.179169   121.990278              121.990288   \n",
       "190  1382.132048         1382.132080  1389.458887             1389.458862   \n",
       "184    84.662256           84.662247   116.007755              116.007736   \n",
       "154   154.702597          154.702591   174.748838              174.748825   \n",
       "121   293.815909          293.815887   292.408084              292.408112   \n",
       "62    360.313932          360.313965   370.613009              370.613007   \n",
       "60    244.381297          244.381256   244.194078              244.194077   \n",
       "115    87.490673           87.490669    87.137560               87.137558   \n",
       "60   1393.413407         1393.413452  1396.197367             1396.197388   \n",
       "\n",
       "     epoch       RMSE   val_RMSE     times  hunits activation    optimizer  \\\n",
       "166    166  24.188894  24.540128  0.777923     200       relu   adagrad_02   \n",
       "197    197  10.058786  11.044921  0.195769      50       relu     adam_005   \n",
       "190    190  37.177037  37.275446  0.561554     150       relu  adagrad_005   \n",
       "184    184   9.201209  10.770689  0.490967     200       relu    adam_0005   \n",
       "154    154  12.437950  13.219260  0.468345     200       relu     adam_005   \n",
       "121    121  17.141059  17.099945  0.259666      50       tanh   adagrad_02   \n",
       "62      62  18.981938  19.251312  0.271495      50       relu  adagrad_005   \n",
       "60      60  15.632698  15.626710  0.247615      50       tanh  adagrad_005   \n",
       "115    115   9.353645   9.334750  0.756261     200       tanh  adagrad_005   \n",
       "60      60  37.328454  37.365725  0.543673     150       relu  adagrad_005   \n",
       "\n",
       "      lrate  \n",
       "166  0.0200  \n",
       "197  0.0050  \n",
       "190  0.0500  \n",
       "184  0.0005  \n",
       "154  0.0050  \n",
       "121  0.0200  \n",
       "62   0.0500  \n",
       "60   0.0500  \n",
       "115  0.0500  \n",
       "60   0.0500  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pkled dataframe for the baseline single layer neural net\n",
    "relu_sl_lr_df = pd.read_pickle(\"OutputData/single_layer_relu_lr_df.pkl\")\n",
    "relu_sl_lr_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc2c1428d5454edd80856b531a9ca261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='optimizer', options=('adam_005', 'adam_0005', 'adagrad_02', 'adagr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Plot the relu learning rate data\n",
    "interact_manual(plot_validation_loss, df=fixed(relu_sl_lr_df), \n",
    "                optimizer = relu_sl_lr_df.optimizer.unique(), \n",
    "                    activation = relu_sl_lr_df.activation.unique())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Layer Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mean_squared_error</th>\n",
       "      <th>epoch</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>val_RMSE</th>\n",
       "      <th>times</th>\n",
       "      <th>hunits</th>\n",
       "      <th>activation</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>lrate</th>\n",
       "      <th>cum_times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.398503</td>\n",
       "      <td>150</td>\n",
       "      <td>elu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.010</td>\n",
       "      <td>61.407666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.395313</td>\n",
       "      <td>150</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.010</td>\n",
       "      <td>16.632931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.416388</td>\n",
       "      <td>100</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.010</td>\n",
       "      <td>41.205356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>3.393705</td>\n",
       "      <td>3.393706</td>\n",
       "      <td>32.006817</td>\n",
       "      <td>32.006821</td>\n",
       "      <td>253</td>\n",
       "      <td>1.842201</td>\n",
       "      <td>5.657457</td>\n",
       "      <td>0.471379</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>129.203526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1.144119</td>\n",
       "      <td>1.144119</td>\n",
       "      <td>3.683345</td>\n",
       "      <td>3.683345</td>\n",
       "      <td>198</td>\n",
       "      <td>1.069635</td>\n",
       "      <td>1.919204</td>\n",
       "      <td>0.501398</td>\n",
       "      <td>100</td>\n",
       "      <td>elu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>99.629387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>2.872493</td>\n",
       "      <td>2.872493</td>\n",
       "      <td>29.487440</td>\n",
       "      <td>29.487438</td>\n",
       "      <td>225</td>\n",
       "      <td>1.694843</td>\n",
       "      <td>5.430234</td>\n",
       "      <td>0.474248</td>\n",
       "      <td>100</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>112.383048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>5.280693</td>\n",
       "      <td>5.280693</td>\n",
       "      <td>34.801313</td>\n",
       "      <td>34.801315</td>\n",
       "      <td>159</td>\n",
       "      <td>2.297976</td>\n",
       "      <td>5.899264</td>\n",
       "      <td>0.470124</td>\n",
       "      <td>150</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>76.343897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>5.132459</td>\n",
       "      <td>5.132459</td>\n",
       "      <td>33.683566</td>\n",
       "      <td>33.683567</td>\n",
       "      <td>158</td>\n",
       "      <td>2.265493</td>\n",
       "      <td>5.803755</td>\n",
       "      <td>0.533842</td>\n",
       "      <td>100</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>78.727865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>5.469104</td>\n",
       "      <td>5.469104</td>\n",
       "      <td>35.034632</td>\n",
       "      <td>35.034634</td>\n",
       "      <td>158</td>\n",
       "      <td>2.338612</td>\n",
       "      <td>5.919006</td>\n",
       "      <td>0.518651</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>81.698643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112.388315</td>\n",
       "      <td>112.388298</td>\n",
       "      <td>108.367533</td>\n",
       "      <td>108.367531</td>\n",
       "      <td>2</td>\n",
       "      <td>10.601335</td>\n",
       "      <td>10.409973</td>\n",
       "      <td>0.504838</td>\n",
       "      <td>50</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.834678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           loss  mean_squared_error    val_loss  val_mean_squared_error  \\\n",
       "145         NaN                 NaN         NaN                     NaN   \n",
       "38          NaN                 NaN         NaN                     NaN   \n",
       "95          NaN                 NaN         NaN                     NaN   \n",
       "253    3.393705            3.393706   32.006817               32.006821   \n",
       "198    1.144119            1.144119    3.683345                3.683345   \n",
       "225    2.872493            2.872493   29.487440               29.487438   \n",
       "159    5.280693            5.280693   34.801313               34.801315   \n",
       "158    5.132459            5.132459   33.683566               33.683567   \n",
       "158    5.469104            5.469104   35.034632               35.034634   \n",
       "2    112.388315          112.388298  108.367533              108.367531   \n",
       "\n",
       "     epoch       RMSE   val_RMSE     times  hunits activation optimizer  \\\n",
       "145    145        NaN        NaN  0.398503     150        elu       sgd   \n",
       "38      38        NaN        NaN  0.395313     150       relu       sgd   \n",
       "95      95        NaN        NaN  0.416388     100       relu       sgd   \n",
       "253    253   1.842201   5.657457  0.471379      50       relu      adam   \n",
       "198    198   1.069635   1.919204  0.501398     100        elu      adam   \n",
       "225    225   1.694843   5.430234  0.474248     100       relu      adam   \n",
       "159    159   2.297976   5.899264  0.470124     150       relu      adam   \n",
       "158    158   2.265493   5.803755  0.533842     100       relu      adam   \n",
       "158    158   2.338612   5.919006  0.518651      50       relu      adam   \n",
       "2        2  10.601335  10.409973  0.504838      50       relu      adam   \n",
       "\n",
       "     lrate   cum_times  \n",
       "145  0.010   61.407666  \n",
       "38   0.010   16.632931  \n",
       "95   0.010   41.205356  \n",
       "253  0.001  129.203526  \n",
       "198  0.001   99.629387  \n",
       "225  0.001  112.383048  \n",
       "159  0.001   76.343897  \n",
       "158  0.001   78.727865  \n",
       "158  0.001   81.698643  \n",
       "2    0.001    1.834678  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pkled dataframe for the baseline single layer neural net\n",
    "tl_df = pd.read_pickle(\"OutputData/two_layer_df.pkl\")\n",
    "tl_df['cum_times'] = tl_df.groupby(['hunits', 'activation', 'optimizer', 'lrate']).times.cumsum()\n",
    "tl_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21333dbab9014471977b54374bd4adc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='optimizer', options=('adam', 'sgd'), value='adam'), Dropdown(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Plot the relu learning rate data\n",
    "interact_manual(plot_validation_loss, df=fixed(tl_df), \n",
    "                optimizer = tl_df.optimizer.unique(), \n",
    "                    activation = tl_df.activation.unique(),\n",
    "               ymax=10,\n",
    "               timemax=250)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Data below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline CNN\n",
    "\n",
    "The baseline CNN was structured following Nuori blog on this Facial Keypoint Detection topic. It uses a CNN architecture of the following:\n",
    "\n",
    "1. Input Layer\n",
    "2. Convolution Layer with valid padding and add N filters\n",
    "3. Max Pooling with 2,2 kernel\n",
    "4. Repeat Steps 2 and 3, doubling the number of filters each time you convolve\n",
    "5. After three full layers - flatten and condense to 500 units\n",
    "6. 500 --> 500 fully connected layer\n",
    "7. Linear activation to 30 output nodes\n",
    "\n",
    "For our Baseline CNN we have chosen to use the relu activation and not use dropout layers. We train only on the non-nan data. And we have identified many follow on studies including:\n",
    "\n",
    "\n",
    "1. *Model for each keypoint* - Some keypoints have a lot more training data than others. We can maximize the use of our training data by building separate specialized models for each keypoint.\n",
    "2. *Transform images* - We can also expand our training data by applying transformations to our training images. We can do things like flipping on the x and y axes or rotating our images. We now will have a different feature matrix. The trick will be to also transform our keypoint locations appropriately.\n",
    "3. *Filters* - Investigate different filter strategies - the 32, 64, 128 strategy employed is expensive. Can we reduce the number of filters and still get good results\n",
    "4. *Drop Out* - Drop out layers can act as a means of regularization - If we notice overfitting we can try this as a correction mechanism\n",
    "5. *Stride v Pool* - Evaluate time and accuracy differences between pooling and using a stride\n",
    "6. *TPU Usage* - Identify when and how to best utilize TPU resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pkled dataframe for the baseline cnn\n",
    "cnn_df = pd.read_pickle(\"OutputData/cnn_base_df.pkl\")\n",
    "cnn_df['cum_times'] = cnn_df.groupby(['optimizer']).times.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mean_squared_error</th>\n",
       "      <th>epoch</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>val_RMSE</th>\n",
       "      <th>times</th>\n",
       "      <th>layers</th>\n",
       "      <th>pooling</th>\n",
       "      <th>fc_layer</th>\n",
       "      <th>activation</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>lrate</th>\n",
       "      <th>cum_times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2.437129</td>\n",
       "      <td>2.437129</td>\n",
       "      <td>3.216901</td>\n",
       "      <td>3.216901</td>\n",
       "      <td>127</td>\n",
       "      <td>1.561131</td>\n",
       "      <td>1.793572</td>\n",
       "      <td>9.558447</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>500</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1202.983716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1.150528</td>\n",
       "      <td>1.150528</td>\n",
       "      <td>3.033182</td>\n",
       "      <td>3.033182</td>\n",
       "      <td>133</td>\n",
       "      <td>1.072627</td>\n",
       "      <td>1.741603</td>\n",
       "      <td>9.299843</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>500</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1275.841142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1451.824655</td>\n",
       "      <td>1451.824585</td>\n",
       "      <td>16.243768</td>\n",
       "      <td>16.243769</td>\n",
       "      <td>0</td>\n",
       "      <td>38.102816</td>\n",
       "      <td>4.030356</td>\n",
       "      <td>10.350786</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>500</td>\n",
       "      <td>relu</td>\n",
       "      <td>nadam</td>\n",
       "      <td>0.002</td>\n",
       "      <td>10.350786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1.604778</td>\n",
       "      <td>1.604778</td>\n",
       "      <td>3.185822</td>\n",
       "      <td>3.185822</td>\n",
       "      <td>112</td>\n",
       "      <td>1.266798</td>\n",
       "      <td>1.784887</td>\n",
       "      <td>9.531875</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>500</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1076.675367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>9.132258</td>\n",
       "      <td>9.132257</td>\n",
       "      <td>9.277314</td>\n",
       "      <td>9.277315</td>\n",
       "      <td>60</td>\n",
       "      <td>3.021962</td>\n",
       "      <td>3.045869</td>\n",
       "      <td>9.517048</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>500</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>582.320275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>10.204178</td>\n",
       "      <td>10.204181</td>\n",
       "      <td>9.677074</td>\n",
       "      <td>9.677074</td>\n",
       "      <td>38</td>\n",
       "      <td>3.194398</td>\n",
       "      <td>3.110800</td>\n",
       "      <td>9.506696</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>500</td>\n",
       "      <td>relu</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.010</td>\n",
       "      <td>372.320420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1.257240</td>\n",
       "      <td>1.257240</td>\n",
       "      <td>2.992142</td>\n",
       "      <td>2.992142</td>\n",
       "      <td>194</td>\n",
       "      <td>1.121267</td>\n",
       "      <td>1.729781</td>\n",
       "      <td>9.458734</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>500</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1838.008554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>4.646559</td>\n",
       "      <td>4.646559</td>\n",
       "      <td>4.644593</td>\n",
       "      <td>4.644594</td>\n",
       "      <td>93</td>\n",
       "      <td>2.155588</td>\n",
       "      <td>2.155132</td>\n",
       "      <td>9.434961</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>500</td>\n",
       "      <td>relu</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.010</td>\n",
       "      <td>890.737207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>9.261003</td>\n",
       "      <td>9.261003</td>\n",
       "      <td>8.998551</td>\n",
       "      <td>8.998552</td>\n",
       "      <td>39</td>\n",
       "      <td>3.043190</td>\n",
       "      <td>2.999759</td>\n",
       "      <td>9.269853</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>500</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.010</td>\n",
       "      <td>377.735415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>3.966604</td>\n",
       "      <td>3.966604</td>\n",
       "      <td>4.257668</td>\n",
       "      <td>4.257668</td>\n",
       "      <td>99</td>\n",
       "      <td>1.991633</td>\n",
       "      <td>2.063412</td>\n",
       "      <td>9.375020</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>500</td>\n",
       "      <td>relu</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.010</td>\n",
       "      <td>947.403977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2.503813</td>\n",
       "      <td>2.503812</td>\n",
       "      <td>3.619661</td>\n",
       "      <td>3.619660</td>\n",
       "      <td>186</td>\n",
       "      <td>1.582344</td>\n",
       "      <td>1.902541</td>\n",
       "      <td>9.317168</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>500</td>\n",
       "      <td>relu</td>\n",
       "      <td>nadam</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1756.305902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2.830967</td>\n",
       "      <td>2.830967</td>\n",
       "      <td>3.558862</td>\n",
       "      <td>3.558862</td>\n",
       "      <td>110</td>\n",
       "      <td>1.682548</td>\n",
       "      <td>1.886495</td>\n",
       "      <td>9.403444</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>500</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1040.871390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2.022387</td>\n",
       "      <td>2.022387</td>\n",
       "      <td>3.107188</td>\n",
       "      <td>3.107188</td>\n",
       "      <td>142</td>\n",
       "      <td>1.422107</td>\n",
       "      <td>1.762722</td>\n",
       "      <td>9.499322</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>500</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1345.184141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.546210</td>\n",
       "      <td>0.546210</td>\n",
       "      <td>3.186799</td>\n",
       "      <td>3.186799</td>\n",
       "      <td>192</td>\n",
       "      <td>0.739060</td>\n",
       "      <td>1.785161</td>\n",
       "      <td>9.276074</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>500</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1826.221265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>10.460291</td>\n",
       "      <td>10.460293</td>\n",
       "      <td>10.160820</td>\n",
       "      <td>10.160819</td>\n",
       "      <td>77</td>\n",
       "      <td>3.234238</td>\n",
       "      <td>3.187604</td>\n",
       "      <td>9.270741</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>500</td>\n",
       "      <td>relu</td>\n",
       "      <td>nadam</td>\n",
       "      <td>0.002</td>\n",
       "      <td>740.935075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>10.365780</td>\n",
       "      <td>10.365781</td>\n",
       "      <td>10.266846</td>\n",
       "      <td>10.266846</td>\n",
       "      <td>66</td>\n",
       "      <td>3.219593</td>\n",
       "      <td>3.204192</td>\n",
       "      <td>9.330250</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>500</td>\n",
       "      <td>relu</td>\n",
       "      <td>nadam</td>\n",
       "      <td>0.002</td>\n",
       "      <td>638.655866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>1.121672</td>\n",
       "      <td>1.121672</td>\n",
       "      <td>3.078161</td>\n",
       "      <td>3.078161</td>\n",
       "      <td>138</td>\n",
       "      <td>1.059090</td>\n",
       "      <td>1.754469</td>\n",
       "      <td>9.322233</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>500</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1322.573277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1.798380</td>\n",
       "      <td>1.798379</td>\n",
       "      <td>3.033823</td>\n",
       "      <td>3.033823</td>\n",
       "      <td>152</td>\n",
       "      <td>1.341037</td>\n",
       "      <td>1.741787</td>\n",
       "      <td>9.507921</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>500</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1441.203421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2.558324</td>\n",
       "      <td>2.558324</td>\n",
       "      <td>3.323868</td>\n",
       "      <td>3.323869</td>\n",
       "      <td>130</td>\n",
       "      <td>1.599476</td>\n",
       "      <td>1.823148</td>\n",
       "      <td>7100.268397</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>500</td>\n",
       "      <td>relu</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.010</td>\n",
       "      <td>15325.297603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.886179</td>\n",
       "      <td>0.886179</td>\n",
       "      <td>3.011179</td>\n",
       "      <td>3.011179</td>\n",
       "      <td>154</td>\n",
       "      <td>0.941371</td>\n",
       "      <td>1.735275</td>\n",
       "      <td>9.345980</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>500</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1471.287639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            loss  mean_squared_error   val_loss  val_mean_squared_error  \\\n",
       "127     2.437129            2.437129   3.216901                3.216901   \n",
       "133     1.150528            1.150528   3.033182                3.033182   \n",
       "0    1451.824655         1451.824585  16.243768               16.243769   \n",
       "112     1.604778            1.604778   3.185822                3.185822   \n",
       "60      9.132258            9.132257   9.277314                9.277315   \n",
       "38     10.204178           10.204181   9.677074                9.677074   \n",
       "194     1.257240            1.257240   2.992142                2.992142   \n",
       "93      4.646559            4.646559   4.644593                4.644594   \n",
       "39      9.261003            9.261003   8.998551                8.998552   \n",
       "99      3.966604            3.966604   4.257668                4.257668   \n",
       "186     2.503813            2.503812   3.619661                3.619660   \n",
       "110     2.830967            2.830967   3.558862                3.558862   \n",
       "142     2.022387            2.022387   3.107188                3.107188   \n",
       "192     0.546210            0.546210   3.186799                3.186799   \n",
       "77     10.460291           10.460293  10.160820               10.160819   \n",
       "66     10.365780           10.365781  10.266846               10.266846   \n",
       "138     1.121672            1.121672   3.078161                3.078161   \n",
       "152     1.798380            1.798379   3.033823                3.033823   \n",
       "130     2.558324            2.558324   3.323868                3.323869   \n",
       "154     0.886179            0.886179   3.011179                3.011179   \n",
       "\n",
       "     epoch       RMSE  val_RMSE        times  layers pooling  fc_layer  \\\n",
       "127    127   1.561131  1.793572     9.558447       3     yes       500   \n",
       "133    133   1.072627  1.741603     9.299843       3     yes       500   \n",
       "0        0  38.102816  4.030356    10.350786       3     yes       500   \n",
       "112    112   1.266798  1.784887     9.531875       3     yes       500   \n",
       "60      60   3.021962  3.045869     9.517048       3     yes       500   \n",
       "38      38   3.194398  3.110800     9.506696       3     yes       500   \n",
       "194    194   1.121267  1.729781     9.458734       3     yes       500   \n",
       "93      93   2.155588  2.155132     9.434961       3     yes       500   \n",
       "39      39   3.043190  2.999759     9.269853       3     yes       500   \n",
       "99      99   1.991633  2.063412     9.375020       3     yes       500   \n",
       "186    186   1.582344  1.902541     9.317168       3     yes       500   \n",
       "110    110   1.682548  1.886495     9.403444       3     yes       500   \n",
       "142    142   1.422107  1.762722     9.499322       3     yes       500   \n",
       "192    192   0.739060  1.785161     9.276074       3     yes       500   \n",
       "77      77   3.234238  3.187604     9.270741       3     yes       500   \n",
       "66      66   3.219593  3.204192     9.330250       3     yes       500   \n",
       "138    138   1.059090  1.754469     9.322233       3     yes       500   \n",
       "152    152   1.341037  1.741787     9.507921       3     yes       500   \n",
       "130    130   1.599476  1.823148  7100.268397       3     yes       500   \n",
       "154    154   0.941371  1.735275     9.345980       3     yes       500   \n",
       "\n",
       "    activation optimizer  lrate     cum_times  \n",
       "127       relu       sgd  0.010   1202.983716  \n",
       "133       relu      adam  0.001   1275.841142  \n",
       "0         relu     nadam  0.002     10.350786  \n",
       "112       relu      adam  0.001   1076.675367  \n",
       "60        relu      adam  0.001    582.320275  \n",
       "38        relu   adagrad  0.010    372.320420  \n",
       "194       relu       sgd  0.010   1838.008554  \n",
       "93        relu   adagrad  0.010    890.737207  \n",
       "39        relu       sgd  0.010    377.735415  \n",
       "99        relu   adagrad  0.010    947.403977  \n",
       "186       relu     nadam  0.002   1756.305902  \n",
       "110       relu       sgd  0.010   1040.871390  \n",
       "142       relu       sgd  0.010   1345.184141  \n",
       "192       relu      adam  0.001   1826.221265  \n",
       "77        relu     nadam  0.002    740.935075  \n",
       "66        relu     nadam  0.002    638.655866  \n",
       "138       relu      adam  0.001   1322.573277  \n",
       "152       relu       sgd  0.010   1441.203421  \n",
       "130       relu   adagrad  0.010  15325.297603  \n",
       "154       relu      adam  0.001   1471.287639  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_df.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create a plotting function for our cnn data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plotting function to pass to the interact widget function\n",
    "def plot_cnn_data(df=cnn_df, optimizer = cnn_df.optimizer.unique(), \n",
    "                    activation = cnn_df.activation.unique(), \n",
    "                         ymax=100,\n",
    "                        timemax=1000):\n",
    "        \n",
    "    # Group the neural net data by optimizer\n",
    "    groups = df.groupby(['optimizer'])\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 20))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Loop over the grouped data and plot out epoch timing and validation loss data\n",
    "    for name, group in groups:\n",
    "        \n",
    "        # Plot training and validation losses by epoch\n",
    "        axes[0].plot(group.epoch, group.val_RMSE, label=str(name)+' Validation Loss')\n",
    "        axes[0].scatter(group.epoch, group.RMSE, label=str(name)+' Training Loss')\n",
    "        axes[0].set_ylim([0,ymax])\n",
    "        axes[0].set_xlabel('Epoch')\n",
    "        axes[0].set_ylabel('Root Mean Square Error')\n",
    "        axes[0].set_title(\"{} Optimizer and {} Activation\".format(group.optimizer.unique(), group.activation.unique()))\n",
    "        \n",
    "        # Plot train time by epoch\n",
    "        axes[1].scatter(group.epoch, group.times, label=str(name)+' Fit Time')\n",
    "        axes[1].set_xlabel('Epoch')\n",
    "        axes[1].set_ylabel('Fit Time (seconds)')\n",
    "        axes[1].set_ylim([0,timemax/group.epoch.max()])\n",
    "        axes[1].legend()\n",
    "        \n",
    "        # Plot cumulative training time\n",
    "        axes[2].plot(group.epoch, group.cum_times, label=str(name)+' Fit Time (s)', lw=4)\n",
    "        axes[2].set_xlabel('Epoch')\n",
    "        axes[2].set_ylabel('Cumulative Fit Time (seconds)')\n",
    "        axes[2].grid(b=True)\n",
    "        axes[2].set_ylim([0,timemax])\n",
    "        axes[2].legend()\n",
    "        \n",
    "        # Plot cumulative validation loss by cumulative time\n",
    "        axes[3].plot(group.cum_times, group.val_RMSE, label=str(name)+' Validation Loss', lw=3)\n",
    "        axes[3].set_xlabel('Cumulative Fit Time (seconds)')\n",
    "        axes[3].set_ylabel('Validation RMSE')\n",
    "        axes[3].set_xlim([0,timemax])\n",
    "        axes[3].set_ylim([0,ymax])\n",
    "        axes[3].legend()\n",
    "    \n",
    "    # Add line for knr score\n",
    "    axes[0].axhline(2.49, label='kNR Score', lw=5, c='k')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Adjust the spacing of the subplots\n",
    "    fig.subplots_adjust(left=0.03, right=0.97, hspace=0.1, wspace=0.15)\n",
    "\n",
    "    # Add an overarching title for these plots\n",
    "    fig.suptitle(\"Performance Comparison for Baseline Convolutional Neural Nets\",\n",
    "                 fontsize=18, y=0.93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae4c9680161a4c578417944242b34dd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='optimizer', options=('adam', 'sgd', 'nadam', 'adagrad'), value='ad…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Plot the relu learning rate data\n",
    "interact_manual(plot_cnn_data, df=fixed(cnn_df), \n",
    "                optimizer = cnn_df.optimizer.unique(), \n",
    "                    activation = cnn_df.activation.unique(),\n",
    "               ymax=10,\n",
    "               timemax=1000)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      16.774411\n",
       "1      10.803520\n",
       "2      10.233881\n",
       "3      10.233680\n",
       "4       9.985762\n",
       "5      10.038510\n",
       "6      10.134028\n",
       "7      10.044329\n",
       "8       9.996206\n",
       "9      10.064538\n",
       "10     10.101108\n",
       "11     10.020350\n",
       "12     10.060766\n",
       "13     10.003001\n",
       "14     10.061866\n",
       "15     10.032402\n",
       "16     10.131830\n",
       "17      9.986675\n",
       "18      9.988453\n",
       "19     10.018970\n",
       "20     10.146545\n",
       "21     10.287867\n",
       "22      9.998142\n",
       "23     10.046421\n",
       "24     10.002417\n",
       "25      9.982548\n",
       "26      9.980573\n",
       "27     10.262111\n",
       "28     10.083271\n",
       "29     10.200400\n",
       "         ...    \n",
       "170     2.851715\n",
       "171     2.914028\n",
       "172     2.778235\n",
       "173     2.907122\n",
       "174     2.875822\n",
       "175     2.778594\n",
       "176     2.955646\n",
       "177     2.977480\n",
       "178     2.783652\n",
       "179     2.916816\n",
       "180     2.749964\n",
       "181     2.981440\n",
       "182     2.985107\n",
       "183     2.804005\n",
       "184     2.708213\n",
       "185     3.157891\n",
       "186     2.834607\n",
       "187     2.745469\n",
       "188     2.774565\n",
       "189     2.847229\n",
       "190     2.791091\n",
       "191     2.746600\n",
       "192     2.729275\n",
       "193     2.836102\n",
       "194     2.726668\n",
       "195     2.776544\n",
       "196     2.863327\n",
       "197     2.739938\n",
       "198     2.703899\n",
       "199     2.938621\n",
       "Name: val_loss, Length: 800, dtype: float64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_df.val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessment of Initial CNN Results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
